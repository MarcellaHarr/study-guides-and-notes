[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Study Notes & Guides",
    "section": "",
    "text": "Welcome",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "1  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "courseD421.html",
    "href": "courseD421.html",
    "title": "Discrete Math II",
    "section": "",
    "text": "Discrete Math II Functions and Applications (D421)\n\n\n\n\n\n\n\n\nNote\n\n\n\nThese exercises are not mines. They are from this Quizlet »\n\n\n\n\n\nThe Foundations | Logic and Proofs\n\nChapter 1:\n\n\nExercise 1a\n\n\nStep-1Step-2Step-3Step-4Results\n\n\nIn this exercise, we determine whether the given statement represents a proposition.\nWhat is a proposition?\n\n\nA proposition is a statement that is known to be true or known to be false. If we don’t know if a statement is true or false, then the statement is not a proposition.\n\n\n(a)\nThe statement is a proposition because we know that the statement is true \\(T\\) (as Boston is the capital of Massachusetts).\n\n\nLet us summarize how the results were derived.\nTo determine whether a statement is a proposition, we determined whether the statement was true or false.\nIf we were able to derive a truth value, then the statement has to be a proposition. If we were unable to assign a truth value to the statement or the truth value was dependent on some variable, then the statement couldn’t be a proposition.\n\n\n(a) Proposition, \\(T\\)\n\n\n\n\nExercise 1b\n\n\nStep-1Step-2Step-3Step-4Results\n\n\nIn this exercise, we determine whether the given statement represents a proposition.\nWhat is a proposition?\n\n\nA proposition is a statement that is known to be true or known to be false. If we don’t know if a statement is true or false, then the statement is not a proposition.\n\n\n\n\n\nThe statement is a proposition because we know that the statement is false \\(F\\) (as Tallahassee is the capital of Florida).\n\n\nLet us summarize how the results were derived.\nTo determine whether a statement is a proposition, we determined whether the statement was true or false.\n\nIf we were able to derive a truth value, then the statement has to be a proposition.\nIf we were unable to assign a truth value to the statement or the truth value was dependent on some variable, then the statement couldn’t be a proposition.\n\n\n\n(b) Proposition, \\(F\\)\n\n\n\n\nExercise 1c\n\n\nStep-1Step-2Step-3Step-4Results\n\n\nIn this exercise, we determine whether the given statement represents a proposition.\nWhat is a proposition?\n\n\nA proposition is a statement that is known to be true or known to be false. If we don’t know if a statement is true or false, then the statement is not a proposition.\n\n\n(c)\nThe statement is a proposition because we know that the statement is true \\(T\\) (since 2 added to 3 is equal to 5).\n\n\nLet us summarize how the results were derived.\nTo determine whether a statement is a proposition, we determined whether the statement was true or false.\n\nIf we were able to derive a truth value, then the statement has to be a proposition.\nIf we were unable to assign a truth value to the statement or the truth value was dependent on some variable, then the statement couldn’t be a proposition.\n\n\n\n(c) Proposition, \\(T\\)\n\n\n\n\nExercise 1d\n\n\nStep-1Step-2Step-3Step-4Results\n\n\nIn this exercise, we determine whether the given statement represents a proposition.\nWhat is a proposition?\n\n\nA proposition is a statement that is known to be true or known to be false. If we don’t know if a statement is true or false, then the statement is not a proposition.\n\n\n(d)\nThe statement is a proposition because we know that the statement is false \\(F\\) (since 5 added to 7 is equal to 12, and thus not equal to 10).\n\n\nLet us summarize how the results were derived.\nTo determine whether a statement is a proposition, we determined whether the statement was true or false.\n\nIf we were able to derive a truth value, then the statement has to be a proposition.\nIf we were unable to assign a truth value to the statement or the truth value was dependent on some variable, then the statement couldn’t be a proposition.\n\n\n\n(d) Proposition, \\(F\\)\n\n\n\n\nExercise 1e\n\n\nStep-1Step-2Step-3Step-4Results\n\n\nIn this exercise, we determine whether the given statement represents a proposition.\nWhat is a proposition?\n\n\nA proposition is a statement that is known to be true or known to be false. If we don’t know if a statement is true or false, then the statement is not a proposition.\n\n\n(e)\nThe statement is not a proposition, because the statement could be true or could be false (but we do not know which case since \\(x\\) is unknown).\n\n\nLet us summarize how the results were derived.\nTo determine whether a statement is a proposition, we determined whether the statement was true or false.\n\nIf we were able to derive a truth value, then the statement has to be a proposition.\nIf we were unable to assign a truth value to the statement or the truth value was dependent on some variable, then the statement couldn’t be a proposition.\n\n\n\n(e) Not a proposition\n\n\n\n\nExercise 1f\n\n\nStep-1Step-2Step-3Step-4Results\n\n\nIn this exercise, we determine whether the given statement represents a proposition.\nWhat is a proposition?\n\n\nA proposition is a statement that is known to be true or known to be false. If we don’t know if a statement is true or false, then the statement is not a proposition.\n\n\n(f)\nThe statement is not a proposition, because it is not a statement that could be true or false.\n\n\nLet us summarize how the results were derived.\nTo determine whether a statement is a proposition, we determined whether the statement was true or false.\n\nIf we were able to derive a truth value, then the statement has to be a proposition.\nIf we were unable to assign a truth value to the statement or the truth value was dependent on some variable, then the statement couldn’t be a proposition.\n\n\n\n(f) Not a proposition\n\n\n\n\n\n\nChapter 2:\n\n\nExercise 2a\n\n\nStep-1Step-2\n\n\nPART A: This sentence is not a proposition because it is not a declarative sentence.\nSo it is not possible for this sentence to be true or false.\n\n\nPART A: not a proposition\n\n\n\n\nExercise 2b\n\n\nStep-1Step-2\n\n\nPART B: This sentence is not a proposition because it is not a declarative sentence.\nSo it is not possible for this sentence to be true or false.\n\n\nPART B: not a proposition\n\n\n\n\nExercise 2c\n\n\nStep-1Step-2\n\n\nPART C: This sentence is a proposition because it can either be true or false.\nIts truth value is false because black flies exist everywhere.\n\n\nPART C: proposition, false\n\n\n\n\nExercise 2d\n\n\nStep-1Step-2\n\n\nPART D: This sentence is not a proposition because the value of \\(x\\) is not given.\nSo it is not possible for this sentence to be true or false.\n\n\nPART D: not a proposition\n\n\n\n\nExercise 2e\n\n\nStep-1Step-2\n\n\nPART E: This sentence is a proposition because it can either be true or false.\nIts truth value is false because the moon is not made from green cheese.\n\n\nPART E: proposition, false\n\n\n\n\nExercise 2f\n\n\nStep-1Step-2\n\n\nPART F: This sentence is not a proposition because the value of \\(n\\) is not given.\nSo it is not possible for this sentence to be true or false.\n\n\nPART F: not a proposition\n\n\n\n\n\n\nChapter 3\n\n\nExercise 3\n\n\nStep-1Step-2Step-3Step-4Results\n\n\n(a)\n\n\\(\\text{ Linda is younger than Sanjay. }\\)\n\nThe negation of the proposition adds the word “not” to the sentence:\n\n\\(\\text{ Linda is not younger than Sanjay. }\\)\n\nNote: This sentence is also equivalent with: Linda is older or the same age as Sanjay.\n\n\n(b)\n\n\\(\\text{ Mei makes more money than Isabella. }\\)\n\nThe negation of the proposition adds the word “not” to the sentence:\n\n\\(\\text{ Mei does not make more money than Isabella. }\\)\n\nNote: This sentence is also equivalent with: Mei makes less money or the same amount of money than Isabella.\n\n\n(c)\n\n\\(\\text{ Moshe is taller than Monica. }\\)\n\nThe negation of the proposition adds the word “not” to the sentence:\n\n\\(\\text{ Moshe is not taller than Monica. }\\)\n\nNote: This sentence is also equivalent with: Moshe is shorter or the same height as Monica.\n\n\n(d)\n\n\\(\\text{ Abby is richer than Ricardo. }\\)\n\nThe negation of the proposition adds the word “not” to the sentence:\n\n\\(\\text{ Abby is not richer than Ricardo. }\\)\n\nNote: This sentence is also equivalent with: Abby is poorer or equally rich to Ricardo.\n\n\n\n(a) Linda is not younger than Sanjay.\n(b) Mei does not make more money than Isabella.\n(c) Moshe is not taller than Monica.\n(d) Abby is not richer than Ricardo.\n\n\n\n\n\n\n\nChapter 4:\n\n\nExercise 4\n\n\nStep-1Step-2Step-3Step-4\n\n\n(a)\n\n\\(\\text{ Janice has more Facebook friends than Juan. }\\)\n\nThe negation of the proposition adds the word “not” to the sentence:\n\n\\(\\text{ Janice does not have more Facebook friends than Juan. }\\)\n\nNote: This sentence is also equivalent with: Janice has less Facebook friends or the same number of Facebook friends as Juan.\n\n\n(b)\n\n\\(\\text{ Quincy is smarter than Venkat. }\\)\n\nThe negation of the proposition adds the word “not” to the sentence:\n\n\\(\\text{ Quincy is not smarter than Venkat. }\\)\n\nNote: This sentence is also equivalent with: Quincy is dumber or equally intelligent as Venkat.\n\n\n(c)\n\n\\(\\text{ Zelda drives more miles to school than Paola. }\\)\n\nThe negation of the proposition adds the word “not” to the sentence:\n\n\\(\\text{ Zelda does not drive more miles to school than Paola. }\\)\n\nNote: This sentence is also equivalent with: Zelda drives less miles or the same number of miles to school than Paola.\n\n\n(d)\n\n\\(\\text{ Brianna sleeps longer than Gloria. }\\)\n\nThe negation of the proposition adds the word “not” to the sentence:\n\n\\(\\text{ Brianna does not sleep longer than Gloria. }\\)\n\nNote: This sentence is also equivalent with: Brianna sleeps less or the same amount than Gloria.\n\nResults\n\n(a) Janice does not have more Facebook friends than Juan.\n(b) Quincy is not smarter than Venkat.\n(c) Zelda does not drive more miles to school than Paola.\n(d) Brianna does not sleep longer than Gloria.\n\n\n\n\n\n\n\n\nChapter 5:\n\n\nExercise 5a\n\n\nStep-1Step-2Step-3\n\n\nDEFINITIONS\nThe negation of a statement states the opposite of the given statement.\n\n\nSOLUTION\n(a) The opposite of a statement can be obtained by adding “not” to the given statement. The opposite of Mei having an MP3 player is that Mei does not have an MP3 player.\n\n\n(a) Mei does not have an MP3 player.\n\n\n\n\nExercise 5b\n\n\nStep-1Step-2Step-3\n\n\nDEFINITIONS\nThe negation of a statement states the opposite of the given statement.\n\n\nSOLUTION\n(b) The opposite of no pollution in New Jersey is that there is pollution in New Jersey.\n\n\n(b) There is pollution in New Jersey.\n\n\n\n\nExercise 5c\n\n\nStep-1Step-2Step-3\n\n\nDEFINITIONS\nThe negation of a statement states the opposite of the given statement.\n\n\nSOLUTION\n(c) The opposite of an equality \\((=)\\) is a difference \\(\\text{(≠)   2+1 ≠ 3 }\\)\n\n\n(c) \\(2+1 ≠ 3\\)\n\n\n\n\nExercise 5d\n\n\nStep-1Step-2Step-3\n\n\nDEFINITIONS\nThe negation of a statement states the opposite of the given statement.\n\n\nSOLUTION\n(d) The opposite of a statement can be obtained by adding “not” to the given statement: The summer in Maine is not (hot and sunny).\n\n\n(d) The summer in Maine is not (hot and sunny).\n\n\n\n\n\n\nChapter 6:\n\n\ncoming soon …\n\n\n\n\nChapter 7:\n\n\nExercise 7a\n\n\nStep-1Step-2Step-3\n\n\nDEFINITION\nThe negation of a statement states the opposite of the given statement.\n\n\n(a) The opposite of a statement can be obtained by adding “not” to the given statement\n(note: adjust the sentence such that it remains proper English): - Steve does not have more than 100 GB free disk space on his laptop.\n\n\n(a) Steve does not have more than 100 GB free disk space on his laptop.\n\n\n\n\nExercise 7b\n\n\nStep-1Step-2Results\n\n\nDEFINITION\nThe negation of a statement states the opposite of the given statement.\n\n\n(b) The opposite of a statement can be obtained by adding “not” to the given statement (note: adjust the sentence such that it remains proper English): Zach does not block e-mails and texts from Jennifer.\n\n\n(b) Zach does not block e-mails and texts from Jennifer.\n\n\n\n\nExercise 7c\n\n\nStep-1Step-2Results\n\n\nDEFINITION\nThe negation of a statement states the opposite of the given statement.\n\n\n(c) The opposite of an equality \\((=)\\) is a difference \\((≠)\\)\n\n\\(\\text{7 ⋅ 11 ⋅ 13 ≠ 999}\\)\n\n\n\n\n\\(\\text{7 ⋅ 11 ⋅ 13 / 999}\\)\n\n\n\n\n\nExercise 7d\n\n\nStep-1Step-2Results\n\n\nDEFINITION\nThe negation of a statement states the opposite of the given statement.\n\n\n(d) The opposite of a statement can be obtained by adding “not” to the given statement (note: adjust the sentence such that it remains proper English): Diane did not ride her bicycle 100 miles on Sunday.\n\n\n\n(d) Diane did not ride her bicycle 100 miles on Sunday.\n\n\n\n\n\n\n\nChapter 8:\n\n\nExercise 8a\n\n\nStep-1Results\n\n\nA.  Smartphone B has 288 MB RAM, which is the most out of the other two phones.\n\n\n\nA. True\n\n\n\n\n\nExercise 8b\n\n\nStep-1Results\n\n\nB.  Either the ROM has to be greater or the resolution has to be greater. The resolution is greater in this example so it is true.\n\n\n\nB. True\n\n\n\n\n\nExercise 8c\n\n\nStep-1Results\n\n\nC.  It is false because the resolution is larger in Smartphone A.\n\n\n\nC. False\n\n\n\n\n\nExercise 8d\n\n\nStep-1Results\n\n\nD.  It may have more RAM and ROM, but Smartphone B’s resolution is less making the statement false.\n\n\n\nD. False\n\n\n\n\n\nExercise 8e\n\n\nStep-1Results\n\n\nE.  It is a biconditional statement which is F - T making the statement false.\n\n\n\nE. False\n\n\n\n\n\n\n\nChapter 9:\n\n\nExercise 9a\n\n\nStep-1Results\n\n\na. This proposition is false because Quixote Media had less annual revenue than Acme Computer ($111 billion &lt; $138 billion).\n\n\n\na. False\n\n\n\n\n\nExercise 9b\n\n\nStep-1Results\n\n\nb.  This proposition is true because both statements are true.\n\n\n\nb. True\n\n\n\n\n\nExercise 9c\n\n\nStep-1Results\n\n\nc.  This proposition is true because Quixote Media had the largest net profit.\nNote: Since this is an \\(V\\) statement, either statement being true makes the proposition true.\n\n\n\nc. True\n\n\n\n\n\nExercise 9d\n\n\nStep-1Results\n\n\nd.  This proposition is true because Acme Computer had the largest revenue.\nNote: this is an \\(⇒\\) proposition. Even though Quixote did not have the smallest net profit (hypothesis), the conclusion still holds.\n\n\n\nd. True\n\n\n\n\n\nExercise 9e\n\n\nStep-1Results\n\n\ne.  This proposition is true because in both directions the conclusions hold true.\n\n\n\ne. True\n\n\n\n\n\n\n\nChapter 10\n\n\nExercise 10a\n\n\nStep-1Step-2Results\n\n\nGiven:\n\np: I bought a lottery ticket this weekend.\nq: I won the million-dollar jackpot.\n\nInterpretation Symbols\n\n\\(¬p: \\text{not p}\\)\n\\(p ∨ q: \\text{p or q}\\)\n\\(p ∧ q: \\text{p and q}\\)\n\\(p → q: \\text{if p, then q}\\)\n\\(p ↔ q: \\text{p if and only if q}\\)\n\n\n\nSOLUTION\nDetermine the English sentences by replacing \\(\\text{p and q}\\) by their given sentences in the above interpretations (and adjust the sentence to form a proper English sentence as needed):\n\n\nI did not buy a lottery ticket this week.\n\n\n\n\n\n(a) I did not buy a lottery ticket this week.\n\n\n\n\n\nExercise 10b\n\n\nStep-1Step-2Results\n\n\nGiven:\n\np: I bought a lottery ticket this weekend.\nq: I won the million-dollar jackpot.\n\nInterpretation Symbols\n\n\\(¬p: \\text{not p}\\)\n\\(p ∨ q: \\text{p or q}\\)\n\\(p ∧ q: \\text{p and q}\\)\n\\(p → q: \\text{if p, then q}\\)\n\\(p ↔ q: \\text{p if and only if q}\\)\n\n\n\nSOLUTION\nDetermine the English sentences by replacing \\(\\text{p and q}\\) by their given sentences in the above interpretations (and adjust the sentence to form a proper English sentence as needed):\n\n\nI bought a lottery ticket this week or I won the million dollar jackpot.\n\n\n\n\n\n(b) I bought a lottery ticket this week or I won the million-dollar jackpot.\n\n\n\n\n\nExercise 10c\n\n\nStep-1Step-2Results\n\n\nGiven:\n\np: I bought a lottery ticket this weekend.\nq: I won the million-dollar jackpot.\n\nInterpretation Symbols\n\n\\(¬p: \\text{not p}\\)\n\\(p ∨ q: \\text{p or q}\\)\n\\(p ∧ q: \\text{p and q}\\)\n\\(p → q: \\text{if p, then q}\\)\n\\(p ↔ q: \\text{p if and only if q}\\)\n\n\n\nSOLUTION\nDetermine the English sentences by replacing \\(\\text{p and q}\\) by their given sentences in the above interpretations (and adjust the sentence to form a proper English sentence as needed):\n\n\nIf I bought a lottery ticket this week, then I won the million dollar jackpot.\n\n\n\n\n\n(c) If I bought a lottery ticket this week, then I won the million-dollar jackpot.\n\n\n\n\n\nExercise 10d\n\n\nStep-1Step-2Results\n\n\nGiven:\n\np: I bought a lottery ticket this weekend.\nq: I won the million-dollar jackpot.\n\nInterpretation Symbols\n\n\\(¬p: \\text{not p}\\)\n\\(p ∨ q: \\text{p or q}\\)\n\\(p ∧ q: \\text{p and q}\\)\n\\(p → q: \\text{if p, then q}\\)\n\\(p ↔ q: \\text{p if and only if q}\\)\n\n\n\nSOLUTION\nDetermine the English sentences by replacing \\(\\text{p and q}\\) by their given sentences in the above interpretations (and adjust the sentence to form a proper English sentence as needed):\n\n\nI bought a lottery ticket this week and I won the million dollar jackpot.\n\n\n\n\n\n(d) I bought a lottery ticket this week and I won the million-dollar jackpot.\n\n\n\n\n\nExercise 10e\n\n\nStep-1Step-2Results\n\n\nGiven:\n\np: I bought a lottery ticket this weekend.\nq: I won the million-dollar jackpot.\n\nInterpretation Symbols\n\n\\(¬p: \\text{not p}\\)\n\\(p ∨ q: \\text{p or q}\\)\n\\(p ∧ q: \\text{p and q}\\)\n\\(p → q: \\text{if p, then q}\\)\n\\(p ↔ q: \\text{p if and only if q}\\)\n\n\n\nSOLUTION\nDetermine the English sentences by replacing \\(\\text{p and q}\\) by their given sentences in the above interpretations (and adjust the sentence to form a proper English sentence as needed):\n\n\nI bought a lottery ticket this week if and only if I won the million dollar jackpot.\n\n\n\n\n\n(e) I bought a lottery ticket this week if and only if I won the million-dollar jackpot.\n\n\n\n\n\nExercise 10f\n\n\nStep-1Step-2Results\n\n\nGiven:\n\np: I bought a lottery ticket this weekend.\nq: I won the million-dollar jackpot.\n\nInterpretation Symbols\n\n\\(¬p: \\text{not p}\\)\n\\(p ∨ q: \\text{p or q}\\)\n\\(p ∧ q: \\text{p and q}\\)\n\\(p → q: \\text{if p, then q}\\)\n\\(p ↔ q: \\text{p if and only if q}\\)\n\n\n\nSOLUTION\nDetermine the English sentences by replacing \\(\\text{p and q}\\) by their given sentences in the above interpretations (and adjust the sentence to form a proper English sentence as needed):\n\n\nIf I did not buy a lottery ticket this week, then I did not win the million dollar jackpot.\n\n\n\n\n\n(f) If I did not buy a lottery ticket this week, then I did not win the million-dollar jackpot.\n\n\n\n\n\nExercise 10g\n\n\nStep-1Step-2Results\n\n\nGiven:\n\np: I bought a lottery ticket this weekend.\nq: I won the million-dollar jackpot.\n\nInterpretation Symbols\n\n\\(¬p: \\text{not p}\\)\n\\(p ∨ q: \\text{p or q}\\)\n\\(p ∧ q: \\text{p and q}\\)\n\\(p → q: \\text{if p, then q}\\)\n\\(p ↔ q: \\text{p if and only if q}\\)\n\n\n\nSOLUTION\nDetermine the English sentences by replacing \\(\\text{p and q}\\) by their given sentences in the above interpretations (and adjust the sentence to form a proper English sentence as needed):\n\n\nI did not buy a lottery ticket this week and I did not win the million dollar jackpot.\n\n\n\n\n\n(g) I did not buy a lottery ticket this week and I did not win the million dollar jackpot.\n\n\n\n\n\nExercise 10h\n\n\nStep-1Step-2Results\n\n\nGiven:\n\np: I bought a lottery ticket this weekend.\nq: I won the million-dollar jackpot.\n\nInterpretation Symbols\n\n\\(¬p: \\text{not p}\\)\n\\(p ∨ q: \\text{p or q}\\)\n\\(p ∧ q: \\text{p and q}\\)\n\\(p → q: \\text{if p, then q}\\)\n\\(p ↔ q: \\text{p if and only if q}\\)\n\n\n\nSOLUTION\nDetermine the English sentences by replacing \\(\\text{p and q}\\) by their given sentences in the above interpretations (and adjust the sentence to form a proper English sentence as needed):\n\n\nI did not buy a lottery ticket this week and I did not win the million dollar jackpot.\n\n\n\n\n\n(h) I did not buy a lottery ticket this week or, I bought a lottery ticket this week and won the million dollar jackpot.",
    "crumbs": [
      "Discrete Math II"
    ]
  },
  {
    "objectID": "index.html#whats-inside",
    "href": "index.html#whats-inside",
    "title": "My Study Notes & Guides",
    "section": "✍️ What’s Inside",
    "text": "✍️ What’s Inside\n\n\n📚 Organized course notes and study guides\n🎥 Embedded videos and media\n🧠 Quick-reference guides\n🧪 Code examples and exercises",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "My Study Notes & Guides",
    "section": "🚀 Getting Started",
    "text": "🚀 Getting Started\n\n\n\n\n\n\nStart exploring by selecting a course or topic from the sidebar.\nOr jump straight into this course here:\n\n\n\nBegin Here »",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#contribute-or-feedback",
    "href": "index.html#contribute-or-feedback",
    "title": "My Study Notes & Guides",
    "section": "🙌 Contribute or Feedback",
    "text": "🙌 Contribute or Feedback\nThis project is personal, but feedback is welcome!\nFeel free to open an issue or follow my GitHub:\nGitHub Repository",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "courseD421.html#chapter-5",
    "href": "courseD421.html#chapter-5",
    "title": "Discrete Math II Functions and Applications",
    "section": "Chapter 5:",
    "text": "Chapter 5:\n\nExercise 5a\n\n\nStep-1Step-2Step-3\n\n\nDEFINITIONS\nThe negation of a statement states the opposite of the given statement.\n\n\nSOLUTION\n(a) The opposite of a statement can be obtained by adding “not” to the given statement. The opposite of Mei having an MP3 player is that Mei does not have an MP3 player.\n\n\n(a) Mei does not have an MP3 player.\n\n\n\n\nExercise 5b\n\n\nStep-1Step-2Step-3\n\n\nDEFINITIONS\nThe negation of a statement states the opposite of the given statement.\n\n\nSOLUTION\n(b) The opposite of no pollution in New Jersey is that there is pollution in New Jersey.\n\n\n(b) There is pollution in New Jersey.\n\n\n\n\nExercise 5c\n\n\nStep-1Step-2Step-3\n\n\nDEFINITIONS\nThe negation of a statement states the opposite of the given statement.\n\n\nSOLUTION\n(c) The opposite of an equality \\((=)\\) is a difference \\(\\text{(≠)   2+1 ≠ 3 }\\)\n\n\n(c) \\(2+1 ≠ 3\\)\n\n\n\n\nExercise 5d\n\n\nStep-1Step-2Step-3\n\n\nDEFINITIONS\nThe negation of a statement states the opposite of the given statement.\n\n\nSOLUTION\n(d) The opposite of a statement can be obtained by adding “not” to the given statement: The summer in Maine is not (hot and sunny).\n\n\n(d) The summer in Maine is not (hot and sunny).",
    "crumbs": [
      "Discrete Math II Functions and Applications"
    ]
  },
  {
    "objectID": "courseC949.html",
    "href": "courseC949.html",
    "title": "DSA I",
    "section": "",
    "text": "Explains Algorithms (29%)",
    "crumbs": [
      "DSA I"
    ]
  },
  {
    "objectID": "courseC949.html#explains-algorithms-29",
    "href": "courseC949.html#explains-algorithms-29",
    "title": "DSA I",
    "section": "",
    "text": "Characteristics of Algorithms\n\n\n\n\n\n\nNames\n\n\n\n\n\n\nFiniteness\nAn algorithm must always have a finite number of steps before it ends. When the operation is finished, it must have a defined endpoint or output and not enter an endless loop.\nDefiniteness\nAn algorithm needs to have exact definitions for each step. Clear and straightforward directions ensure that every step is understood and can be taken easily.\nInput\nAn algorithm requires one or more inputs. The values that are first supplied to the algorithm before its processing are known as inputs. These inputs come from a predetermined range of acceptable values.\nOutput\nOne or more outputs must be produced by an algorithm. The output is the outcome of the algorithm after every step has been completed. The relationship between the input and the result should be clear.\nEffectiveness\nAn algorithm’s stages must be sufficiently straightforward to be carried out in a finite time utilizing fundamental operations. With the resources at hand, every operation in the algorithm should be doable and practicable.\nGenerality\nRather than being limited to a single particular case, an algorithm should be able to solve a group of issues. It should offer a generic fix that manages a variety of inputs inside a predetermined range or domain.\n\n\n\n\n\nFactors of an Algorithm\n\n\n\n\n\n\nFactors\n\n\n\n\n\n\n**Modularity**\nThis feature was perfectly designed for the algorithm if you are given a problem and break it down into small-small modules or small-small steps, which is a basic definition of an algorithm.\nCorrectness\nAn algorithm’s correctness is defined as when the given inputs produce the desired output, indicating that the algorithm was designed correctly. An algorithm’s analysis has been completed correctly.\nMaintainability\nIt means that the algorithm should be designed in a straightforward, structured way so that when you redefine the algorithm, no significant changes are made to the algorithm.\nFunctionality\nIt takes into account various logical steps to solve a real-world problem.\nRobustness\nRobustness refers to an algorithm’s ability to define your problem clearly.\nUser-friendly\nIf the algorithm is difficult to understand, the designer will not explain it to the programmer.\nSimplicity\nIf an algorithm is simple, it is simple to understand.\n**Extensibility**\nYour algorithm should be extensible if another algorithm designer or programmer wants to use it.\n\n\n\n\n\n\nTypes of Algorithms\n\n\nType-1Type-2Type-3Type-4\n\n\n\n\n\n\n\n\n\n\n\n\n\nBrute Force Algorithm\nA straightforward approach that exhaustively tries all possible solutions, suitable for small problem instances but may become impractical for larger ones due to its high time complexity.\n\n\n\n\n\n\n\n\n\n\n\nRecursive Algorithm\nA method that breaks a problem into smaller, similar subproblems and repeatedly applies itself to solve them until reaching a base case, making it effective for tasks with recursive structures.\n\n\n\n\n\n\n\n\n\n\n\nEncryption Algorithm\nUtilized to transform data into a secure, unreadable form using cryptographic techniques, ensuring confidentiality and privacy in digital communications and transactions.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacktracking Algorithm\nA trial-and-error technique used to explore potential solutions by undoing choices when they lead to an incorrect outcome, commonly employed in puzzles and optimization problems.\n\n\n\n\n\n\n\n\n\n\n\nSearching Algorithm\nDesigned to find a specific target within a data set, enabling efficient retrieval of information from sorted or unsorted collections.\n\n\n\n\n\n\n\n\n\n\n\nSorting Algorithm\nAimed at arranging elements in a specific order, like numerical or alphabetical, to enhance data organization and retrieval.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHashing Algorithm\nConverts data into a fixed-size hash value, enabling rapid data access and retrieval in hash tables, commonly used in databases and password storage.\n\n\n\n\n\n\n\n\n\n\n\nDivide & Conquer Algorithm\nBreaks a complex problem into smaller subproblems, solves them independently, and then combines their solutions to address the original problem effectively.\n\n\n\n\n\n\n\n\n\n\n\nGreedy Algorithm\nMakes locally optimal choices at each step in the hope of finding a global optimum, useful for optimization problems but may not always lead to the best solution.\n\n\n\n\n\n\n\n\n\n\n\n\n\nDynamic Programming Algorithm\nStores and reuses intermediate results to avoid redundant computations, enhancing the efficiency of solving complex problems.\n\n\n\n\n\n\n\n\n\n\n\nRandomized Algorithm\nUtilizes randomness in its steps to achieve a solution, often used in situations where an approximate or probabilistic answer suffices.\n\n\n\n\n\n\nRecursive Algorithms\n\n\nAlgorithms\nRecursive algorithms are a fundamental concept in computer science, particularly in the study of data structures and algorithms. A recursive algorithm is one that solves a problem by breaking it down into smaller instances of the same problem, which it then solves in the same way. This process continues until the problem is reduced to a base case, which is solved directly without further recursion.\n\n\n\nKey Concepts\n\n\nBase CaseRecursive CaseStack\n\n\nThis is the condition under which the recursion stops. It represents the simplest instance of the problem, which can be solved directly without further recursion.\n\n\nThis is the part of the algorithm that breaks the problem down into smaller instances of the same problem and then calls the algorithm recursively on these smaller instances.\n\n\nEach recursive call is placed on the system call stack. When the base case is reached, the stack begins to unwind as each instance of the function returns its result.\n\n\n\n\n\n\nFactorial Calculation\n\nThe factorial of a number n (denoted as n!) is a classic example of a recursive algorithm. The factorial is defined as:\n\nO! = 1 (Base Case)\nN! = n * (n-1)! For n &gt; O (Recursive Case)\n\n\nCodeLogicPros/ConsUsage\n\n\n\ndef factorial(n):\n    if n == 0:  # Base Case\n        return 1\n    else:  # Recursive Case\n        return n * factorial(n - 1)\n\n\n\nHow It Works:\n\nBase Case: When n is 0, the function returns 1.\nRecursive Case: For any other value of n, the function calls itself with n−1 and multiplies the result by n.\n\nFor example, calling factorial(3) would work as follows:\n\nfactorial(3) calls factorial(2)\nfactorial(2) calls factorial(1)\nfactorial(1) calls factorial(0)\nfactorial(0) returns 1, then:\nfactorial(1) returns 1 * 1 = 1\nfactorial(2) returns 2 * 1 = 2\nfactorial(3) returns 3 * 2 = 6\n\n\n\nAdvantages of Recursion\n\nSimplicity: Recursive solutions are often more elegant and easier to understand than their iterative counterparts.\nDirect Translation: Some problems are naturally recursive, like tree traversals, making recursion the most straightforward approach.\n\nDisadvantages of Recursion\n\nPerformance: Recursive algorithms can be less efficient due to the overhead of multiple function calls and potential stack overflow issues for deep recursion.\nMemory Usage: Recursion can consume more memory because each function call adds a new frame to the call stack.\n\n\n\nWhen to Use Recursion - When a problem can naturally be divided into similar sub-problems (e.g., tree traversal, searching algorithms like binary search). - When the recursive solution is significantly simpler or more intuitive than an iterative one.\n\n\n\n\n\n\nLinear & Binary Search\n\nLinear search and binary search are two fundamental algorithms used to search for an element in a collection, like an array or a list. However, they differ significantly in how they approach the search and their efficiency.\n\n\nLinear Search\n\n\nConceptStepsUsage\n\n\n\nLinear search is the simplest search algorithm.\nIt works by sequentially checking each element of the array or list until the target element is found or the end of the collection is reached.\n\n\n\nAlgorithm:\n\nStart from the first element of the array.\nCompare the current element with the target element.\nIf they match, return the index of the element.\nIf they don’t match, move to the next element and repeat the process.\nIf the target element is not found by the end of the array, return a “not found” indication.\n\nTime Complexity: \\(O(n)\\), where n is the number of elements in the array. This is because in the worst case, the algorithm may need to check every element in the array.\n\n\nWhen to Use:\n\nWhen the array or list is small.\nWhen the array is unsorted.\nWhen simplicity is more important than performance.\n\n\ndef linear_search(arr, target):\n    for i in range(len(arr)):\n        if arr[i] == target:\n            return i\n    return -1  # Return -1 if the element is not found\n\n\n\n\n\n\n\nBinary Search\n\n\nConceptStepsUsageCompare\n\n\n\nBinary search is much more efficient than linear search but requires the array or list to be sorted.\nIt works by repeatedly dividing the search interval in half. If the target value is less than the middle element, the search continues in the left half, otherwise in the right half.\n\n\n\nAlgorithm:\n\nStart with two pointers, one at the beginning (low) and one at the end (high) of the sorted array.\nFind the middle element of the current interval.\nCompare the middle element with the target:\n\nIf they match, return the index of the middle element.\nIf the target is less than the middle element, repeat the search on the left half.\nIf the target is greater, repeat the search on the right half.\n\nIf the interval becomes invalid (low &gt; high), return a “not found” indication.\n\nTime Complexity: \\(\\text{O(log⁡ n)}\\), where n is the number of elements in the array. This logarithmic time complexity makes binary search significantly faster than linear search for large data sets.\n\n\nWhen to Use:\n\nWhen the array or list is sorted.\nWhen the array is large and efficiency is crucial.\n\n\ndef binary_search(arr, target):\n    low = 0\n    high = len(arr) - 1\n\n    while low &lt;= high:\n        mid = (low + high) // 2\n        if arr[mid] == target:\n            return mid\n        elif arr[mid] &lt; target:\n            low = mid + 1\n        else:\n            high = mid - 1\n\n    return -1  # Return -1 if the element is not found\n\n\n\nComparison\n\nEfficiency: Binary search is faster than linear search, especially for large data sets, but it requires the array to be sorted.\nSimplicity: Linear search is simpler to implement and doesn’t require the array to be sorted, making it more versatile for smaller or unsorted data sets.\nUse Cases:\n\nLinear Search: Suitable for small or unsorted collections where the simplicity of the algorithm outweighs the need for speed.\nBinary Search: Ideal for large, sorted collections where performance is a priority.\n\n\n\n\n\n\n\n\nStep-by-Step Guide\n\n\nArraysSetup1st Iteration2nd Iteration\n\n\nFiguring out the array elements that correspond to the mid-values in the first and second iterations of A binary search\n\\(\\text{ arr = {45, 77, 89, 90, 94, 99, 100} }\\) and \\(\\text{key = 100}\\)\n\n\n\nThe array arr is {45, 77, 89, 90, 94, 99, 100}.\nThe key to find is 100.\nInitialize two pointers: low (start of the array) and high (end of the array).\n\n\n\n\nCalculate the middle index mid using the formula: mid = (low + high) / 2\nCheck the value at arr[mid].\nCompare arr[mid] with the key:\n\nIf arr[mid] is less than key, update low to mid + 1.\nIf arr[mid] is greater than key, update high to mid - 1.\nIf arr[mid] is equal to key, you have found the key (though you won’t need a second iteration in this case).\n\n\n\n\n\nRepeat the calculation for mid with the updated low and high values.\nAgain, compare arr[mid] with the key and update low or high accordingly.\n\n\n\n\n\n\n\n\nSearching Algorithms\n\nLinear Search\n\n\n\nLogicUsageStates\n\n\n\nConcept: As discussed earlier, linear search involves checking each element in a list or array sequentially until the target element is found or the end of the collection is reached.\nTime Complexity: \\(O(n)\\), where n is the number of elements.\n\n\n\n\nUse Case: Best used when the list is small or unsorted.\nDistinct Characteristics:\n\nSimple, sequential search.\nChecks each element one by one.\nWorks on both sorted and unsorted data.\n\n\n\n\n\nLinear Search Worst, Average and Best\n\n**Best Case:** $O(1)$ — The target element is the first element.\n**Average Case:** $O(n)$ — The target element is somewhere in the middle or not in the array.\n**Worst Case:** $O(n)$ — The target element is the last element or not present.\n\n\n\n\n\n\n\n\nBinary Search\n\n\n\nLogicUsageStates\n\n\n\nConcept: Binary search operates on a sorted list. It repeatedly divides the search interval in half until the target element is found or the interval is empty.\nTime Complexity: \\(\\text{O(log⁡ n)}\\)\n\n\n\n\nUse Case: Ideal for large, sorted datasets.\nDistinct Characteristics:\n\nRequires a sorted array.\nDivides the search interval in half repeatedly.\nEfficient, logarithmic time complexity.\n\n\n\n\n\nBinary Search Worst, Average and Best\n\nBest Case: \\(O(1)\\) — The target element is the middle element.\nAverage Case: \\(\\text{O(log⁡ n)}\\) — The target element is not immediately found but within the sorted array.\nWorst Case: \\(\\text{O(log⁡ n)}\\) — The target element is at the extreme ends or not present.\n\n\n\n\n\n\n\n\nInterpolation Search\n\n\n\nLogicUsageStates\n\n\n\nConcept: Similar to binary search but works on uniformly distributed data. It estimates the position of the target element based on the value.\nTime Complexity: O(log ⁡log ⁡n) in the best case, \\(O(n)\\) in the worst case.\n\n\n\n\nUse Case: Effective when the data is uniformly distributed.\n\n\n\n\nInterpolation Search Worst, Average and Best\n\nBest Case: \\(O(1)\\) — The target element is exactly where the interpolation suggests.\nAverage Case: \\(\\text{O(log ⁡log⁡ n)}\\) — Uniformly distributed data.\nWorst Case: \\(O(n)\\) — Highly skewed data distribution or worst interpolation.\n\n\n\n\n\n\n\n\nDFS/BFS\n\n\n\nLogicUsageStates\n\n\n\nConcept: Used primarily in graph and tree data structures. Depth-First Search (DFS) explores as far as possible along one branch before backtracking, while Breadth-First Search (BFS) explores all neighbors at the present depth before moving on to nodes at the next depth level.\nTime Complexity: \\(\\text{O(V + E)}\\), where V is the number of vertices and E is the number of edges.\n\n\n\n\nUse Case: Useful for searching nodes in graphs and trees.\n\n\n\n\n(DFS)\n\nBest Case: \\(O(1)\\) — The target node is found immediately.\nAverage Case: \\(\\text{O(V + E)}\\)— Typically when all nodes and edges must be explored.\nWorst Case: \\(\\text{O(V + E)}\\) — The target node is the last one discovered.\n\n(BFS)\n\nBest Case: \\(O(1)\\) — The target node is the root or the first node checked.\nAverage Case: \\(\\text{O(V + E)}\\) — All nodes and edges need to be explored.\nWorst Case: \\(\\text{O(V + E)}\\) — The target node is the last one explored.\n\n\n\n\n\n\n\n\n\nSorting Algorithms\nSorting algorithms organize data in a particular order (usually ascending or descending). This makes searching and other operations more efficient.\n\n\nBubble Sort\n\n\n\nUsageDescriptorStatesTips\n\n\n\nUse Case: Simple but inefficient for large datasets. Best used for educational purposes or small lists.\n\n\n\n\nDistinct Characteristics:\n\nRepeatedly swaps adjacent elements if they are in the wrong order.\nSimple, but inefficient for large datasets.\n“Bubbles” the largest element to the end of the list.\n\n\n\n\n\nBubble Sort Worst, Average and Best\n\nBest Case: \\(O(n)\\) — The array is already sorted (with an optimized version that stops early).\nAverage Case: \\(O(n^2)\\) — Average case with random elements.\nWorst Case: \\(O(n^2)\\) — The array is sorted in reverse order.\n\n\n\n\n\nBubble: Look for something that swaps so the result can “bubble” to the top. (Swap, Exchange)\n\n\n\n\n\n\n\nSelection Sort\n\n\n\nUsageDescriptorStatesTips\n\n\n\nUse Case: Inefficient for large lists, but useful when memory writes are more expensive than comparisons.\n\n\n\n\nDistinct Characteristics:\n\nFinds the minimum element and swaps it with the first unsorted element.\nReduces the problem size by one in each iteration.\nAlways performs \\(O(n^2)\\) comparisons, regardless of input.\n\n\n\n\n\nSelection Sort Worst, Average and Best\n\nBest Case: \\(O(n^2)\\) — Selection sort does not improve with better input, always \\(O(n^2)\\).\nAverage Case: \\(O(n^2)\\) — Average case with random elements.\nWorst Case: \\(O(n^2)\\) — Selection sort is insensitive to input order.\n\n\n\n\n\nSelection: Look for code that repeatedly finds the minimum (or maximum) element and moves it to the beginning (or end) of the list. (Select minimum, Swap with start)\n\n\n\n\n\n\n\nInsertion Sort\n\n\n\nUsageDescriptorStatesTips\n\n\n\nUse Case: Good for small or nearly sorted lists.\n\n\n\n\nDistinct Characteristics:\n\nBuilds a sorted list one element at a time.\nEfficient for small or nearly sorted datasets.\nShifts elements to make space for the current element.\n\n\n\n\n\nInsertion Sort Worst, Average and Best\n\nBest Case: \\(O(n)\\) — The array is already sorted.\nAverage Case: \\(O(n^2)\\) — Average case with random elements.\nWorst Case: \\(O(n^2)\\) — The array is sorted in reverse order.\n\n\n\n\n\nInsertion: Look for code that builds a sorted portion of the list one element at a time by inserting each new element into its correct position within the already-sorted part. (Insert, Shift Element)\n\n\n\n\n\n\n\nMerge Sort\n\n\n\nUsageDescriptorStatesTips\n\n\n\nUse Case: Efficient and stable; good for large datasets.\n\n\n\n\nDistinct Characteristics:\n\nDivides the list into halves, sorts each half, and then merges them.\nStable and efficient for large datasets.\nRequires additional space for merging.\n\n\n\n\n\nMerge Sort Worst, Average and Best\n\nBest Case: \\(\\text{O(n ⁡log⁡ n)}\\) — Merge sort’s time complexity is the same in all cases.\nAverage Case: \\(\\text{O(n ⁡log⁡ n)}\\).\nWorst Case: \\(\\text{O(n ⁡log⁡ n)}\\).\n\n\n\n\n\nMerge: Look for something that continually splits a list in half. (Merge, Split)\n\n\n\n\n\n\n\nQuicksort\n\n\n\nUsageDescriptorStatesTips\n\n\n\nUse Case: Often faster in practice than merge sort but less stable.\n\n\n\n\nDistinct Characteristics:\n\nSelects a “pivot” element and partitions the array around it.\nRecursively sorts the partitions.\nEfficient, but can degrade to \\(O(n^2)\\) if poor pivot selection occurs.\n\n\n\n\n\nQuicksort Worst, Average and Best\n\nBest Case: \\(\\text{O(n ⁡log⁡ n)}\\) — The pivot splits the array into two nearly equal halves.\nAverage Case: \\(\\text{O(n ⁡log⁡ n)}\\) — Average case with random pivots.\nWorst Case: \\(O(n^2)\\) — The pivot is always the smallest or largest element, leading to unbalanced partitions.\n\n\n\n\n\nQuicksort: Look for the keywords “pivot” and/or “split”. (Pivot, Split)\n\n\n\n\n\n\n\nHeap Sort\n\n\n\nUsageDescriptorStatesTips\n\n\n\nUse Case: Useful when memory usage is a concern as it’s an in-place algorithm.\n\n\n\n\nDistinct Characteristics:\n\nUtilizes a binary heap data structure.\nBuilds a max-heap and repeatedly extracts the maximum element.\nEfficient and in-place, but not stable.\n\n\n\n\n\nHeap Sort Worst, Average and Best\n\nBest Case: \\(\\text{O(n ⁡log⁡ n)}\\) — Heap sort’s time complexity is the same in all cases.\nAverage Case: \\(\\text{O(n ⁡log⁡ n)}\\).\nWorst Case: \\(\\text{O(n ⁡log⁡ n)}\\).\n\n\n\n\n\nHeap Sort: Look for code that uses a heap data structure to repeatedly extract the maximum (or minimum) element and rebuilds the heap. (Heapify, Extract Max, Build Heap)\n\n\n\n\n\n\n\nCounting Sort\n\n\n\nUsageDescriptorStates\n\n\n\nUse Case: Efficient for sorting integers or other items with a small range of possible values.\n\n\n\n\nDistinct Characteristics:\n\nNon-comparative sorting.\nCounts occurrences of each element and uses this information to place elements.\nEfficient for small ranges of integers.\n\n\n\n\n\nCounting Sort Worst, Average and Best\n\nBest Case: \\(\\text{O(n ⁡+ k) - k}\\) is the range of the input.\nAverage Case: \\(\\text{O(n ⁡+ k)}\\).\nWorst Case: \\(\\text{O(n ⁡+ k)}\\).\n\n\n\n\n\n\n\n\nRadix Sort\n\n\n\nUsageDescriptorStatesTips\n\n\n\nUse Case: Effective for sorting large numbers or strings with a fixed length.\n\n\n\n\nDistinct Characteristics:\n\nSorts numbers by processing individual digits.\nNon-comparative, stable, and efficient for specific data types.\nOften combined with counting sort.\n\n\n\n\n\nRadix Sort Worst, Average and Best\n\nBest Case: \\(\\text{O(n ⁡* k)}\\) — k is the number of digits in the largest number.\nAverage Case: \\(\\text{O(n ⁡* k)}\\).\nWorst Case: \\(\\text{O(n ⁡* k)}\\).\n\n\n\n\n\nRadix Sort: Look for code that sorts numbers based on their individual digits, starting from the least significant digit (LSD) or the most significant digit (MSD). (Count, Frequency, Sum)\n\n\n\n\n\n\n\nBucket Sort\n\n\n\nUsageDescriptorStatesTips\n\n\n\nUse Case: Good for uniformly distributed data.\n\n\n\n\nDistinct Characteristics:\n\nDistributes elements into buckets and sorts each bucket individually.\nEfficient when the input is uniformly distributed.\nOften combined with another sorting algorithm like insertion sort.\n\n\n\n\n\nBucket Sort Worst, Average and Best\n\nBest Case: \\(\\text{O(n + k)}\\) — k is the number of buckets; assumes uniform distribution.\nAverage Case: \\(\\text{O(n + k)}\\).\nWorst Case: \\(O(n^2)\\) — All elements end up in one bucket (degenerate case).\n\n\n\n\n\nBucket: Look for something that distributes the values into “buckets” where they are individually sorted. (Bucket)\n\n\n\n\n\n\n\nShell Sort\n\n\n\nDescriptorStatesTips\n\n\n\nDistinct Characteristics:\n\nGeneralization of insertion sort with a gap sequence.\nSorts elements far apart and gradually reduces the gap.\nEfficient for medium-sized datasets.\nTime Complexity: Depends on the gap sequence; commonly \\(\\text{O(n3/2)}\\).\n\n\n\n\n\nShell Sort Worst, Average and Best\n\nBest Case: \\(\\text{O(n log n)}\\) — Occurs when the array is already sorted or nearly sorted, especially when using a good gap sequence like the Knuth sequence.\nAverage Case: \\(O(n^(3/2))\\) or \\(O(n^1.5)\\) — Highly dependent on the gap sequence used. With commonly used sequences like the Knuth sequence, the average-case complexity is approximately \\(O(n^1.5)\\).\nWorst Case: \\({O(n^2)}\\) — Can degrade to \\({O(n^2)}\\), particularly with poorly chosen gap sequences like the original Shell sequence (where the gaps are halved each time)\n\n\n\n\n\nShell Sort: Look for code that sorts elements at specific intervals and gradually reduces the interval until it performs a final insertion sort. (Gap, Interval)\n\n\n\n\n\n\n\n\nSummary\n\n\n\n\n\n\n\n\nSearching & Sorting Algorithms\n\n\n\n\n\n\nLinear Search: Simple, sequential; \\(O(n)\\).\nBinary Search: Sorted data, divide and conquer; \\(\\text{O(log n)}\\).\nBubble Sort: Swaps, bubbles up; \\(O(n^2)\\).\nSelection Sort: Finds minimum, swaps; \\(O(n^2)\\).\nInsertion Sort: Builds sorted list, shifts; \\(O(n^2)\\), \\(O(n)\\) best case.\nMerge Sort: Divide and conquer, merge; \\(\\text{O(n log n)}\\).\nQuick Sort: Pivot, partition; \\(\\text{O(n log n)}\\) average, \\(O(n^2)\\) worst case.\nHeap Sort: Max-heap, extract max; \\(\\text{O(n log n)}\\).\nCounting Sort: Counts occurrences, non-comparative; \\(\\text{O(n + k)}\\).\nRadix Sort: Sorts by digits, non-comparative; \\(O(nk)\\).\nBucket Sort: Distributes into buckets, sorts; \\(\\text{O(n + k)}\\).\nShell Sort: Gap sequence, insertion-like; \\(O(n^3/2)\\).\n\n\n\n\n\n\n\n\n\n\nKey Observations\n\n\n\n\n\n\nBubble Sort, Selection Sort, and Insertion Sort: These are simple but inefficient for large datasets, especially in the worst case.\nMerge Sort and Heap Sort: Stable and consistent in performance, regardless of the input.\nQuick Sort: Very efficient on average but can degrade to \\(O(n^2)\\) in the worst case without proper pivot selection.\nCounting Sort, Radix Sort, and Bucket Sort: Efficient for specific types of data (e.g., integers within a fixed range) but less versatile.\n\n\n\n\n\n\n\n\n\n\nChoosing the Right Algorithm\n\n\n\n\n\n\nSmall datasets: Simpler algorithms like bubble sort, selection sort, or insertion sort might suffice.\nLarge datasets: More efficient algorithms like merge sort, quick sort, or heap sort are preferred.\nSorted data: Algorithms like insertion sort can be very efficient.\nSpecial conditions: Use counting sort, radix sort, or bucket sort if the data is within a certain range or has other specific properties.\n\n\n\n\n\n\n\n\n\nBig O Notation\nWhat is Big O Notation?\n\nBig O Notation: It provides an upper bound on the time or space complexity of an algorithm, representing the worst-case scenario. It’s a way to describe the efficiency of an algorithm as the input size grows towards infinity.\n\nWhy Use Big O Notation?\n\nComparing Algorithms: It allows us to compare the efficiency of different algorithms independently of hardware or other environmental factors.\nScalability: It helps us understand how an algorithm will perform as the size of the input data grows.\n\n\n\nO Notations\n\n\n\n\n\n\n\nCommon Big Os\n\n\n\n\n\n\nO(1) - Constant Time:\n\nDescription: The algorithm takes the same amount of time to execute regardless of the size of the input.\nExample: Accessing an element in an array by index.\nEfficiency: Excellent.\n\nO(log n) - Logarithmic Time:\n\nDescription: The runtime increases logarithmically as the input size increases. Typically occurs in algorithms that halve the problem size at each step, like binary search.\nExample: Binary search.\nEfficiency: Very good for large inputs.\n\nO(n) - Linear Time:\n\nDescription: The runtime increases linearly with the size of the input. If you double the input size, the runtime also doubles.\nExample: Linear search, iterating through a list.\nEfficiency: Reasonable for moderate to large inputs.\n\nO(n log n) - Log-Linear Time:\n\nDescription: The runtime increases more than linearly but less than quadratically. Common in efficient sorting algorithms like merge sort and quicksort.\nExample: Merge sort, quicksort, heap sort.\nEfficiency: Efficient for large inputs.\n\nO(n^2) - Quadratic Time:\n\nDescription: The runtime increases quadratically with the size of the input. If you double the input size, the runtime quadruples.\nExample: Bubble sort, insertion sort, selection sort (for unsorted arrays).\nEfficiency: Poor for large inputs.\n\nO(2n) - Exponential Time:\n\nDescription: The runtime doubles with each additional element in the input. Common in algorithms that solve problems by brute force or explore all possible solutions.\nExample: Recursive algorithms for the Fibonacci sequence, certain dynamic programming problems.\nEfficiency: Very poor, impractical for large inputs.\n\nO(n!) - Factorial Time:\n\nDescription: The runtime increases factorially with the size of the input. Common in algorithms that generate all permutations of an input set.\nExample: Traveling salesman problem via brute force.\nEfficiency: Extremely poor, infeasible for even moderate input sizes.\n\n\n\n\n\n\n\n\n\n\n\nTime Complexity\n\n\n\n\n\nBest Case, Worst Case, and Average Case\n\nBest Case: The scenario where the algorithm performs the minimum possible number of operations. It’s often less relevant because it’s optimistic.\n\nExample: For linear search, the best case is \\(O(1)\\), where the target element is the first one in the array.\n\nWorst Case: The scenario where the algorithm performs the maximum possible number of operations. Big O notation typically describes the worst-case complexity.\n\nExample: For linear search, the worst case is \\(O(n)\\), where the target element is the last one in the array or isn’t present at all.\n\nAverage Case: The scenario that represents the expected number of operations for a typical input. It’s more complex to calculate because it depends on the distribution of inputs.\n\nExample: For linear search, the average case is \\(O(n/2)\\), but in Big O notation, we simplify this to \\(O(n)\\).\n\n\n\n\n\n\n\n\n\n\n\nCalculation Rules\n\n\n\n\n\nIgnore Constants:\n\nRule: In Big O notation, constant factors are ignored.\nWhy: Big O notation focuses on the growth rate as the input size \\((n)\\) increases, so a constant multiplier doesn’t affect the growth rate.\nExample: \\(O(2n)\\) simplifies to \\(O(n)\\)\n\nFocus on the Dominant Term:\n\nRule: Only the term with the highest growth rate is considered.\nWhy: As n becomes large, the term with the highest growth rate will dominate the others.\nExample: \\(O(n2+n)\\) simplifies to \\(O(n2)\\)\n\nDrop Lower Order Terms:\n\nRule: Lower-order terms are ignored because they become insignificant as n grows.\nWhy: Similar to focusing on the dominant term, lower-order terms have a negligible impact on large inputs.\nExample: \\(O(n2 + n + log n)\\) simplifies to \\(O(n2)\\)\n\nMultiplicative Constants Can Be Ignored: - Rule: Coefficients that multiply variables (e.g., 2n, 3n^2) are ignored. - Why: Like constants, they don’t change the growth rate. - Example: \\(O(3n2)\\) simplifies to \\(O(n2)\\)\nAdditive Constants Can Be Ignored:\n\nRule: Constant terms that don’t depend on n are ignored.\nWhy: They don’t affect the overall growth rate as n increases.\nExample: \\(O(n+10)\\) simplifies to \\(O(n)\\)\n\nLogarithms with Different Bases:\n\nRule: Logarithms with different bases can be considered equivalent in Big O notation.\nWhy: Changing the base of a logarithm only introduces a constant factor, which is ignored in Big O notation.\nExample: \\(\\text{O(log⁡2 n)}\\) simplifies to \\(\\text{O(log⁡ n)}\\)\n\nNon-Dominant Polynomial Terms:\n\nRule: In polynomials, only the highest degree term is considered.\nWhy: As n grows large, the highest degree term will dominate.\nExample: \\(\\text{O(5n3 + 2n2 + 7)}\\) simplifies to \\(O(n3)\\)\n\nExponential Growth:\n\nRule: Exponential growth functions dominate polynomial functions.\nWhy: Exponential functions grow much faster than polynomial functions as n increases.\nExample: \\(\\text{O(2n + n3)}\\) simplifies to \\(O(2n)\\)\n\nNested Loops:\n\nRule: The time complexity of nested loops is the product of the complexities of each loop.\nWhy: Each loop iterates based on the input size, so their combined effect is multiplicative.\nExample: A loop inside another loop both running n times results in \\(\\text{O(n * n) = O(n2)}\\)\n\nSequential Statements:\n\nRule: If two independent statements (or loops) are executed sequentially, their time complexities are added.\nWhy: Sequential operations don’t multiply time complexity, but rather add up.\nExample: Two loops each running n times sequentially result in \\(\\text{O(n + n) = O(n)}\\)",
    "crumbs": [
      "DSA I"
    ]
  },
  {
    "objectID": "courseD493.html",
    "href": "courseD493.html",
    "title": "Scripting & Programming",
    "section": "",
    "text": "Scripting & Programming - Applications (D493)\n\n\n\nBool:\nAn integer type whose value can be either true or false.\n\nbool is_even(int x) {\n return x%2 == 0;\n}\nconst bool b = is_even(47); // false",
    "crumbs": [
      "Scripting & Programming"
    ]
  },
  {
    "objectID": "courseD495.html",
    "href": "courseD495.html",
    "title": "Big Data",
    "section": "",
    "text": "Big Data Foundations (D495)\n\n\n\ncoming soon",
    "crumbs": [
      "Big Data"
    ]
  },
  {
    "objectID": "courseC949.html#characteristics-of-algorithms",
    "href": "courseC949.html#characteristics-of-algorithms",
    "title": "Data Structures and Algorithms I",
    "section": "Characteristics of Algorithms",
    "text": "Characteristics of Algorithms\n\n\n\n\n\n\nNames\n\n\n\n\n\nFiniteness\nAn algorithm must always have a finite number of steps before it ends. When the operation is finished, it must have a defined endpoint or output and not enter an endless loop.\nDefiniteness\nAn algorithm needs to have exact definitions for each step. Clear and straightforward directions ensure that every step is understood and can be taken easily.\nInput\nAn algorithm requires one or more inputs. The values that are first supplied to the algorithm before its processing are known as inputs. These inputs come from a predetermined range of acceptable values.\nOutput\nOne or more outputs must be produced by an algorithm. The output is the outcome of the algorithm after every step has been completed. The relationship between the input and the result should be clear.\nEffectiveness\nAn algorithm’s stages must be sufficiently straightforward to be carried out in a finite time utilizing fundamental operations. With the resources at hand, every operation in the algorithm should be doable and practicable.\nGenerality\nRather than being limited to a single particular case, an algorithm should be able to solve a group of issues. It should offer a generic fix that manages a variety of inputs inside a predetermined range or domain.",
    "crumbs": [
      "Data Structures and Algorithms I"
    ]
  },
  {
    "objectID": "courseC949.html#factors-of-an-algorithm",
    "href": "courseC949.html#factors-of-an-algorithm",
    "title": "Data Structures and Algorithms I",
    "section": "Factors of an Algorithm",
    "text": "Factors of an Algorithm\nFactors",
    "crumbs": [
      "Data Structures and Algorithms I"
    ]
  },
  {
    "objectID": "courseC949.html#determines-data-structure-impact---31",
    "href": "courseC949.html#determines-data-structure-impact---31",
    "title": "DSA I",
    "section": "Determines Data Structure Impact - (31%)",
    "text": "Determines Data Structure Impact - (31%)\n\nImplementation of Data Structures\n\n\nData Types\n\n\n\nDefinitionExamplesExtra\n\n\nWhat is a Data Type?\nDefinition: A data type is a classification that specifies the type of data that a variable can hold in programming. It defines the operations that can be performed on the data and the way the data is stored in memory.\n\n\n\nPrimitive Data Types: These are the basic building blocks of data in a programming language.\n\nInteger (e.g., int in C, Java): Holds whole numbers.\nFloating Point (e.g., float, double): Holds numbers with fractional parts.\nCharacter (e.g., char): Holds a single character.\nBoolean (e.g., bool): Holds a true or false value.\n\nComposite Data Types: These are constructed from primitive types.\n\nArrays: A collection of elements of the same data type.\nStructures (e.g., struct in C): A collection of different data types.\n\nUser-Defined Data Types: Created by the user, typically by combining primitive data types.\n\nEnumerations (enum), Classes, etc.\n\n\n\n\nEnumeration:\n\nEnumeration, often referred to as “enum,” is a data type in programming that allows a variable to be a set of predefined constants.\nThese constants are typically related and represent a set of possible values that a variable of the enumeration type can hold.\nEnums improve code readability, make it easier to manage sets of related values, and reduce errors by limiting the values a variable can take.\n\nKey Concepts of Enumeration:\n\nDefinition: An enumeration is defined using the enum keyword (syntax can vary by language). It consists of a set of named constants, each representing a unique value.\nValues: The values in an enum are usually integers by default, starting from 0, but they can be assigned specific values as needed.\nUsage: Enums are commonly used when a variable can only take one out of a small set of possible values, like days of the week, directions, states, etc.\n\nExample in Different Languages:\nC/C++\n\nenum Direction {\n    NORTH,\n    EAST,\n    SOUTH,\n    WEST\n};\n\nDirection dir = NORTH;\n\nJava\n\npublic enum Direction {\n    NORTH,\n    EAST,\n    SOUTH,\n    WEST\n}\n\nDirection dir = Direction.NORTH;\n\nPython (using enum module)\n\nfrom enum import Enum\n\nclass Direction(Enum):\n    NORTH = 1\n    EAST = 2\n    SOUTH = 3\n    WEST = 4\n\ndir = Direction.NORTH\n\nAdvantages of Using Enums: - Readability: Code is easier to read and understand. - Maintainability: Easier to update and maintain related values. - Type Safety: Prevents assigning invalid values to variables of the enum type.\nEnums are useful in scenarios where a variable should only be allowed to take one out of a small set of specific values, helping prevent errors and making the code clearer and more reliable.\nKey Characteristics: - Memory Allocation: Data types determine how much memory is allocated for storing the data. - Operations: Each data type supports a set of operations, like arithmetic operations for integers or concatenation for strings.\n\n\n\n\n\n\nData Structures\n\n\n\nDefinitionExamples\n\n\nWhat is a Data Structure?\n\nDefinition: A data structure is a specific way of organizing and storing data in a computer so that it can be accessed and modified efficiently. Data structures use data types as their underlying foundation.\n\n\n\n\nArrays: A collection of elements stored in contiguous memory locations.\nLinked Lists: A series of connected nodes, where each node contains data and a reference to the next node.\nStacks: A collection of elements with Last-In-First-Out (LIFO) access.\nQueues: A collection of elements with First-In-First-Out (FIFO) access.\nTrees: A hierarchical structure with a root element and sub-elements called nodes.\nGraphs: A collection of nodes (vertices) connected by edges.\nHash Tables: A data structure that maps keys to values for efficient lookup.\n\n\n\n\n\n\n\nAbstract Data Types (ADTs)\n\n\n\nDefinitionExamples\n\n\n\nDefinition: An abstract data type (ADT) is a theoretical model of a data structure that defines the behavior from the user’s point of view, without specifying the underlying implementation. It specifies the operations that can be performed and the expected behavior but not how these operations are carried out.\n\n\n\n\nList ADT: Operations include insertion, deletion, and access by index.\nStack ADT: Operations include push, pop, and peek.\nQueue ADT: Operations include enqueue and dequeue.\nMap (or Dictionary) ADT: Operations include inserting, deleting, and searching for key-value pairs.\n\n\n\n\n\n\n\nDifferences\n\n\n\n1. Abstraction2. Purpose3. Implementation4. Examples\n\n\n\nData Types: The most basic level; concerned with how data is stored and what operations are allowed.\nData Structures: A step higher in abstraction; concerned with how data is organized and accessed.\nADTs: The highest level of abstraction; concerned with the operations and behavior of a data structure, abstracted away from the implementation details.\n\n\n\n\nData Types: Define the type and nature of the data.\nData Structures: Provide a way to organize and manage data efficiently.\nADTs: Define a blueprint for data structures, focusing on what operations can be performed and what their expected behavior is.\n\n\n\n\nData Types: Directly supported by the programming language.\nData Structures: Built using data types and can be complex.\nADTs: Can be implemented using various data structures; the choice of implementation depends on the specific needs like performance and memory usage.\n\n\n\n\nData Types: int, float, char, bool\nData Structures: Arrays, linked lists, trees, hash tables\nADTs: Stack, queue, list, set, map\n\n\n\n\n\n\n\nArray\n\n\n\n1. Description2. Operations3. Usage\n\n\n\nAn array is a collection of homogeneous elements stored in contiguous memory locations. Each element in the array can be accessed using its index.\nPython Equivalent: list\n\n\n\n\nAccess: O(1) — Direct access to elements via index.\nSearch:\n\nLinear Search: O(n)\nBinary Search: O(log⁡ n) (only if the array is sorted)\n\nInsertion:\n\nAt the End: Append the element to the end of the array. If the array is full (fixed size), you may need to resize it.\n\nTime Complexity: O(1) (amortized if resizing is needed).\n\nAt a Specific Index: Shift elements to the right from the index to create space, then insert the new element.\n\nTime Complexity: O(n), where n is the number of elements after the insertion point.\n\n\nDeletion:\n\nFrom the End: Remove the last element.\n\nTime Complexity: O(1).\n\nFrom a Specific Index: Shift elements to the left to fill the gap left by the removed element.\n\nTime Complexity: O(n), where n is the number of elements after the removal point.\n\n\n\n\n\n\nUse Cases:\n\nSuitable for scenarios where fast access to elements is required, and the size of the data set is known.\n\n\n\n\n\n\n\n\nLinked List\n\n\n\nDescriptionTypesOperationsUsage\n\n\n\nA linked list is a linear collection of elements called nodes, where each node contains data and a reference (or pointer) to the next node in the sequence.\nPython Equivalent: Custom class with Node and LinkedList classes\n\n\n\n\nSingly Linked List: Each node points to the next node.\nDoubly Linked List: Each node points to both the next and previous nodes.\nCircular Linked List: The last node points back to the first node, forming a loop.\n\n\n\n\nAccess: O(n) — Requires traversal from the head to the desired node.\nSearch: O(n) — Requires traversal to find the target element.\nInsertion:\n\nAt the Beginning (Singly/ Doubly Linked List): Create a new node and adjust the head (and possibly tail in a doubly linked list).\n\nTime Complexity: O(1).\n\nAt the End (Singly Linked List): Traverse to the last node, then insert the new node.\n\nTime Complexity: O(n).\n\nAt a Specific Position: Traverse to the position and insert the node, adjusting the pointers.\n\nTime Complexity: O(n).\n\n\nDeletion:\n\nFrom the Beginning: Adjust the head pointer to the next node.\n\nTime Complexity: O(1).\n\nFrom the End: Traverse to the second last node, adjust its pointer to null.\n\nTime Complexity: O(n).\n\nFrom a Specific Position: Traverse to the node before the one to remove, then adjust pointers to bypass the removed node.\n\nTime Complexity: O(n).\n\n\n\n\n\n\nUse Cases:\n\nUseful when the size of the data set is unknown or when frequent insertions and deletions are required.\n\n\n\n\n\n\n\n\nMethods for Lists/Arrays\n\n\n\nI …II …III …IV …V …\n\n\n\nappend()\n\nDescription: Adds an element to the end of the list.\nSyntax: list.append(element)\n\n\nExample:\n\nfruits = [\"apple\", \"banana\"]\nfruits.append(\"orange\")\nprint(fruits)  # Output: ['apple', 'banana', 'orange']\n\n['apple', 'banana', 'orange']\n\n\n\nextend()\n\nDescription: Extends the list by appending elements from another iterable (e.g., another list).\nSyntax: list.extend(iterable)\n\n\nExample:\n\nnumbers = [1, 2, 3]\nnumbers.extend([4, 5])\nprint(numbers)  # Output: [1, 2, 3, 4, 5]\n\n[1, 2, 3, 4, 5]\n\n\n\n\n\ninsert() - Description: Inserts an element at a specific index in the list. - Syntax: list.insert(index, element)\nExample:\n\nfruits = [\"apple\", \"banana\"]\nfruits.insert(1, \"orange\")\nprint(fruits)  # Output: ['apple', 'orange', 'banana']\n\n['apple', 'orange', 'banana']\n\n\n\nremove()\n\nDescription: Removes the first occurrence of a specified value from the list.\nSyntax: list.remove(element)\n\n\nExample:\n\nfruits = [\"apple\", \"banana\", \"orange\"]\nfruits.remove(\"banana\")\nprint(fruits)  # Output: ['apple', 'orange']\n\n['apple', 'orange']\n\n\n\n\n\n\npop()\n\nDescription: Removes and returns the element at the specified index. If no index is specified, it removes and returns the last element.\nSyntax: list.pop(index)\n\n\nExample:\n\nfruits = [\"apple\", \"banana\", \"orange\"]\nlast_fruit = fruits.pop()\nprint(last_fruit)  # Output: 'orange'\n\norange\n\nprint(fruits)      # Output: ['apple', 'banana']\n\n['apple', 'banana']\n\n\n\nindex()\n\nDescription: Returns the index of the first occurrence of a specified value.\nSyntax: list.index(element, start, end)\n\n\nExample:\n\nfruits = [\"apple\", \"banana\", \"orange\"]\nindex_of_banana = fruits.index(\"banana\")\nprint(index_of_banana)  # Output: 1\n\n1\n\n\n\n\n\n\ncount()\n\nDescription: Returns the number of occurrences of a specified value in the list.\nSyntax: list.count(element)\n\n\nExample:\n\nfruits = [\"apple\", \"banana\", \"orange\", \"banana\"]\ncount_of_banana = fruits.count(\"banana\")\nprint(count_of_banana)  # Output: 2\n\n2\n\n\n\nsort()\n\nDescription: Sorts the elements of the list in ascending order (or descending order if specified) in place.\nSyntax: list.sort(reverse=False)\n\n\nExample:\n\nnumbers = [3, 1, 4, 1, 5, 9]\nnumbers.sort()\nprint(numbers)  # Output: [1, 1, 3, 4, 5, 9]\n\n[1, 1, 3, 4, 5, 9]\n\n\n\n\n\n\nreverse()\n\nDescription: Reverses the elements of the list in place.\nSyntax: list.reverse()\n\n\nExample:\n\nnumbers = [1, 2, 3, 4]\nnumbers.reverse()\nprint(numbers)  # Output: [4, 3, 2, 1]\n\n[4, 3, 2, 1]\n\n\n\ncopy()\n\nDescription: Returns a shallow copy of the list.\nSyntax: list.copy()\n\n\nExample:\n\nfruits = [\"apple\", \"banana\", \"orange\"]\nfruits_copy = fruits.copy()\nprint(fruits_copy)  # Output: ['apple', 'banana', 'orange']\n\n['apple', 'banana', 'orange']\n\n\n\nJava ArrayList Methods\n\n**add():** Adds an element to the end of the list.\n**remove():** Removes the first occurrence of a specified element.\n**get():** Retrieves the element at a specified index.\n**set():** Replaces the element at a specified index with a new element.\n**size():** Returns the number of elements in the list.\n\n\n\n\n\n\n\nRecord\n\nA Record is a composite data structure used to store a collection of related fields, each with a specific name and data type.\nIt is commonly used to model entities in databases and programming, allowing for structured and organized data storage.\nRecords are versatile and can represent complex objects with multiple attributes, making them essential in many applications.\nIn Python, a Record is typically implemented as a class, a namedtuple, or a dataclass. Each of these provides a way to group multiple fields (attributes) together under one name, similar to how a record in other languages might work.\n\n\n\n\nStack\n\n\n\nDescriptionOperationsUsage\n\n\n\nA stack is a linear data structure that follows the Last-In-First-Out (LIFO) principle, meaning the last element added is the first one to be removed.\nPython Equivalent: list or collections.deque\n\n\n\n\nPush (Insertion): O(1) — Add an element to the top of the stack.\nPop (Deletion): O(1) — Remove the top element from the stack.\nPeek/Top: O(1) — View the top element without removing it.\nIsEmpty: O(1) — Check if the stack is empty.\n\n\n\n\nUse Cases:\n\nUsed in expression evaluation, backtracking algorithms, undo mechanisms in applications, and for maintaining function call stacks in recursion.\n\n\n\n\n\n\n\n\nBag\n\n\n\nDescriptionOperationsUsage\n\n\n\nA Bag (also known as a multiset) is a simple data structure that allows for storing a collection of elements where duplicate elements are allowed. Unlike a set, which requires all elements to be unique, a bag can contain multiple occurrences of the same element.\nPython Equivalent: collections.Counter\n\n\n\n\nAdd (add) — Adds an element to the bag.\n\nSimply add the element, usually at the end or beginning, depending on the implementation (array, linked list, etc.).\n\nTime Complexity: \\(O(1)\\).\n\n\nCheck Membership (contains) — Checks if an element is in the bag.\nCount Occurrences (count) — Counts how many times an element appears in the bag.\nRemove (remove) — Removes one occurrence of an element from the bag.\n\nTypically, bags do not have a direct remove operation unless implemented, in which case:\n\nRemove Specific Element: Find the element and remove it, adjusting structure accordingly.\n\nTime Complexity: \\(O(n)\\).\n\n\n\nGet Size (size) — Returns the total number of elements in the bag, including duplicates.\n\n\n\n\nUse Cases:\n\nA bag is useful when you need to count the number of occurrences of items, such as counting words in a document.\n\n\n\n\n\n\n\n\nQueue\n\n\n\nDescriptionOperationsUsage\n\n\n\nA queue is a linear data structure that follows the First-In-First-Out (FIFO) principle, meaning the first element added is the first one to be removed.\nPython Equivalent: collections.deque or queue.Queue\n\n\n\n\nEnqueue (Insertion/Push): O(1) — Add an element to the end of the queue.\nDequeue (Deletion/Pop): O(1) — Remove the front element from the queue.\nFront/Peek: O(1) — View the front element without removing it.\nIsEmpty: O(1) — Check if the queue is empty.\n\n\n\n\nUse Cases:\n\nUseful in scheduling processes, managing tasks in order, breadth-first search (BFS) algorithms, and handling requests in servers.\n\n\n\n\n\n\n\n\nDeque\n\n\n\nDescriptionOperationsUsage\n\n\n\nA deque is a linear data structure that allows insertion and deletion of elements from both the front and rear ends.\nPython Equivalent: collections.deque\n\n\n\n\nInsertFront: O(1) — Add an element to the front.\nInsertLast: O(1) — Add an element to the end.\nDeleteFront: O(1) — Remove an element from the front.\nDeleteLast: O(1) — Remove an element from the end.\nPeekFront: O(1)— View the front element.\nPeekLast: O(1) — View the last element.\nIsEmpty: O(1) — Check if the deque is empty.\n\n\n\n\nUse Cases:\n\nUseful in scenarios requiring access from both ends, such as the implementation of both stacks and queues, task scheduling, and sliding window algorithms.\n\n\n\n\n\n\n\n\n\n\n\n\n\nHash Table\n\n\n\n\n\n\nDescriptions\n\nA hash table is a data structure that maps keys to values using a hash function, which transforms the key into an index in an array.\nPython Equivalent: dict\n\n\n\n\nOperations\n\nInsert: O(1) — Map a key to a value by computing its hash.\nSearch: O(1) — Retrieve the value associated with a given key.\nDelete: O(1) — Remove the key-value pair from the table.\n\n\n\n\nUsage\n\nUse Cases:\n\nHighly efficient for scenarios requiring fast lookups, such as databases, caches, and dictionaries.\n\n\n\n\n\nCollisions\n\nHandling Collisions:\n\nChaining: Store multiple elements at the same index using a linked list.\nOpen Addressing (Probing): Find another open slot using techniques like linear probing, quadratic probing, or double hashing.\n\n\n\n\n\nHashing\n\nHashing\n\nHashing is the process of mapping keys to indices in an array using a hash function. It ensures efficient data retrieval by minimizing the number of comparisons required.\n\n\nHash Function - A hash function is a function that converts input (key) into a fixed-size value, typically an integer, which serves as an index in the hash table array. - A good hash function has the following properties:\n  - **Deterministic:** The same key always produces the same hash value.\n  - **Uniform Distribution:** The hash values should be distributed uniformly across the array to minimize collisions.\n  - **Fast Computation:** The function should be quick to compute.\n\nHash Keys\n\nHash Key: The key for which the hash function generates an index.\nHash Value: The integer index produced by the hash function.\n\n\n\n\n\nHow to perform hash function on calculator\nTo determine where the data associated with the last 4 digits of the Social Security number (‘2023’) will be stored in the array, follow these steps:\n1. Understand the Hash Function: The problem specifies a hash function given by key % 1009. Here, % denotes the modulus operation. This operation returns the remainder of the division of key by 1009.\n2. Determine the Key: The last 4 digits of the Social Security number are ‘2023’. Therefore, the key you’re interested in is 2023.\n3. Apply the Hash Function: Use the hash function to find the index in the array where the data should be stored. Specifically, you need to compute:\na. Key / Hash - (whole number in result) * Hash\n  i. For this example\n    1. (2023 / 1009) = 2.004955401\n    2. 2.004955401 - 2 = 0.004955401\n    3. 0.004955401 * 1009 = 5\n4. By calculating the remainder, you will find the index in the array soc where the data associated with the key ‘2023’ will be stored.\na. soc[5]\n\n\n\n\n\n\n\nTrees\n\n\n\n\n\n\n\n\nTree\n\n\n\n\n\n\n\nDescription\n\nA tree is a hierarchical data structure composed of nodes, where each node contains a value and references to child nodes. The top node is called the root, and nodes with no children are called leaves.\nPython Equivalent: Custom class with Node and Tree classes\n\n\n\n\nTypes\n\nBinary Tree: Each node has at most two children (left and right).\nBinary Search Tree (BST): A binary tree where the left child contains values less than the parent, and the right child contains values greater than the parent.\nAVL Tree: A self-balancing binary search tree.\nRed-Black Tree: Another type of self-balancing binary search tree.\nB-Tree: A self-balancing tree that maintains sorted data and allows searches, sequential access, insertions, and deletions in logarithmic time.\n\n\n\n\nForms\n\nFull Binary Tree — Definition: A binary tree in which every node has either 0 or 2 children.\nComplete Binary Tree — Definition: A binary tree in which all levels are completely filled except possibly the last level, which is filled from left to right.\nPerfect Binary Tree — Definition: A binary tree in which all interior nodes have two children and all leaves are at the same level.\nBalanced Binary Tree — Definition: A binary tree where the height of the left and right subtrees of any node differ by at most one.\n\n\n\n\nOperations\n\nInsertion: O(log ⁡n) for balanced trees like AVL or Red-Black Trees; O(n) for unbalanced trees.\nDeletion: O(log ⁡n) for balanced trees; O(n) for unbalanced trees.\n\nBST: Find the node to be removed, then:\n\nNo Children: Just remove the node.\nOne Child: Bypass the node and link its parent directly to its child.\nTwo Children: Find the in-order predecessor (or successor), swap values, and remove the predecessor (or successor) node.\nTime Complexity: O(log n) on average, O(n) in the worst case.\n\n\nSearch: O(log ⁡n) for balanced trees; O(n) for unbalanced trees.\nTraversal:\n\nIn-order: O(n) — Left, Root, Right (used in BSTs to get sorted order).\nPre-order: O(n) — Root, Left, Right.\nPost-order: O(n) — Left, Right, Root.\nLevel-order: O(n)— Traverse nodes level by level.\n\n\n\n\n\nUsage\n\nUse Cases:\n\nSuitable for hierarchical data (like file systems), database indexing, and scenarios requiring sorted data with dynamic insertion and deletion.\n\n\n\n\n\n\n\n\n\nAdelson-Velsky and Landis Trees\n\n\n\n\n\n\n\n\nAVL Trees\n\n\n\n\n\n\n\nProperties\n\nAn AVL tree is a binary search tree in which the height of the two child subtrees of any node differs by at most one.\nIf at any time during insertion or deletion this condition is violated, the tree is rebalanced through rotations.\n\n\n\n\nBalancing\n\nSingle Rotation: Used when a node is inserted into the left subtree of the left child or the right subtree of the right child.\nDouble Rotation: Used when a node is inserted into the left subtree of the right child or the right subtree of the left child.\n\n\n\n\nTime\n\nTime Complexity:\n\nSearch, Insertion, Deletion: \\(\\text{O(log n)}\\), where n is the number of nodes.\n\n\n\n\n\nUsage\n\nUse Cases:\n\nAVL trees are well-suited for applications where frequent insertions and deletions occur, and maintaining strict balance is important.\n\n\n\n\n\n\n\n\n\nRed-Black\n\n\n\n\n\n\n\n\nRed-Black Trees\n\n\n\n\n\n\n\nProperties\n\nA Red-Black tree is a binary search tree with an extra bit of storage per node: its color, which can be either red or black.\nThe tree satisfies several properties:\n\nEvery node is either red or black.\nThe root is always black.\nAll leaves (NIL nodes) are black.\nRed nodes cannot have red children (no two red nodes can be adjacent).\nEvery path from a node to its descendant NIL nodes must have the same number of black nodes (black height).\n\n\n\n\n\nBalancing\n\nThe tree is kept balanced by performing rotations and color changes during insertions and deletions.\n\n\n\n\nTime\n\nTime Complexity:\n\nSearch, Insertion, Deletion: \\(\\text{O(log n)}\\).\n\n\n\n\n\nUsage\n\nUse Cases:\n\nRed-Black trees are used in many systems, such as the Linux kernel’s process scheduling and in standard libraries like C++’s std::map and std::set, due to their relatively simple implementation and good performance.\n\n\n\n\n\n\n\n\n\nBalanced Tree\n\n\n\n\n\n\n\n\nB-Trees\n\n\n\n\n\n\n\nProperties\n\nA B-tree is a self-balancing search tree in which nodes can have more than two children. It’s commonly used in databases and file systems.\nA B-tree of order m can have at most m-1 keys and m children.\nAll leaf nodes are at the same depth, and internal nodes act as a guide to direct searches.\n\n\n\n\nBalancing\n\nBalancing in B-trees is achieved through splitting and merging nodes.\nWhen a node in a B-tree becomes too full (i.e., has more than m-1 keys), it is split into two nodes, and the middle key is pushed up to the parent node.\nWhen a node has too few keys, it may borrow keys from its neighbors or merge with a neighboring node.\n\n\n\n\nTime\n\nTime Complexity:\n\nSearch, Insertion, Deletion: \\(\\text{O(log n)}\\).\n\n\n\n\n\nUsage\n\nUse Cases:\n\nB-trees are particularly effective for systems that read and write large blocks of data, such as databases and file systems, where minimizing disk I/O operations is critical.\n\n\n\n\n\n\n\n\n\n\nWrap-up\n\n\n\n\n\n\n\n\nComparison Summary\n\n\n\n\n\n\nAVL Trees: Strictly balanced, more rotations, better for search-heavy applications.\nRed-Black Trees: Looser balancing, fewer rotations, generally faster insertions and deletions.\nB-Trees: Optimized for storage systems, used in databases, and file systems for handling large volumes of data.\n\n\n\n\n\n\n\n\n\n\nTree Traversal\n\n\n\n\n\n\nPre-Order Traversal (NLR) - Node, Left, Right\nIn-Order Traversal (LNR) - Left, Node, Right\nPost-Order Traversal (LRN) - Left, Right, Node\n\n\n\n\n\n\n\n\nPre-Order Traversal (NLR)\n\n\n\nOrder:Process:Examples:\n\n\n\nNode → Left → Right\n\n\n\n\nVisit the Node first.\nThen recursively visit the Left subtree.\nFinally, visit the Right subtree.\n\n\n\nIf you have a tree like this:\n\n\n\n\n\nflowchart TB\n  A --&gt; B\n  A --&gt; C\n  B --&gt; D\n  B --&gt; E\n\n\n\n\n\n\n\nThe Pre-Order traversal would be: A B D E C\n\n\n\n\n\n\nIn-Order Traversal (LNR)\n\n\n\nOrder:Process:Example:\n\n\n\nLeft → Node → Right\n\n\n\n\nRecursively visit the Left subtree.\nThen visit the Node.\nFinally, visit the Right subtree.\n\n\n\nFor the same tree:\n\n\n\n\n\nflowchart TB\n  A --&gt; B\n  A --&gt; C\n  B --&gt; D\n  B --&gt; E\n\n\n\n\n\n\n\nThe In-Order traversal would be: D B E A C\n\n\n\n\n\n\nPost-Order Traversal (LRN)\n\n\n\nOrder:Process:Examples:\n\n\n\nLeft → Right → Node\n\n\n\n\nRecursively visit the Left subtree.\nThen visit the Right subtree.\nFinally, visit the Node.\n\n\n\nFor the same tree:\n\n\n\n\n\nflowchart TB\n  A --&gt; B\n  A --&gt; C\n  B --&gt; D\n  B --&gt; E\n\n\n\n\n\n\n\nThe Post-Order traversal would be: D E B C A\n\n\n\n\n\n\n\nWrap-up\n\n\n\n\n\n\n\n\nHow to Remember Them:\n\n\n\n\n\n\nPre-Order (NLR): Think of “Pre” as “before” - you process the Node before anything else.\nIn-Order (LNR): “In” implies “in between” - the Node is processed in between the Left and Right subtrees.\nPost-Order (LRN): “Post” means “after” - the Node is processed after the subtrees.\n\n\n\n\n\n\n\n\n\n\nVisual Mnemonic:\n\n\n\n\n\n\nPre-Order: Imagine starting at the root and touching it first.\nIn-Order: Imagine walking along the edge of the tree, touching the left side first, then the root, and then the right side.\nPost-Order: Imagine leaving the tree by processing the children before the root.",
    "crumbs": [
      "DSA I"
    ]
  }
]