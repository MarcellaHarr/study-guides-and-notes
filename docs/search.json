[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Study Notes & Guides",
    "section": "",
    "text": "Welcome",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#whats-inside",
    "href": "index.html#whats-inside",
    "title": "My Study Notes & Guides",
    "section": "‚úçÔ∏è What‚Äôs Inside",
    "text": "‚úçÔ∏è What‚Äôs Inside\n\n\nüìö Organized course notes and study guides\nüé• Embedded videos and media\nüß† Quick-reference guides\nüß™ Code examples and exercises",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "My Study Notes & Guides",
    "section": "üöÄ Getting Started",
    "text": "üöÄ Getting Started\n\n\n\n\n\n\nStart exploring by selecting a course or topic from the sidebar.\nOr jump straight into this course here:\n\n\n\nBegin Here ¬ª",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#contribute-or-feedback",
    "href": "index.html#contribute-or-feedback",
    "title": "My Study Notes & Guides",
    "section": "üôå Contribute or Feedback",
    "text": "üôå Contribute or Feedback\nThis project is personal, but feedback is welcome!\nFeel free to open an issue or follow my GitHub:\nGitHub Repository",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "courseD421.html",
    "href": "courseD421.html",
    "title": "Discrete Math II",
    "section": "",
    "text": "Module I: Working with Sets",
    "crumbs": [
      "Discrete Math II"
    ]
  },
  {
    "objectID": "courseD421.html#module-i-working-with-sets",
    "href": "courseD421.html#module-i-working-with-sets",
    "title": "Discrete Math II",
    "section": "",
    "text": "Section 1:\n\n\n\n1.2\n\n\nset theory\n\nA set is a collection of objects. The objects in a set are called elements. The roster notation definition of a set is a list of the elements enclosed in curly braces with the individual elements separated by commas.\n\n\n\n\n1.2.1\n\n\nempty set\n\nThe set with no elements is called the empty set and is denoted by the symbol \\(‚àÖ\\). The empty set is sometimes referred to as the null set and can also be denoted by \\(\\{ \\}\\). It is also an element of every power set. A finite set has a finite number of elements. An infinite set has an infinite number of elements.\n\n\n\n\n1.2.2\n\n\nset member & subset\n\n\n\n‚ÄúElement of‚Äù ExampleSubset Example\n\n\n\nelement \\(\\epsilon\\) set\n\n\\(x\\enspace \\epsilon \\enspace \\{w,x\\}\\)\n\\(p\\enspace \\epsilon \\enspace \\{q,r,s\\}\\)\n\n\n\nset \\(\\subseteq\\) set\n\n\\(\\{6,7,8\\}\\enspace \\subseteq \\enspace \\{1,2,3,...\\}\\)\n\\(\\{2\\}\\enspace \\subseteq \\enspace \\{1,2\\}\\)\n\n\n\n\nThe cardinality of a finite set is the number of elements in that set, and is denoted as \\(|\\thinspace|\\). Two sets are equal if they have exactly the same elements.\n\n\n\n\n1.2.3\n\n\ntheory symbols\n\n\n\n\nTable¬†1: Math Symbol Examples \n\n\n\n\n\n\n\n(a) Common Math Sets\n\n\n\n\n\n\n\n\n\n\nSymbol\nSet\nExample\n\n\n\n\n\\(\\mathbb{N}\\)\nThe set of natural numbers: All integers greater than or equal to 0.\n\\(0, 1, 2\\)\n\n\n\\(\\mathbb{Z}\\)\nThe set of all integers.\n\\(..., -2, -1, 0, 1, 2, ...\\)\n\n\n\\(\\mathbb{Q}\\)\nThe set of rational numbers: All real numbers that can be expressed as a/b, where a and b are integers and b ‚â† 0.\n\\(0,\\thinspace 1/2,\\thinspace 5.23, \\thinspace -5/3\\)\n\n\n\\(\\mathbb{R}\\)\nThe set of real numbers.\n\\(0, 1/2, 5.23, -5/3,\\thinspace \\pi, \\sqrt{2}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Superscripts\n\n\n\n\n\nSymbol\nSet\n\n\n\n\n\\(\\mathbb{R^+}\\)\nThe set of all positive real numbers.\n\n\n\\(\\mathbb{R^-}\\)\nThe set of all negative real numbers.\n\n\n\\(\\mathbb{Z^+}\\)\nThe set of all positive integers.\n\n\n\\(\\mathbb{Z^-}\\)\nThe set of all negative integers\n\n\n\n\n\n\n\n\n\n\n\nA number x is positive if \\(x &gt; 0\\). A number x is negative if \\(x &lt; 0\\). The number \\(0\\) is neither positive nor negative, so \\(0 \\in \\mathbb{Z^+}\\) and \\(0 \\in \\mathbb{Z^-}\\), and a number \\(x\\) is non-negative if \\(x ‚â• 0\\).\n\n\n\n\n1.2.4\n\n\nset builder\n\nIn set builder notation, a set is defined by specifying that the set includes all elements in a larger set that also satisfy certain conditions.\n\n\\(\\mathbb{A} = { x \\in \\mathbb{S} : \\mathbb{P}(x) }\\)\n\\(\\mathbb{S}\\) is the larger set from which the elements in \\(\\mathbb{S}\\) are taken.\n\n\n\n\n\n1.2.5 / 1.3\n\n\nuniversal set\n\nThe universal set is a set that contains all elements mentioned in a particular context, and is denoted by the variable \\(\\cup\\). A Venn diagram visual representation of sets using overlapping circles or other closed curves. However, zyBook‚Äôs uses rectangles to denote the universal set and oval shapes to denote sets within \\(\\cup\\).\n\n\n\n\nEqual SubsetsProper Subsets\n\n\n\nset \\(\\subseteq\\) set\n\nEqual sets \\(\\{ \\}\\) can be considered subsets \\(\\subseteq\\). Meaning all of a set‚Äôs elements must be found in the other set (superset).\n\n\\(\\mathbb{A}= \\{ \\mathbb{a, b, c, d, e} \\}\\)  \\(\\mathbb{B}= \\{ \\mathbb{e, b, c, a, d} \\}\\)\n\n\n\\(\\mathbb{B} \\subseteq \\mathbb{A}\\)\n\n\n\n\nset \\(\\subset\\) set\n\nWith proper subsets \\(\\subset\\), equality is not possible. Meaning, a set that is a subset \\(\\subseteq\\) with lesser elements than the superset is considered a proper subset.\n\n\\(\\mathbb{A}= \\{ \\mathbb{a, b, c, d, e} \\}\\) \\(\\mathbb{B}= \\{ \\mathbb{e, b, c, a, d} \\}\\) \\(\\mathbb{C}= \\{ \\mathbb{e, c, a} \\}\\)\n\n\n\\(\\mathbb{C} \\subset \\mathbb{A}\\) or \\(\\mathbb{C} \\subset \\mathbb{B}\\)\n\n\n\n\n\nA subset is a set whose elements are all contained within another set. If every element, for example, in set \\(\\mathbb{A}\\) is also an element of set \\(\\mathbb{B}\\), then \\(\\mathbb{A}\\) is a subset of \\(\\mathbb{B}\\). It is denoted by the symbol: \\(\\mathbb{A} \\thinspace \\subseteq \\mathbb{B}\\).\nA proper subset is a subset that is strictly contained within another set, meaning it does not include all elements of the larger set. If \\(\\mathbb{A} \\thinspace \\subseteq \\mathbb{B}\\) and \\(\\mathbb{A} \\thinspace \\ne \\thinspace \\mathbb{B}\\), then \\(\\mathbb{A}\\) is a proper subset of \\(\\mathbb{B}\\). It is denoted by the symbol: \\(\\mathbb{A} \\thinspace \\subset \\thinspace \\mathbb{B}\\).\n\n\n\n\n1.4\n\n\nset containing\n\nThe empty set \\(\\varnothing\\) is not the same as \\(\\{ \\varnothing \\}\\). The cardinality of \\(\\{ \\varnothing \\}\\) is one since it contains exactly one element, which is the empty set. A set can contain a combination of numbers and sets of numbers as in:\n\n\\(\\mathbb{B} = \\{ 2, \\varnothing, \\{1, 2, 3\\}, \\{1\\} \\}\\)\n\n\n\n\n\n1.5\n\n\npower set\n\nA power set is a set of all the subsets, including the empty set and the set itself. For example, the power set of a set \\(\\mathbb{A}\\), denoted \\(P\\{\\mathbb{A}\\}\\), is the set of all subsets of \\(\\mathbb{A}\\), so, if \\(\\mathbb{A} = \\{1,2,3\\}\\), then:\n\n\\(P\\{\\mathbb{A}\\} = \\{ \\varnothing, \\{1\\}, \\{2\\}, \\{3\\}, \\{1, 2\\}, \\{1,3\\}, \\{2,3\\}, \\{1, 2, 3\\} \\}\\)\n\n\n\nCardinality of a power set\n\nLet \\(\\mathbb{A}\\) be a finite set of cardinality \\(n\\). Then the cardinality of the power set of \\(\\mathbb{A}\\) is \\(2^n\\), or \\(\\mid P\\{\\mathbb{A}\\}=2^n \\mid\\).\n\n\n\n\n\n\n\n\n\n1.6\n\n\nintersection & union\n\nSet intersection is the operation that produces a set containing only the elements that are common to both sets. If \\(A\\) and \\(B\\) are sets, their intersection is the set of all elements that are members of both \\(\\mathbb{A}\\) and \\(\\mathbb{B}\\). It is denoted by the symbol: \\(\\mathbb{A} \\cap \\mathbb{B}\\)\n\n\nFormulaExampleNote\n\n\n\n\\(\\mathbb{A} \\cap \\mathbb{B} = \\{ x \\thinspace \\epsilon \\thinspace \\mathbb{A} \\enspace\\text{and}\\enspace x \\thinspace \\epsilon \\thinspace \\mathbb{B} \\}\\)\n\nThis is the formula for the set intersection.\n\n\n\nIF\n\n\n\\(\\mathbb{A} = \\{ 1,3,5 \\}\\); \\(\\mathbb{B} = \\{ 3,4,5 \\}\\);\n\n\nTHEN\n\n\n\\(\\mathbb{A} \\cap \\mathbb{B} = \\{ 3,5 \\}\\);\n\n\n\nThe union and intersection operations are commutative. That is,\n\n\\(\\mathbb{A} \\cap \\mathbb{B} = \\mathbb{B} \\cap \\mathbb{A}\\)\n\n\n\n\n\n\n\nSet union is the operation that produces a set containing all elements that belong to either of two sets. If \\(A\\) and \\(B\\) are sets, their union is the set of all elements that are in \\(\\mathbb{A}\\), or \\(\\mathbb{B}\\), or in both. It is denoted by the symbol: \\(\\mathbb{A} \\cup \\mathbb{B}\\).\n\n\nFormulaExampleNote\n\n\n\n\\(\\mathbb{A} \\cup \\mathbb{B} = \\{ x \\thinspace \\epsilon \\thinspace \\mathbb{A} \\enspace\\text{or}\\enspace x \\thinspace \\epsilon \\thinspace \\mathbb{B} \\}\\)\n\nThis is the formula for the set union.\n\n\n\nIF\n\n\n\\(\\mathbb{A} = \\{ 1,3,5 \\}\\); \\(\\mathbb{B} = \\{ 3,4,5 \\}\\);\n\n\nTHEN\n\n\n\\(\\mathbb{A} \\cup \\mathbb{B} = \\{ 1,3,4,5 \\}\\);\n\n\n\nThe union and intersection operations are commutative. That is,\n\n\\(\\mathbb{A} \\cup \\mathbb{B} = \\mathbb{B} \\cup \\mathbb{A}\\)\n\n\n\n\n\n\n\n\n\n1.7\n\n\nset operation\n\n\n\nSet OperationsSet ExpressionSet Defined\n\n\n\n\\(\\mathbb{A} \\cup \\mathbb{B}; \\enspace \\mathbb{A} \\cap \\mathbb{B}; \\enspace \\mathbb{A} \\setminus \\mathbb{B}\\)\n\nSet operations are mathematical procedures used to create new sets from existing ones. Common operations include union, intersection, and difference, and they follow rules similar to logical operators in propositional logic.\n\n\nA set expression is a mathematical statement that combines sets using one or more operations to define a new set. Parentheses are often used to clarify order of operations and ensure accurate interpretation.\n\nAn example is: \\(\\mathbb{A} \\cup (\\,\\mathbb{B} \\cap \\mathbb{C})\\,\\),\n\nwhich represents the union of A with the intersection of B and C.\n\n\nA defined set is when its elements are explicitly or logically described. It can be defined by listing elements, using conditions, or applying set operations.\nFor example,\n\n\\(\\mathbb{A} \\cap \\mathbb{B} \\cap \\mathbb{C} \\cap \\mathbb{D}\\)\n\nThe set above is defined as the set of elements common to all four sets: \\(\\mathbb{A}, \\mathbb{B}, \\mathbb{C}, \\text{and} \\thinspace \\mathbb{D}\\).\n\n\n\n\n\n\n\n\n1.7.2\n\n\ninteger multiples\n\n\n\nExercise (a)Step 1Step 2Step 3Result\n\n\nUse the definition for \\(A_i\\) to answer the questions.For \\(i \\in \\mathbb{Z^+}, A_i\\), is the set of all integer multiples of \\(i\\).\nDescribe the following set using set builder notation:\n\n\\[\\bigcap^5_{i=1} A_i\\]\n\n\n\nUnderstand the definition:\nWe‚Äôre told that for each \\(i\\) in the set of positive integers (\\(\\mathbb{Z^+}\\)), the set \\(A_i\\) contains all positive integer multiples of \\(i\\).\nExamples:\n\n\\(A_i\\) is the set of all integers (since every number is divisible by 1)\n\n\n\\(A_1 = \\{0,1,2,3,4,5,6, \\ldots\\}\\)\n\n\n\\(A_2\\) is the set of all even integers\n\n\n\\(A_2 = \\{0,2,4,6,8,10, \\ldots\\}\\)\n\n\n\\(A_3\\) is the set of all integers divisible by 3\n\n\n\\(A_3 = \\{0,3,6,9,12,15, \\ldots\\}\\)\n\n\n\\(A_4\\) is the set of all integers divisible by 4\n\n\n\\(A_4 = \\{0,4,8,12,16,20, \\ldots\\}\\)\n\n\n\\(A_5\\) is the set of all integers divisible by 5\n\n\n\\(A_5 = \\{0,5,10,15,20,25, \\ldots\\}\\)\n\n\n\n\n\\[\nWhat Does \\bigcap_{i=1}^5 A_i Mean?\n\\]\n\nThis is asking:\n\n‚ÄúWhat integers are in every one of these sets \\(A_1, A_2, A_3, A_4, A_5\\)?‚Äù\n\nThat means we‚Äôre looking for numbers that are divisible by 1, 2, 3, 4, and 5. So, we need to find integers that are multiples of all these numbers at once.\n\n\nFind the Least Common Multiple\nTo satisfy all five conditions, a number must be a common multiple of all five integers and to be a multiple of all five integers, a number has to be divisible by their least common multiple (LCM).\n\nLCM(1, 2, 3, 4, 5) = 60\n\n\n  A‚ÇÅ      A‚ÇÇ        A‚ÇÉ        A‚ÇÑ        A‚ÇÖ\n         / \\       / \\       / \\       / \\\n none   1   2     1   3     2   2     1   5\n\nThen multiply the prime factors, \\(2 \\cdot 3 \\cdot 2 \\cdot 5=60\\)\n\nSo the set contains all integers that are multiples of 60 ‚Äî that‚Äôs the overlap between all five sets!\n\n\nThe intersection of the sets \\(A_1\\) through \\(A_5\\) in set builder notation is:\n\n\\[\n\\bigcap_{i=1}^5 A_i = \\{ x:x=60k,\\thinspace \\text{for} \\thinspace k \\in \\mathbb{Z^+} \\}\n\\]\n‚ÄúThe set of all values x such that x equals 60 times k, where k is any integer.‚Äù\n\n\n\n\n\n\n\nExercise (b)Step 1Step 2Step 3Result\n\n\nUse the definition for \\(A_i\\) to answer the questions.For \\(i \\in \\mathbb{Z^+}, A_i\\), is the set of all integer multiples of \\(i\\).\nDescribe the following set using roster notation:\n\n\\[( \\,\\bigcup^5_{i=2} A_i) \\, \\cap \\{ x \\in \\mathbb{Z}:1 \\leq x \\leq 20 \\}\\]\n\n\n\nUnderstand the definition\n\n\\[\n( \\,\\bigcup^5_{i=2} A_i) \\, \\text{: This means take all multiples of any one of,} A_2, A_3, A_4, A_5 ( \\, excluding A_1, ) \\, \\text{and put them into one big set (union.)}\\]\n\\(\\bigcap\\): This means intersection, or common values between two sets.\n\\(\\{ x \\in \\mathbb{Z}:1 \\leq x \\leq 20 \\}\\): This is just the set of integers from 1 to 20, and is read as:\n\n‚ÄúThe set of all integers x such that x is greater than or equal to 1 and less than or equal to 20.‚Äù\n\n\n\n\nList All Multiples of 1 to 5 (up to 20)\nWe only care about values up to 20 because of the intersection. So list all multiples of 2 to 5 from 1 to 20, by asking, ‚ÄúIs it a multiple of 2, 3, 4, or 5?‚Äù:\n\n\\(A_2:\\{ 2, 4, 6, 8, 10, 12, 14, 16, 18, 20 \\}\\)\n\\(A_3:\\{ 3, 6, 9, 12, 15, 18 \\}\\)\n\\(A_4:\\{ 4, 8, 12, 16, 20 \\}\\)\n\\(A_5:\\{ 5, 10, 15, 20 \\}\\)\n\n\n\nUnion the Sets \\(A_1 \\cup A_2 \\cup A_3 \\cup A_4 \\cup A_5\\)\nNow, combine all the unique elements from all five sets ‚Äî but since \\(A_1\\) already includes everything from 1 to 20, the union is just:\n  2           3           4           5\n /|\\         /|\\         /|\\         /|\\\n2 4 6      3 6 9      4 8 12      5 10 15\n8 10 12    12 15 18   16 20       20\n14 16 18                 \n20\n\nExcluded:\n  1  7  11  13  17  19\n\nThe common multiples combined together are: \\(\\{2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20\\}\\)\n\n\nThe union of the sets \\(A_2\\) through \\(A_5\\) in roster notation is:\n\n\\[\n( \\,\\bigcup^5_{i=2} A_i) \\, = \\{ 2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20 \\}\n\\]\n\n\n\n\n\n\n\n\n\n1.7.4\n\n\nmultiple set\n\n\n\nIntersectionUnion\n\n\n\n\\(\\bigcap^n_{i=0} A_i\\)\n\nThe intersection of multiple sets is an operation that yields the set of all elements common to every set in a sequence. When given a collection of sets indexed by integers from 1 to n, their intersection is the set of elements that appear in all of the sets from \\(A_\\imath\\) to \\(A_n\\).\n\n\n\n\\(\\bigcup^n_{i=0} A_i\\)\n\nThe union of multiple sets is an operation that yields the set of all elements that appear in at least one of the sets in a sequence. When given a collection of sets indexed by integers from 1 to n, their union includes every element from any of the sets \\(A_\\imath\\) through \\(A_n\\).\n\n\n\n\n\n\n\n\n1.8\n\n\nset/symmetric difference\n\n\n\nSet DifferenceNote\n\n\n\n\\(\\mathbb{A} - \\mathbb{B}\\)\n\nSet difference is the operation that produces a set containing elements that belong to one set but not to another. If \\(\\mathbb{A}\\) and \\(\\mathbb{B}\\) are sets, the set difference \\(A -B\\) contains all elements that are in \\(\\mathbb{A}\\) and not in \\(\\mathbb{B}\\).\n\n\n\n\n\nThe set difference operation is not commutative, meaning \\(A - B \\neq B - A\\) in general.\n\n\n\n\n\n\n\n\n\nSymmetric DifferenceNote\n\n\n\n\\(\\mathbb{A} \\oplus \\mathbb{B}\\)\n\nSymmetric difference is the operation that produces a set containing elements that belong to exactly one of two sets ‚Äî in either \\(\\mathbb{A}\\) or \\(\\mathbb{B}\\), but not in both.\n\nAn alternate definition expresses it using union and set difference:\n\n\\(\\mathbb{A} \\oplus \\mathbb{B}= ( \\, \\mathbb{A} - \\mathbb{B} ) \\, \\cup ( \\, \\mathbb{B} - \\mathbb{A} ) \\,\\)\n\n\n\n\nThe symmetric difference is commutative, so \\(\\mathbb{A} \\oplus \\mathbb{B} = \\mathbb{B} \\oplus \\mathbb{A}\\)\n\n\n\n\n\n\n\n\n\n1.8.1\n\n\nset subtraction\n\nNote: Set subtraction is not associative\n\n\nHere‚Äôs a vid on how, specifically, set and symmetric difference translates into programming.\n\n\n\n\n\n\n1.8.3\n\n\nset complement operation\n\n\n\nComplement OperationsAlternate FormExample\n\n\nThe set complement operation produces a set containing all elements in a universal set \\((\\, \\mathbb{U} )\\,\\) that are not in a subset \\((\\, \\mathbb{A} )\\,\\).\nIt is denoted by:\n\n\\((\\, \\mathbb{A}^c )\\,\\) or \\((\\, \\overline{\\mathbb{A}} )\\,\\) (depending on notation style)\nFormally:\n\n\\([\\, \\mathbb{A}^c = \\{ x \\in \\mathbb{U} : x \\notin \\mathbb{A} \\} \\quad \\text{or} \\quad \\mathbb{A}^c = \\mathbb{U} - \\mathbb{A}]\\,\\)\n\n\nüìò Note: This operation requires a well-defined universal set \\((\\, \\mathbb{U} )\\,\\) unlike union or intersection.\n\n\nYou can express the complement using a set difference operation:\n\\([\\, \\mathbb{A}^c = \\mathbb{U} - \\mathbb{A} ]\\,\\)\nThis says: take everything in the universe \\(( \\, \\mathbb{U} ) \\,\\) and remove the contents of \\(( \\, \\mathbb{A} ) \\,\\).\n\n\nLet the universal set be \\(( \\, \\mathbb{U} = \\mathbb{Z} ) \\,\\) the set of all integers.\nDefine:\n\n\\([ \\, \\mathbb{A} = \\{ x \\in \\mathbb{Z} : x \\text{ is odd} \\} ] \\,\\)\n\nThen:\n\n\\([ \\, \\mathbb{A}^c = \\{ x \\in \\mathbb{Z} : x \\text{ is even} \\} ] \\,\\)\n\nWhich is the set of all even integers.\n\n\n\n\n\n\n\n\n\nTable¬†2: Section 1.8 Summary \n\n\n\n\n\n\n\n(a) Set Operations\n\n\n\n\n\n\n\n\n\n\nOperation\nNotation\nDescription\n\n\n\n\nIntersection\n\\(\\mathbb{A} \\cap \\mathbb{B}\\)\n\\(\\{ x: x \\in \\mathbb{A} \\enspace \\text{and} \\enspace x \\in \\mathbb{B} \\}\\)\n\n\nUnion\n\\(\\mathbb{A} \\cup \\mathbb{B}\\)\n\\(\\{ x:x \\in \\mathbb{A} \\quad \\text{or} \\quad x \\in \\mathbb{B} \\quad \\text{or} \\enspace \\text{both} \\}\\)\n\n\nDifference\n\\(\\mathbb{A} - \\mathbb{B}\\)\n\\(\\{ x:x \\in \\mathbb{A} \\quad \\text{and} \\quad x \\notin \\mathbb{B} \\}\\)\n\n\nSymmetric Difference\n\\(\\mathbb{A} \\oplus \\mathbb{B}\\)\n\\(\\{ x:x \\in \\mathbb{A}-\\mathbb{B} \\quad \\text{or} \\quad x: \\in \\mathbb{B}-\\mathbb{A} \\}\\)\n\n\nComplement\n\\(\\overline{\\rm \\mathbb{A}}\\)\n\\(\\{ x:x \\notin \\mathbb{A} \\}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.9\n\n\ncombining sets\n\n\n\n\n\nDefinitionExplanationExample\n\n\nCombining sets refers to the use of multiple set operations ‚Äî such as union, intersection, difference, and complement ‚Äî in a single expression to create new sets from existing ones.\nThese operations may be nested or sequenced to define increasingly complex relationships among sets, and are governed by mathematical precedence similar to arithmetic operations.\n\n\n\nThe complement operation requires a clearly defined universal set \\((\\, \\mathbb{U} )\\,\\) against which the contents of a subset \\((\\, \\mathbb{A} )\\,\\) are negated.\nCombined operations should be evaluated by grouping parentheses first, then applying the logic of each operator.\nSet expressions such as \\((\\, (\\, \\mathbb{A} \\oplus \\mathbb{B})\\, \\cup (\\, \\mathbb{A} \\cap \\mathbb{C})\\, )\\,\\) illustrate how symmetric difference, union, and intersection interact.\n\nüß† Tip: Just as in algebra, parentheses determine the order of evaluation. For example:\n\n\\((\\, (\\, \\mathbb{A} \\cup \\mathbb{B})\\, \\cap \\mathbb{C} )\\,\\) may produce a different result than \\((\\, \\mathbb{A} \\cup (\\, \\mathbb{B} \\cap \\mathbb{C})\\, )\\,\\)\n\n\n\nLet:\n\n\\((\\, \\mathbb{A} = \\{ \\text{even integers} \\} )\\,\\)\n\\((\\, \\mathbb{U} = \\mathbb{Z} )\\,\\) the set of all integers\n\nThen:\n\nThe complement of \\((\\, A )\\,\\) is:\n\n\\([\\,A^c = \\{ x \\in \\mathbb{Z} : x \\text{ is odd} \\}]\\,\\)\n\n\nNow combine operations:\n\n\\((\\, (\\, \\mathbb{A} \\oplus \\mathbb{B})\\, \\cup (\\, \\mathbb{A} \\cap \\mathbb{C})\\, )\\,\\) defines a new set composed of:\n\nElements in \\(A\\) or \\(B\\) but not both, combined with\nElements shared between \\(A\\) and \\(C\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\n\n\n1a - 1c\n\n\n\n\n\n\n\nExercise 1a\n\n\nStep-1Step-2Step-3Step-4Results\n\n\nThe goal of this exercise is to list all elements of the set\n\n\\(\\{x‚à£x \\text{ is a real number such that } x^2=1\\}\\)\n\nWhat is a set?\n\n\nA set is an unordered collection of objects that satisfy a certain property. This property can be expressed mathematically or in a form of a sentence.\n\n\nLet‚Äôs identify all real numbers \\(x\\) for which \\(x^2=1\\).\n\n\\(x^2 = 1 ‚üπ x = ¬± 1 ‚üπ x = ¬± 1\\)\n\nTherefore, elements of the given set are \\(‚àí1\\) and \\(1\\). We can also write this as\n\n\\(\\{x‚à£x \\text{ is a real number such that } x^2=1\\} = \\{-1, 1\\}\\).\n\n\n\nLet‚Äôs recap what we have done.\nWe determined that the real numbers whose square is equal to \\(1\\) are \\(‚àí1\\) and \\(1\\), and that they are the only elements of this set.\n\n\n\n\\(‚àí1,1\\)\n\n\n\n\n\n\n\nExercise 1b\n\n\nStep-1Step-2Step-3Step-4Results\n\n\nThe goal of this exercise is to list all elements of the set\n\n\\(\\{x‚à£ x \\text{ is a positive integer less than } 12\\}\\)\n\nWhat is a set?\n\n\nA set is an unordered collection of objects that satisfy a certain property. This property can be expressed mathematically or in a form of a sentence.\n\n\nRemember that positive integers are whole positive numbers, also called natural numbers. This set consists of numbers \\(1,2,3,‚Ä¶.\\) Therefore, integers that are less than \\(12\\) are\n\n\\(1,2,3,4,5,6,7,8,9,10,11\\)\n\nThese are the elements of our set, which we can also denote as\n\n\\(\\{x‚à£ x \\text{ is a positive integer less than } 12\\} = \\{1,2,3,4,5,6,7,8,9,10,11\\}\\)\n\n\n\nLet‚Äôs recap what we have done. We recalled what the set of positive integers is, and then identified the ones that are less than \\(12\\). These are the whole numbers from \\(1\\) to \\(11\\), and they are the only elements of our set.\n\n\n\n\\(1,2,3,4,5,6,7,8,9,10,11\\)\n\n\n\n\n\n\nExercise 1c\n\n\nStep-1Step-2Step-3Step-4Results\n\n\nThe goal of this exercise is to list all elements of the set\nWhat is a set?\n\n\nA set is an unordered collection of objects that satisfy a certain property. This property can be expressed mathematically or in a form of a sentence.\n\n\nIn part \\(b)\\,\\) we recalled that integers are whole numbers. Their squares are positive whole numbers, or natural numbers. Suppose that a is an integer such that\n\n\\(a^2=x\\)\n\nSince \\(10^2=100\\), and we know that \\(x&lt;100\\), it follows that\n\n\\(a^2 &lt; 10^2 ‚üπ \\sqrt{a^2} &gt; \\sqrt{10^2} ‚üπ |a| &lt; |10| ‚üπ |a| &lt; 10\\)\n\nTherefore, \\(a\\) is an integer whose absolute value is smaller than \\(10\\). The list of possible values of a is\n\n\\(0,\\thinspace¬±1,\\thinspace¬±2,\\thinspace¬±3,\\thinspace¬±4,\\thinspace¬±5,\\thinspace¬±6,\\thinspace¬±7,\\thinspace¬±8,\\thinspace¬±9\\)\n\nConsequently, the list of all possible values of x, which is the square of a is\n\n\\(0,1,4,9,16,25,36,49,64,81\\)\n\nHence, there are \\(10\\) elements of our set.\n\n\nLet‚Äôs recap what we have done.\nFirst, we identified that the absolute value of an integer whose square is less than \\(100\\) is smaller than \\(10\\). Then, we listed them and found their squares, which are the elements of our set.\n\n\n\n\\(0,1,4,9,16,25,36,49,64,81\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSection 2:",
    "crumbs": [
      "Discrete Math II"
    ]
  },
  {
    "objectID": "courseC949.html",
    "href": "courseC949.html",
    "title": "Data Structures",
    "section": "",
    "text": "Explains Algorithms (29%)\nFiniteness\nFor Loop",
    "crumbs": [
      "Data Structures"
    ]
  },
  {
    "objectID": "courseC949.html#explains-algorithms-29",
    "href": "courseC949.html#explains-algorithms-29",
    "title": "Data Structures",
    "section": "",
    "text": "Characteristics of Algorithms\n\n\n\n\n\n\nNames\n\n\n\n\n\n\n\nAn algorithm must always have a finite number of steps before it ends. When the operation is finished, it must have a defined endpoint or output and not enter an endless loop.\nDefiniteness\nAn algorithm needs to have exact definitions for each step. Clear and straightforward directions ensure that every step is understood and can be taken easily.\nInput\nAn algorithm requires one or more inputs. The values that are first supplied to the algorithm before its processing are known as inputs. These inputs come from a predetermined range of acceptable values.\nOutput\nOne or more outputs must be produced by an algorithm. The output is the outcome of the algorithm after every step has been completed. The relationship between the input and the result should be clear.\nEffectiveness\nAn algorithm‚Äôs stages must be sufficiently straightforward to be carried out in a finite time utilizing fundamental operations. With the resources at hand, every operation in the algorithm should be doable and practicable.\nGenerality\nRather than being limited to a single particular case, an algorithm should be able to solve a group of issues. It should offer a generic fix that manages a variety of inputs inside a predetermined range or domain.\n\n\n\n\n\nFactors of an Algorithm\n\n\n\n\n\n\nFactors\n\n\n\n\n\n\n**Modularity**\nThis feature was perfectly designed for the algorithm if you are given a problem and break it down into small-small modules or small-small steps, which is a basic definition of an algorithm.\nCorrectness\nAn algorithm‚Äôs correctness is defined as when the given inputs produce the desired output, indicating that the algorithm was designed correctly. An algorithm‚Äôs analysis has been completed correctly.\nMaintainability\nIt means that the algorithm should be designed in a straightforward, structured way so that when you redefine the algorithm, no significant changes are made to the algorithm.\nFunctionality\nIt takes into account various logical steps to solve a real-world problem.\nRobustness\nRobustness refers to an algorithm‚Äôs ability to define your problem clearly.\nUser-friendly\nIf the algorithm is difficult to understand, the designer will not explain it to the programmer.\nSimplicity\nIf an algorithm is simple, it is simple to understand.\n**Extensibility**\nYour algorithm should be extensible if another algorithm designer or programmer wants to use it.\n\n\n\n\n\n\nTypes of Algorithms\n\n\nType-1Type-2Type-3Type-4\n\n\n\n\nBrute Force Algorithm\nA straightforward approach that exhaustively tries all possible solutions, suitable for small problem instances but may become impractical for larger ones due to its high time complexity.\n\n\nRecursive Algorithm\nA method that breaks a problem into smaller, similar subproblems and repeatedly applies itself to solve them until reaching a base case, making it effective for tasks with recursive structures.\n\n\nEncryption Algorithm\nUtilized to transform data into a secure, unreadable form using cryptographic techniques, ensuring confidentiality and privacy in digital communications and transactions.\n\n\n\n\nBacktracking Algorithm\nA trial-and-error technique used to explore potential solutions by undoing choices when they lead to an incorrect outcome, commonly employed in puzzles and optimization problems.\n\n\nSearching Algorithm\nDesigned to find a specific target within a data set, enabling efficient retrieval of information from sorted or unsorted collections.\n\n\nSorting Algorithm\nAimed at arranging elements in a specific order, like numerical or alphabetical, to enhance data organization and retrieval.\n\n\n\n\n\nHashing Algorithm\nConverts data into a fixed-size hash value, enabling rapid data access and retrieval in hash tables, commonly used in databases and password storage.\n\n\nDivide & Conquer Algorithm\nBreaks a complex problem into smaller subproblems, solves them independently, and then combines their solutions to address the original problem effectively.\n\n\nGreedy Algorithm\nMakes locally optimal choices at each step in the hope of finding a global optimum, useful for optimization problems but may not always lead to the best solution.\n\n\n\n\nDynamic Programming Algorithm\nStores and reuses intermediate results to avoid redundant computations, enhancing the efficiency of solving complex problems.\n\n\nRandomized Algorithm\nUtilizes randomness in its steps to achieve a solution, often used in situations where an approximate or probabilistic answer suffices.\n\n\n\n\n\n\nRecursive Algorithms\n\n\nAlgorithms\nRecursive algorithms are a fundamental concept in computer science, particularly in the study of data structures and algorithms. A recursive algorithm is one that solves a problem by breaking it down into smaller instances of the same problem, which it then solves in the same way. This process continues until the problem is reduced to a base case, which is solved directly without further recursion.\n\n\n\nKey Concepts\n\n\nBase CaseRecursive CaseStack\n\n\nThis is the condition under which the recursion stops. It represents the simplest instance of the problem, which can be solved directly without further recursion.\n\n\nThis is the part of the algorithm that breaks the problem down into smaller instances of the same problem and then calls the algorithm recursively on these smaller instances.\n\n\nEach recursive call is placed on the system call stack. When the base case is reached, the stack begins to unwind as each instance of the function returns its result.\n\n\n\n\n\n\nFactorial Calculation\n\nThe factorial of a number n (denoted as n!) is a classic example of a recursive algorithm. The factorial is defined as:\n\nO! = 1 (Base Case)\nN! = n * (n-1)! For n &gt; O (Recursive Case)\n\n\nCodeLogicPros/ConsUsage\n\n\n\ndef factorial(n):\n    if n == 0:  # Base Case\n        return 1\n    else:  # Recursive Case\n        return n * factorial(n - 1)\n\n\n\nHow It Works:\n\nBase Case: When n is 0, the function returns 1.\nRecursive Case: For any other value of n, the function calls itself with n‚àí1 and multiplies the result by n.\n\nFor example, calling factorial(3) would work as follows:\n\nfactorial(3) calls factorial(2)\nfactorial(2) calls factorial(1)\nfactorial(1) calls factorial(0)\nfactorial(0) returns 1, then:\nfactorial(1) returns 1 * 1 = 1\nfactorial(2) returns 2 * 1 = 2\nfactorial(3) returns 3 * 2 = 6\n\n\n\nAdvantages of Recursion\n\nSimplicity: Recursive solutions are often more elegant and easier to understand than their iterative counterparts.\nDirect Translation: Some problems are naturally recursive, like tree traversals, making recursion the most straightforward approach.\n\nDisadvantages of Recursion\n\nPerformance: Recursive algorithms can be less efficient due to the overhead of multiple function calls and potential stack overflow issues for deep recursion.\nMemory Usage: Recursion can consume more memory because each function call adds a new frame to the call stack.\n\n\n\nWhen to Use Recursion - When a problem can naturally be divided into similar sub-problems (e.g., tree traversal, searching algorithms like binary search). - When the recursive solution is significantly simpler or more intuitive than an iterative one.\n\n\n\n\n\n\nLinear & Binary Search\n\nLinear search and binary search are two fundamental algorithms used to search for an element in a collection, like an array or a list. However, they differ significantly in how they approach the search and their efficiency.\n\n\nLinear Search\n\n\nConceptStepsUsage\n\n\n\nLinear search is the simplest search algorithm.\nIt works by sequentially checking each element of the array or list until the target element is found or the end of the collection is reached.\n\n\n\nAlgorithm:\n\nStart from the first element of the array.\nCompare the current element with the target element.\nIf they match, return the index of the element.\nIf they don‚Äôt match, move to the next element and repeat the process.\nIf the target element is not found by the end of the array, return a ‚Äúnot found‚Äù indication.\n\nTime Complexity: \\(O(n)\\), where n is the number of elements in the array. This is because in the worst case, the algorithm may need to check every element in the array.\n\n\nWhen to Use:\n\nWhen the array or list is small.\nWhen the array is unsorted.\nWhen simplicity is more important than performance.\n\n\ndef linear_search(arr, target):\n    for i in range(len(arr)):\n        if arr[i] == target:\n            return i\n    return -1  # Return -1 if the element is not found\n\n\n\n\n\n\n\nBinary Search\n\n\nConceptStepsUsageCompare\n\n\n\nBinary search is much more efficient than linear search but requires the array or list to be sorted.\nIt works by repeatedly dividing the search interval in half. If the target value is less than the middle element, the search continues in the left half, otherwise in the right half.\n\n\n\nAlgorithm:\n\nStart with two pointers, one at the beginning (low) and one at the end (high) of the sorted array.\nFind the middle element of the current interval.\nCompare the middle element with the target:\n\nIf they match, return the index of the middle element.\nIf the target is less than the middle element, repeat the search on the left half.\nIf the target is greater, repeat the search on the right half.\n\nIf the interval becomes invalid (low &gt; high), return a ‚Äúnot found‚Äù indication.\n\nTime Complexity: \\(\\text{O(log‚Å° n)}\\), where n is the number of elements in the array. This logarithmic time complexity makes binary search significantly faster than linear search for large data sets.\n\n\nWhen to Use:\n\nWhen the array or list is sorted.\nWhen the array is large and efficiency is crucial.\n\n\ndef binary_search(arr, target):\n    low = 0\n    high = len(arr) - 1\n\n    while low &lt;= high:\n        mid = (low + high) // 2\n        if arr[mid] == target:\n            return mid\n        elif arr[mid] &lt; target:\n            low = mid + 1\n        else:\n            high = mid - 1\n\n    return -1  # Return -1 if the element is not found\n\n\n\nComparison\n\nEfficiency: Binary search is faster than linear search, especially for large data sets, but it requires the array to be sorted.\nSimplicity: Linear search is simpler to implement and doesn‚Äôt require the array to be sorted, making it more versatile for smaller or unsorted data sets.\nUse Cases:\n\nLinear Search: Suitable for small or unsorted collections where the simplicity of the algorithm outweighs the need for speed.\nBinary Search: Ideal for large, sorted collections where performance is a priority.\n\n\n\n\n\n\n\n\nStep-by-Step Guide\n\n\nArraysSetup1st Iteration2nd Iteration\n\n\nFiguring out the array elements that correspond to the mid-values in the first and second iterations of A binary search\n\\(\\text{ arr = {45, 77, 89, 90, 94, 99, 100} }\\) and \\(\\text{key = 100}\\)\n\n\n\nThe array arr is {45, 77, 89, 90, 94, 99, 100}.\nThe key to find is 100.\nInitialize two pointers: low (start of the array) and high (end of the array).\n\n\n\n\nCalculate the middle index mid using the formula: mid = (low + high) / 2\nCheck the value at arr[mid].\nCompare arr[mid] with the key:\n\nIf arr[mid] is less than key, update low to mid + 1.\nIf arr[mid] is greater than key, update high to mid - 1.\nIf arr[mid] is equal to key, you have found the key (though you won‚Äôt need a second iteration in this case).\n\n\n\n\n\nRepeat the calculation for mid with the updated low and high values.\nAgain, compare arr[mid] with the key and update low or high accordingly.\n\n\n\n\n\n\n\n\nSearching Algorithms\n\n\nLinear Search\n\n\n\nLogicUsageStates\n\n\n\nConcept: As discussed earlier, linear search involves checking each element in a list or array sequentially until the target element is found or the end of the collection is reached.\nTime Complexity: \\(O(n)\\), where n is the number of elements.\n\n\n\n\nUse Case: Best used when the list is small or unsorted.\nDistinct Characteristics:\n\nSimple, sequential search.\nChecks each element one by one.\nWorks on both sorted and unsorted data.\n\n\n\n\n\nLinear Search Worst, Average and Best\n\n**Best Case:** \\(O(1)\\) ‚Äî The target element is the first element.\n**Average Case:** \\(O(n)\\) ‚Äî The target element is somewhere in the middle or not in the array.\n**Worst Case:** \\(O(n)\\) ‚Äî The target element is the last element or not present.\n\n\n\n\n\n\n\n\nBinary Search\n\n\n\nLogicUsageStates\n\n\n\nConcept: Binary search operates on a sorted list. It repeatedly divides the search interval in half until the target element is found or the interval is empty.\nTime Complexity: \\(\\text{O(log‚Å° n)}\\)\n\n\n\n\nUse Case: Ideal for large, sorted datasets.\nDistinct Characteristics:\n\nRequires a sorted array.\nDivides the search interval in half repeatedly.\nEfficient, logarithmic time complexity.\n\n\n\n\n\nBinary Search Worst, Average and Best\n\nBest Case: \\(O(1)\\) ‚Äî The target element is the middle element.\nAverage Case: \\(\\text{O(log‚Å° n)}\\) ‚Äî The target element is not immediately found but within the sorted array.\nWorst Case: \\(\\text{O(log‚Å° n)}\\) ‚Äî The target element is at the extreme ends or not present.\n\n\n\n\n\n\n\n\nInterpolation Search\n\n\n\nLogicUsageStates\n\n\n\nConcept: Similar to binary search but works on uniformly distributed data. It estimates the position of the target element based on the value.\nTime Complexity: O(log ‚Å°log ‚Å°n) in the best case, \\(O(n)\\) in the worst case.\n\n\n\n\nUse Case: Effective when the data is uniformly distributed.\n\n\n\n\nInterpolation Search Worst, Average and Best\n\nBest Case: \\(O(1)\\) ‚Äî The target element is exactly where the interpolation suggests.\nAverage Case: \\(\\text{O(log ‚Å°log‚Å° n)}\\) ‚Äî Uniformly distributed data.\nWorst Case: \\(O(n)\\) ‚Äî Highly skewed data distribution or worst interpolation.\n\n\n\n\n\n\n\n\nDFS/BFS\n\n\n\nLogicUsageStates\n\n\n\nConcept: Used primarily in graph and tree data structures. Depth-First Search (DFS) explores as far as possible along one branch before backtracking, while Breadth-First Search (BFS) explores all neighbors at the present depth before moving on to nodes at the next depth level.\nTime Complexity: \\(\\text{O(V + E)}\\), where V is the number of vertices and E is the number of edges.\n\n\n\n\nUse Case: Useful for searching nodes in graphs and trees.\n\n\n\n\n(DFS)\n\nBest Case: \\(O(1)\\) ‚Äî The target node is found immediately.\nAverage Case: \\(\\text{O(V + E)}\\)‚Äî Typically when all nodes and edges must be explored.\nWorst Case: \\(\\text{O(V + E)}\\) ‚Äî The target node is the last one discovered.\n\n(BFS)\n\nBest Case: \\(O(1)\\) ‚Äî The target node is the root or the first node checked.\nAverage Case: \\(\\text{O(V + E)}\\) ‚Äî All nodes and edges need to be explored.\nWorst Case: \\(\\text{O(V + E)}\\) ‚Äî The target node is the last one explored.\n\n\n\n\n\n\n\n\n\nSorting Algorithms\nSorting algorithms organize data in a particular order (usually ascending or descending). This makes searching and other operations more efficient.\n\n\nBubble Sort\n\n\n\nUsageDescriptorStatesTips\n\n\n\nUse Case: Simple but inefficient for large datasets. Best used for educational purposes or small lists.\n\n\n\n\nDistinct Characteristics:\n\nRepeatedly swaps adjacent elements if they are in the wrong order.\nSimple, but inefficient for large datasets.\n‚ÄúBubbles‚Äù the largest element to the end of the list.\n\n\n\n\n\nBubble Sort Worst, Average and Best\n\nBest Case: \\(O(n)\\) ‚Äî The array is already sorted (with an optimized version that stops early).\nAverage Case: \\(O(n^2)\\) ‚Äî Average case with random elements.\nWorst Case: \\(O(n^2)\\) ‚Äî The array is sorted in reverse order.\n\n\n\n\n\nBubble: Look for something that swaps so the result can ‚Äúbubble‚Äù to the top. (Swap, Exchange)\n\n\n\n\n\n\n\nSelection Sort\n\n\n\nUsageDescriptorStatesTips\n\n\n\nUse Case: Inefficient for large lists, but useful when memory writes are more expensive than comparisons.\n\n\n\n\nDistinct Characteristics:\n\nFinds the minimum element and swaps it with the first unsorted element.\nReduces the problem size by one in each iteration.\nAlways performs \\(O(n^2)\\) comparisons, regardless of input.\n\n\n\n\n\nSelection Sort Worst, Average and Best\n\nBest Case: \\(O(n^2)\\) ‚Äî Selection sort does not improve with better input, always \\(O(n^2)\\).\nAverage Case: \\(O(n^2)\\) ‚Äî Average case with random elements.\nWorst Case: \\(O(n^2)\\) ‚Äî Selection sort is insensitive to input order.\n\n\n\n\n\nSelection: Look for code that repeatedly finds the minimum (or maximum) element and moves it to the beginning (or end) of the list. (Select minimum, Swap with start)\n\n\n\n\n\n\n\nInsertion Sort\n\n\n\nUsageDescriptorStatesTips\n\n\n\nUse Case: Good for small or nearly sorted lists.\n\n\n\n\nDistinct Characteristics:\n\nBuilds a sorted list one element at a time.\nEfficient for small or nearly sorted datasets.\nShifts elements to make space for the current element.\n\n\n\n\n\nInsertion Sort Worst, Average and Best\n\nBest Case: \\(O(n)\\) ‚Äî The array is already sorted.\nAverage Case: \\(O(n^2)\\) ‚Äî Average case with random elements.\nWorst Case: \\(O(n^2)\\) ‚Äî The array is sorted in reverse order.\n\n\n\n\n\nInsertion: Look for code that builds a sorted portion of the list one element at a time by inserting each new element into its correct position within the already-sorted part. (Insert, Shift Element)\n\n\n\n\n\n\n\nMerge Sort\n\n\n\nUsageDescriptorStatesTips\n\n\n\nUse Case: Efficient and stable; good for large datasets.\n\n\n\n\nDistinct Characteristics:\n\nDivides the list into halves, sorts each half, and then merges them.\nStable and efficient for large datasets.\nRequires additional space for merging.\n\n\n\n\n\nMerge Sort Worst, Average and Best\n\nBest Case: \\(\\text{O(n ‚Å°log‚Å° n)}\\) ‚Äî Merge sort‚Äôs time complexity is the same in all cases.\nAverage Case: \\(\\text{O(n ‚Å°log‚Å° n)}\\).\nWorst Case: \\(\\text{O(n ‚Å°log‚Å° n)}\\).\n\n\n\n\n\nMerge: Look for something that continually splits a list in half. (Merge, Split)\n\n\n\n\n\n\n\nQuicksort\n\n\n\nUsageDescriptorStatesTips\n\n\n\nUse Case: Often faster in practice than merge sort but less stable.\n\n\n\n\nDistinct Characteristics:\n\nSelects a ‚Äúpivot‚Äù element and partitions the array around it.\nRecursively sorts the partitions.\nEfficient, but can degrade to \\(O(n^2)\\) if poor pivot selection occurs.\n\n\n\n\n\nQuicksort Worst, Average and Best\n\nBest Case: \\(\\text{O(n ‚Å°log‚Å° n)}\\) ‚Äî The pivot splits the array into two nearly equal halves.\nAverage Case: \\(\\text{O(n ‚Å°log‚Å° n)}\\) ‚Äî Average case with random pivots.\nWorst Case: \\(O(n^2)\\) ‚Äî The pivot is always the smallest or largest element, leading to unbalanced partitions.\n\n\n\n\n\nQuicksort: Look for the keywords ‚Äúpivot‚Äù and/or ‚Äúsplit‚Äù. (Pivot, Split)\n\n\n\n\n\n\n\nHeap Sort\n\n\n\nUsageDescriptorStatesTips\n\n\n\nUse Case: Useful when memory usage is a concern as it‚Äôs an in-place algorithm.\n\n\n\n\nDistinct Characteristics:\n\nUtilizes a binary heap data structure.\nBuilds a max-heap and repeatedly extracts the maximum element.\nEfficient and in-place, but not stable.\n\n\n\n\n\nHeap Sort Worst, Average and Best\n\nBest Case: \\(\\text{O(n ‚Å°log‚Å° n)}\\) ‚Äî Heap sort‚Äôs time complexity is the same in all cases.\nAverage Case: \\(\\text{O(n ‚Å°log‚Å° n)}\\).\nWorst Case: \\(\\text{O(n ‚Å°log‚Å° n)}\\).\n\n\n\n\n\nHeap Sort: Look for code that uses a heap data structure to repeatedly extract the maximum (or minimum) element and rebuilds the heap. (Heapify, Extract Max, Build Heap)\n\n\n\n\n\n\n\nCounting Sort\n\n\n\nUsageDescriptorStates\n\n\n\nUse Case: Efficient for sorting integers or other items with a small range of possible values.\n\n\n\n\nDistinct Characteristics:\n\nNon-comparative sorting.\nCounts occurrences of each element and uses this information to place elements.\nEfficient for small ranges of integers.\n\n\n\n\n\nCounting Sort Worst, Average and Best\n\nBest Case: \\(\\text{O(n ‚Å°+ k) - k}\\) is the range of the input.\nAverage Case: \\(\\text{O(n ‚Å°+ k)}\\).\nWorst Case: \\(\\text{O(n ‚Å°+ k)}\\).\n\n\n\n\n\n\n\n\nRadix Sort\n\n\n\nUsageDescriptorStatesTips\n\n\n\nUse Case: Effective for sorting large numbers or strings with a fixed length.\n\n\n\n\nDistinct Characteristics:\n\nSorts numbers by processing individual digits.\nNon-comparative, stable, and efficient for specific data types.\nOften combined with counting sort.\n\n\n\n\n\nRadix Sort Worst, Average and Best\n\nBest Case: \\(\\text{O(n ‚Å°* k)}\\) ‚Äî k is the number of digits in the largest number.\nAverage Case: \\(\\text{O(n ‚Å°* k)}\\).\nWorst Case: \\(\\text{O(n ‚Å°* k)}\\).\n\n\n\n\n\nRadix Sort: Look for code that sorts numbers based on their individual digits, starting from the least significant digit (LSD) or the most significant digit (MSD). (Count, Frequency, Sum)\n\n\n\n\n\n\n\nBucket Sort\n\n\n\nUsageDescriptorStatesTips\n\n\n\nUse Case: Good for uniformly distributed data.\n\n\n\n\nDistinct Characteristics:\n\nDistributes elements into buckets and sorts each bucket individually.\nEfficient when the input is uniformly distributed.\nOften combined with another sorting algorithm like insertion sort.\n\n\n\n\n\nBucket Sort Worst, Average and Best\n\nBest Case: \\(\\text{O(n + k)}\\) ‚Äî k is the number of buckets; assumes uniform distribution.\nAverage Case: \\(\\text{O(n + k)}\\).\nWorst Case: \\(O(n^2)\\) ‚Äî All elements end up in one bucket (degenerate case).\n\n\n\n\n\nBucket: Look for something that distributes the values into ‚Äúbuckets‚Äù where they are individually sorted. (Bucket)\n\n\n\n\n\n\n\nShell Sort\n\n\n\nDescriptorStatesTips\n\n\n\nDistinct Characteristics:\n\nGeneralization of insertion sort with a gap sequence.\nSorts elements far apart and gradually reduces the gap.\nEfficient for medium-sized datasets.\nTime Complexity: Depends on the gap sequence; commonly \\(\\text{O(n3/2)}\\).\n\n\n\n\n\nShell Sort Worst, Average and Best\n\nBest Case: \\(\\text{O(n log n)}\\) ‚Äî Occurs when the array is already sorted or nearly sorted, especially when using a good gap sequence like the Knuth sequence.\nAverage Case: \\(O(n^(3/2))\\) or \\(O(n^1.5)\\) ‚Äî Highly dependent on the gap sequence used. With commonly used sequences like the Knuth sequence, the average-case complexity is approximately \\(O(n^1.5)\\).\nWorst Case: \\({O(n^2)}\\) ‚Äî Can degrade to \\({O(n^2)}\\), particularly with poorly chosen gap sequences like the original Shell sequence (where the gaps are halved each time)\n\n\n\n\n\nShell Sort: Look for code that sorts elements at specific intervals and gradually reduces the interval until it performs a final insertion sort. (Gap, Interval)\n\n\n\n\n\n\n\n\nSummary\n\n\n\n\n\n\n\n\nSearching & Sorting Algorithms\n\n\n\n\n\n\nLinear Search: Simple, sequential; \\(O(n)\\).\nBinary Search: Sorted data, divide and conquer; \\(\\text{O(log n)}\\).\nBubble Sort: Swaps, bubbles up; \\(O(n^2)\\).\nSelection Sort: Finds minimum, swaps; \\(O(n^2)\\).\nInsertion Sort: Builds sorted list, shifts; \\(O(n^2)\\), \\(O(n)\\) best case.\nMerge Sort: Divide and conquer, merge; \\(\\text{O(n log n)}\\).\nQuick Sort: Pivot, partition; \\(\\text{O(n log n)}\\) average, \\(O(n^2)\\) worst case.\nHeap Sort: Max-heap, extract max; \\(\\text{O(n log n)}\\).\nCounting Sort: Counts occurrences, non-comparative; \\(\\text{O(n + k)}\\).\nRadix Sort: Sorts by digits, non-comparative; \\(O(nk)\\).\nBucket Sort: Distributes into buckets, sorts; \\(\\text{O(n + k)}\\).\nShell Sort: Gap sequence, insertion-like; \\(O(n^3/2)\\).\n\n\n\n\n\n\n\n\n\n\nKey Observations\n\n\n\n\n\n\nBubble Sort, Selection Sort, and Insertion Sort: These are simple but inefficient for large datasets, especially in the worst case.\nMerge Sort and Heap Sort: Stable and consistent in performance, regardless of the input.\nQuick Sort: Very efficient on average but can degrade to \\(O(n^2)\\) in the worst case without proper pivot selection.\nCounting Sort, Radix Sort, and Bucket Sort: Efficient for specific types of data (e.g., integers within a fixed range) but less versatile.\n\n\n\n\n\n\n\n\n\n\nChoosing the Right Algorithm\n\n\n\n\n\n\nSmall datasets: Simpler algorithms like bubble sort, selection sort, or insertion sort might suffice.\nLarge datasets: More efficient algorithms like merge sort, quick sort, or heap sort are preferred.\nSorted data: Algorithms like insertion sort can be very efficient.\nSpecial conditions: Use counting sort, radix sort, or bucket sort if the data is within a certain range or has other specific properties.\n\n\n\n\n\n\n\n\n\nBig O Notation\nWhat is Big O Notation?\n\nBig O Notation: It provides an upper bound on the time or space complexity of an algorithm, representing the worst-case scenario. It‚Äôs a way to describe the efficiency of an algorithm as the input size grows towards infinity.\n\nWhy Use Big O Notation?\n\nComparing Algorithms: It allows us to compare the efficiency of different algorithms independently of hardware or other environmental factors.\nScalability: It helps us understand how an algorithm will perform as the size of the input data grows.\n\n\n\nO Notations\n\n\n\n\n\n\n\nCommon Big Os\n\n\n\n\n\n\nO(1) - Constant Time:\n\nDescription: The algorithm takes the same amount of time to execute regardless of the size of the input.\nExample: Accessing an element in an array by index.\nEfficiency: Excellent.\n\nO(log n) - Logarithmic Time:\n\nDescription: The runtime increases logarithmically as the input size increases. Typically occurs in algorithms that halve the problem size at each step, like binary search.\nExample: Binary search.\nEfficiency: Very good for large inputs.\n\nO(n) - Linear Time:\n\nDescription: The runtime increases linearly with the size of the input. If you double the input size, the runtime also doubles.\nExample: Linear search, iterating through a list.\nEfficiency: Reasonable for moderate to large inputs.\n\nO(n log n) - Log-Linear Time:\n\nDescription: The runtime increases more than linearly but less than quadratically. Common in efficient sorting algorithms like merge sort and quicksort.\nExample: Merge sort, quicksort, heap sort.\nEfficiency: Efficient for large inputs.\n\nO(n^2) - Quadratic Time:\n\nDescription: The runtime increases quadratically with the size of the input. If you double the input size, the runtime quadruples.\nExample: Bubble sort, insertion sort, selection sort (for unsorted arrays).\nEfficiency: Poor for large inputs.\n\nO(2n) - Exponential Time:\n\nDescription: The runtime doubles with each additional element in the input. Common in algorithms that solve problems by brute force or explore all possible solutions.\nExample: Recursive algorithms for the Fibonacci sequence, certain dynamic programming problems.\nEfficiency: Very poor, impractical for large inputs.\n\nO(n!) - Factorial Time:\n\nDescription: The runtime increases factorially with the size of the input. Common in algorithms that generate all permutations of an input set.\nExample: Traveling salesman problem via brute force.\nEfficiency: Extremely poor, infeasible for even moderate input sizes.\n\n\n\n\n\n\n\n\n\n\n\nTime Complexity\n\n\n\n\n\nBest Case, Worst Case, and Average Case\n\nBest Case: The scenario where the algorithm performs the minimum possible number of operations. It‚Äôs often less relevant because it‚Äôs optimistic.\n\nExample: For linear search, the best case is \\(O(1)\\), where the target element is the first one in the array.\n\nWorst Case: The scenario where the algorithm performs the maximum possible number of operations. Big O notation typically describes the worst-case complexity.\n\nExample: For linear search, the worst case is \\(O(n)\\), where the target element is the last one in the array or isn‚Äôt present at all.\n\nAverage Case: The scenario that represents the expected number of operations for a typical input. It‚Äôs more complex to calculate because it depends on the distribution of inputs.\n\nExample: For linear search, the average case is \\(O(n/2)\\), but in Big O notation, we simplify this to \\(O(n)\\).\n\n\n\n\n\n\n\n\n\n\n\nCalculation Rules\n\n\n\n\n\nIgnore Constants:\n\nRule: In Big O notation, constant factors are ignored.\nWhy: Big O notation focuses on the growth rate as the input size \\((n)\\) increases, so a constant multiplier doesn‚Äôt affect the growth rate.\nExample: \\(O(2n)\\) simplifies to \\(O(n)\\)\n\nFocus on the Dominant Term:\n\nRule: Only the term with the highest growth rate is considered.\nWhy: As n becomes large, the term with the highest growth rate will dominate the others.\nExample: \\(O(n2+n)\\) simplifies to \\(O(n2)\\)\n\nDrop Lower Order Terms:\n\nRule: Lower-order terms are ignored because they become insignificant as n grows.\nWhy: Similar to focusing on the dominant term, lower-order terms have a negligible impact on large inputs.\nExample: \\(O(n2 + n + log n)\\) simplifies to \\(O(n2)\\)\n\nMultiplicative Constants Can Be Ignored: - Rule: Coefficients that multiply variables (e.g., 2n, 3n^2) are ignored. - Why: Like constants, they don‚Äôt change the growth rate. - Example: \\(O(3n2)\\) simplifies to \\(O(n2)\\)\nAdditive Constants Can Be Ignored:\n\nRule: Constant terms that don‚Äôt depend on n are ignored.\nWhy: They don‚Äôt affect the overall growth rate as n increases.\nExample: \\(O(n+10)\\) simplifies to \\(O(n)\\)\n\nLogarithms with Different Bases:\n\nRule: Logarithms with different bases can be considered equivalent in Big O notation.\nWhy: Changing the base of a logarithm only introduces a constant factor, which is ignored in Big O notation.\nExample: \\(\\text{O(log‚Å°2 n)}\\) simplifies to \\(\\text{O(log‚Å° n)}\\)\n\nNon-Dominant Polynomial Terms:\n\nRule: In polynomials, only the highest degree term is considered.\nWhy: As n grows large, the highest degree term will dominate.\nExample: \\(\\text{O(5n3 + 2n2 + 7)}\\) simplifies to \\(O(n3)\\)\n\nExponential Growth:\n\nRule: Exponential growth functions dominate polynomial functions.\nWhy: Exponential functions grow much faster than polynomial functions as n increases.\nExample: \\(\\text{O(2n + n3)}\\) simplifies to \\(O(2n)\\)\n\nNested Loops:\n\nRule: The time complexity of nested loops is the product of the complexities of each loop.\nWhy: Each loop iterates based on the input size, so their combined effect is multiplicative.\nExample: A loop inside another loop both running n times results in \\(\\text{O(n * n) = O(n2)}\\)\n\nSequential Statements:\n\nRule: If two independent statements (or loops) are executed sequentially, their time complexities are added.\nWhy: Sequential operations don‚Äôt multiply time complexity, but rather add up.\nExample: Two loops each running n times sequentially result in \\(\\text{O(n + n) = O(n)}\\)",
    "crumbs": [
      "Data Structures"
    ]
  },
  {
    "objectID": "courseC949.html#determines-data-structure-impact---31",
    "href": "courseC949.html#determines-data-structure-impact---31",
    "title": "Data Structures",
    "section": "Determines Data Structure Impact - (31%)",
    "text": "Determines Data Structure Impact - (31%)\n\nImplementation of Data Structures\n\n\nData Types\n\n\n\nDefinitionExamplesExtra\n\n\nWhat is a Data Type?\nDefinition: A data type is a classification that specifies the type of data that a variable can hold in programming. It defines the operations that can be performed on the data and the way the data is stored in memory.\n\n\n\nPrimitive Data Types: These are the basic building blocks of data in a programming language.\n\nInteger (e.g., int in C, Java): Holds whole numbers.\nFloating Point (e.g., float, double): Holds numbers with fractional parts.\nCharacter (e.g., char): Holds a single character.\nBoolean (e.g., bool): Holds a true or false value.\n\nComposite Data Types: These are constructed from primitive types.\n\nArrays: A collection of elements of the same data type.\nStructures (e.g., struct in C): A collection of different data types.\n\nUser-Defined Data Types: Created by the user, typically by combining primitive data types.\n\nEnumerations (enum), Classes, etc.\n\n\n\n\nEnumeration:\n\nEnumeration, often referred to as ‚Äúenum,‚Äù is a data type in programming that allows a variable to be a set of predefined constants.\nThese constants are typically related and represent a set of possible values that a variable of the enumeration type can hold.\nEnums improve code readability, make it easier to manage sets of related values, and reduce errors by limiting the values a variable can take.\n\nKey Concepts of Enumeration:\n\nDefinition: An enumeration is defined using the enum keyword (syntax can vary by language). It consists of a set of named constants, each representing a unique value.\nValues: The values in an enum are usually integers by default, starting from 0, but they can be assigned specific values as needed.\nUsage: Enums are commonly used when a variable can only take one out of a small set of possible values, like days of the week, directions, states, etc.\n\nExample in Different Languages:\nC/C++\n\nenum Direction {\n    NORTH,\n    EAST,\n    SOUTH,\n    WEST\n};\n\nDirection dir = NORTH;\n\nJava\n\npublic enum Direction {\n    NORTH,\n    EAST,\n    SOUTH,\n    WEST\n}\n\nDirection dir = Direction.NORTH;\n\nPython (using enum module)\n\nfrom enum import Enum\n\nclass Direction(Enum):\n    NORTH = 1\n    EAST = 2\n    SOUTH = 3\n    WEST = 4\n\ndir = Direction.NORTH\n\nAdvantages of Using Enums: - Readability: Code is easier to read and understand. - Maintainability: Easier to update and maintain related values. - Type Safety: Prevents assigning invalid values to variables of the enum type.\nEnums are useful in scenarios where a variable should only be allowed to take one out of a small set of specific values, helping prevent errors and making the code clearer and more reliable.\nKey Characteristics: - Memory Allocation: Data types determine how much memory is allocated for storing the data. - Operations: Each data type supports a set of operations, like arithmetic operations for integers or concatenation for strings.\n\n\n\n\n\n\nData Structures\n\n\n\nDefinitionExamples\n\n\nWhat is a Data Structure?\n\nDefinition: A data structure is a specific way of organizing and storing data in a computer so that it can be accessed and modified efficiently. Data structures use data types as their underlying foundation.\n\n\n\n\nArrays: A collection of elements stored in contiguous memory locations.\nLinked Lists: A series of connected nodes, where each node contains data and a reference to the next node.\nStacks: A collection of elements with Last-In-First-Out (LIFO) access.\nQueues: A collection of elements with First-In-First-Out (FIFO) access.\nTrees: A hierarchical structure with a root element and sub-elements called nodes.\nGraphs: A collection of nodes (vertices) connected by edges.\nHash Tables: A data structure that maps keys to values for efficient lookup.\n\n\n\n\n\n\n\nAbstract Data Types (ADTs)\n\n\n\nDefinitionExamples\n\n\n\nDefinition: An abstract data type (ADT) is a theoretical model of a data structure that defines the behavior from the user‚Äôs point of view, without specifying the underlying implementation. It specifies the operations that can be performed and the expected behavior but not how these operations are carried out.\n\n\n\n\nList ADT: Operations include insertion, deletion, and access by index.\nStack ADT: Operations include push, pop, and peek.\nQueue ADT: Operations include enqueue and dequeue.\nMap (or Dictionary) ADT: Operations include inserting, deleting, and searching for key-value pairs.\n\n\n\n\n\n\n\nDifferences\n\n\n\n1. Abstraction2. Purpose3. Implementation4. Examples\n\n\n\nData Types: The most basic level; concerned with how data is stored and what operations are allowed.\nData Structures: A step higher in abstraction; concerned with how data is organized and accessed.\nADTs: The highest level of abstraction; concerned with the operations and behavior of a data structure, abstracted away from the implementation details.\n\n\n\n\nData Types: Define the type and nature of the data.\nData Structures: Provide a way to organize and manage data efficiently.\nADTs: Define a blueprint for data structures, focusing on what operations can be performed and what their expected behavior is.\n\n\n\n\nData Types: Directly supported by the programming language.\nData Structures: Built using data types and can be complex.\nADTs: Can be implemented using various data structures; the choice of implementation depends on the specific needs like performance and memory usage.\n\n\n\n\nData Types: int, float, char, bool\nData Structures: Arrays, linked lists, trees, hash tables\nADTs: Stack, queue, list, set, map\n\n\n\n\n\n\n\nArray\n\n\n\n1. Description2. Operations3. Usage\n\n\n\nAn array is a collection of homogeneous elements stored in contiguous memory locations. Each element in the array can be accessed using its index.\nPython Equivalent: list\n\n\n\n\nAccess: \\(O(1)\\) ‚Äî Direct access to elements via index.\nSearch:\n\nLinear Search: \\(O(n)\\)\nBinary Search: \\(\\text{O(log‚Å° n)}\\) (only if the array is sorted)\n\nInsertion:\n\nAt the End: Append the element to the end of the array. If the array is full (fixed size), you may need to resize it.\n\nTime Complexity: \\(O(1)\\) (amortized if resizing is needed).\n\nAt a Specific Index: Shift elements to the right from the index to create space, then insert the new element.\n\nTime Complexity: \\(O(n)\\), where n is the number of elements after the insertion point.\n\n\nDeletion:\n\nFrom the End: Remove the last element.\n\nTime Complexity: \\(O(1)\\).\n\nFrom a Specific Index: Shift elements to the left to fill the gap left by the removed element.\n\nTime Complexity: \\(O(n)\\), where n is the number of elements after the removal point.\n\n\n\n\n\n\nUse Cases:\n\nSuitable for scenarios where fast access to elements is required, and the size of the data set is known.\n\n\n\n\n\n\n\n\nLinked List\n\n\n\nDescriptionTypesOperationsUsage\n\n\n\nA linked list is a linear collection of elements called nodes, where each node contains data and a reference (or pointer) to the next node in the sequence.\nPython Equivalent: Custom class with Node and LinkedList classes\n\n\n\n\nSingly Linked List: Each node points to the next node.\nDoubly Linked List: Each node points to both the next and previous nodes.\nCircular Linked List: The last node points back to the first node, forming a loop.\n\n\n\n\nAccess: \\(O(n)\\) ‚Äî Requires traversal from the head to the desired node.\nSearch: \\(O(n)\\) ‚Äî Requires traversal to find the target element.\nInsertion:\n\nAt the Beginning (Singly/ Doubly Linked List): Create a new node and adjust the head (and possibly tail in a doubly linked list).\n\nTime Complexity: \\(O(1)\\).\n\nAt the End (Singly Linked List): Traverse to the last node, then insert the new node.\n\nTime Complexity: \\(O(n)\\).\n\nAt a Specific Position: Traverse to the position and insert the node, adjusting the pointers.\n\nTime Complexity: \\(O(n)\\).\n\n\nDeletion:\n\nFrom the Beginning: Adjust the head pointer to the next node.\n\nTime Complexity: \\(O(1)\\).\n\nFrom the End: Traverse to the second last node, adjust its pointer to null.\n\nTime Complexity: \\(O(n)\\).\n\nFrom a Specific Position: Traverse to the node before the one to remove, then adjust pointers to bypass the removed node.\n\nTime Complexity: \\(O(n)\\).\n\n\n\n\n\n\nUse Cases:\n\nUseful when the size of the data set is unknown or when frequent insertions and deletions are required.\n\n\n\n\n\n\n\n\nMethods for Lists/Arrays\n\n\n\nI ‚Ä¶II ‚Ä¶III ‚Ä¶IV ‚Ä¶V ‚Ä¶\n\n\n\nappend()\n\nDescription: Adds an element to the end of the list.\nSyntax: list.append(element)\n\n\nExample:\n\nfruits = [\"apple\", \"banana\"]\nfruits.append(\"orange\")\nprint(fruits)  # Output: ['apple', 'banana', 'orange']\n\n['apple', 'banana', 'orange']\n\n\n\nextend()\n\nDescription: Extends the list by appending elements from another iterable (e.g., another list).\nSyntax: list.extend(iterable)\n\n\nExample:\n\nnumbers = [1, 2, 3]\nnumbers.extend([4, 5])\nprint(numbers)  # Output: [1, 2, 3, 4, 5]\n\n[1, 2, 3, 4, 5]\n\n\n\n\n\ninsert() - Description: Inserts an element at a specific index in the list. - Syntax: list.insert(index, element)\nExample:\n\nfruits = [\"apple\", \"banana\"]\nfruits.insert(1, \"orange\")\nprint(fruits)  # Output: ['apple', 'orange', 'banana']\n\n['apple', 'orange', 'banana']\n\n\n\nremove()\n\nDescription: Removes the first occurrence of a specified value from the list.\nSyntax: list.remove(element)\n\n\nExample:\n\nfruits = [\"apple\", \"banana\", \"orange\"]\nfruits.remove(\"banana\")\nprint(fruits)  # Output: ['apple', 'orange']\n\n['apple', 'orange']\n\n\n\n\n\n\npop()\n\nDescription: Removes and returns the element at the specified index. If no index is specified, it removes and returns the last element.\nSyntax: list.pop(index)\n\n\nExample:\n\nfruits = [\"apple\", \"banana\", \"orange\"]\nlast_fruit = fruits.pop()\nprint(last_fruit)  # Output: 'orange'\n\norange\n\nprint(fruits)      # Output: ['apple', 'banana']\n\n['apple', 'banana']\n\n\n\nindex()\n\nDescription: Returns the index of the first occurrence of a specified value.\nSyntax: list.index(element, start, end)\n\n\nExample:\n\nfruits = [\"apple\", \"banana\", \"orange\"]\nindex_of_banana = fruits.index(\"banana\")\nprint(index_of_banana)  # Output: 1\n\n1\n\n\n\n\n\n\ncount()\n\nDescription: Returns the number of occurrences of a specified value in the list.\nSyntax: list.count(element)\n\n\nExample:\n\nfruits = [\"apple\", \"banana\", \"orange\", \"banana\"]\ncount_of_banana = fruits.count(\"banana\")\nprint(count_of_banana)  # Output: 2\n\n2\n\n\n\nsort()\n\nDescription: Sorts the elements of the list in ascending order (or descending order if specified) in place.\nSyntax: list.sort(reverse=False)\n\n\nExample:\n\nnumbers = [3, 1, 4, 1, 5, 9]\nnumbers.sort()\nprint(numbers)  # Output: [1, 1, 3, 4, 5, 9]\n\n[1, 1, 3, 4, 5, 9]\n\n\n\n\n\n\nreverse()\n\nDescription: Reverses the elements of the list in place.\nSyntax: list.reverse()\n\n\nExample:\n\nnumbers = [1, 2, 3, 4]\nnumbers.reverse()\nprint(numbers)  # Output: [4, 3, 2, 1]\n\n[4, 3, 2, 1]\n\n\n\ncopy()\n\nDescription: Returns a shallow copy of the list.\nSyntax: list.copy()\n\n\nExample:\n\nfruits = [\"apple\", \"banana\", \"orange\"]\nfruits_copy = fruits.copy()\nprint(fruits_copy)  # Output: ['apple', 'banana', 'orange']\n\n['apple', 'banana', 'orange']\n\n\n\nJava ArrayList Methods\n\n**add():** Adds an element to the end of the list.\n**remove():** Removes the first occurrence of a specified element.\n**get():** Retrieves the element at a specified index.\n**set():** Replaces the element at a specified index with a new element.\n**size():** Returns the number of elements in the list.\n\n\n\n\n\n\n\n\nRecord\n\nA Record is a composite data structure used to store a collection of related fields, each with a specific name and data type.\nIt is commonly used to model entities in databases and programming, allowing for structured and organized data storage.\nRecords are versatile and can represent complex objects with multiple attributes, making them essential in many applications.\nIn Python, a Record is typically implemented as a class, a namedtuple, or a dataclass. Each of these provides a way to group multiple fields (attributes) together under one name, similar to how a record in other languages might work.\n\n\n\n\nStack\n\n\n\nDescriptionOperationsUsage\n\n\n\nA stack is a linear data structure that follows the Last-In-First-Out (LIFO) principle, meaning the last element added is the first one to be removed.\nPython Equivalent: list or collections.deque\n\n\n\n\nPush (Insertion): \\(O(1)\\) ‚Äî Add an element to the top of the stack.\nPop (Deletion): \\(O(1)\\) ‚Äî Remove the top element from the stack.\nPeek/Top: \\(O(1)\\) ‚Äî View the top element without removing it.\nIsEmpty: \\(O(1)\\) ‚Äî Check if the stack is empty.\n\n\n\n\nUse Cases:\n\nUsed in expression evaluation, backtracking algorithms, undo mechanisms in applications, and for maintaining function call stacks in recursion.\n\n\n\n\n\n\n\n\nBag\n\n\n\nDescriptionOperationsUsage\n\n\n\nA Bag (also known as a multiset) is a simple data structure that allows for storing a collection of elements where duplicate elements are allowed. Unlike a set, which requires all elements to be unique, a bag can contain multiple occurrences of the same element.\nPython Equivalent: collections.Counter\n\n\n\n\nAdd (add) ‚Äî Adds an element to the bag.\n\nSimply add the element, usually at the end or beginning, depending on the implementation (array, linked list, etc.).\n\nTime Complexity: \\(O(1)\\).\n\n\nCheck Membership (contains) ‚Äî Checks if an element is in the bag.\nCount Occurrences (count) ‚Äî Counts how many times an element appears in the bag.\nRemove (remove) ‚Äî Removes one occurrence of an element from the bag.\n\nTypically, bags do not have a direct remove operation unless implemented, in which case:\n\nRemove Specific Element: Find the element and remove it, adjusting structure accordingly.\n\nTime Complexity: \\(O(n)\\).\n\n\n\nGet Size (size) ‚Äî Returns the total number of elements in the bag, including duplicates.\n\n\n\n\nUse Cases:\n\nA bag is useful when you need to count the number of occurrences of items, such as counting words in a document.\n\n\n\n\n\n\n\n\nQueue\n\n\n\nDescriptionOperationsUsage\n\n\n\nA queue is a linear data structure that follows the First-In-First-Out (FIFO) principle, meaning the first element added is the first one to be removed.\nPython Equivalent: collections.deque or queue.Queue\n\n\n\n\nEnqueue (Insertion/Push): \\(O(1)\\) ‚Äî Add an element to the end of the queue.\nDequeue (Deletion/Pop): \\(O(1)\\) ‚Äî Remove the front element from the queue.\nFront/Peek: \\(O(1)\\) ‚Äî View the front element without removing it.\nIsEmpty: \\(O(1)\\) ‚Äî Check if the queue is empty.\n\n\n\n\nUse Cases:\n\nUseful in scheduling processes, managing tasks in order, breadth-first search (BFS) algorithms, and handling requests in servers.\n\n\n\n\n\n\n\n\nDeque\n\n\n\nDescriptionOperationsUsage\n\n\n\nA deque is a linear data structure that allows insertion and deletion of elements from both the front and rear ends.\nPython Equivalent: collections.deque\n\n\n\n\nInsertFront: \\(O(1)\\) ‚Äî Add an element to the front.\nInsertLast: \\(O(1)\\) ‚Äî Add an element to the end.\nDeleteFront: \\(O(1)\\) ‚Äî Remove an element from the front.\nDeleteLast: \\(O(1)\\) ‚Äî Remove an element from the end.\nPeekFront: \\(O(1)\\) ‚Äî View the front element.\nPeekLast: \\(O(1)\\) ‚Äî View the last element.\nIsEmpty: \\(O(1)\\) ‚Äî Check if the deque is empty.\n\n\n\n\nUse Cases:\n\nUseful in scenarios requiring access from both ends, such as the implementation of both stacks and queues, task scheduling, and sliding window algorithms.\n\n\n\n\n\n\n\n\n\n\n\n\n\nHash Table\n\n\n\n\n\n\nDescriptions\n\nA hash table is a data structure that maps keys to values using a hash function, which transforms the key into an index in an array.\nPython Equivalent: dict\n\n\n\n\nOperations\n\nInsert: \\(O(1)\\) ‚Äî Map a key to a value by computing its hash.\nSearch: \\(O(1)\\) ‚Äî Retrieve the value associated with a given key.\nDelete: \\(O(1)\\) ‚Äî Remove the key-value pair from the table.\n\n\n\n\nUsage\n\nUse Cases:\n\nHighly efficient for scenarios requiring fast lookups, such as databases, caches, and dictionaries.\n\n\n\n\n\nCollisions\n\nHandling Collisions:\n\nChaining: Store multiple elements at the same index using a linked list.\nOpen Addressing (Probing): Find another open slot using techniques like linear probing, quadratic probing, or double hashing.\n\n\n\n\n\nHashing\n\nHashing\n\nHashing is the process of mapping keys to indices in an array using a hash function. It ensures efficient data retrieval by minimizing the number of comparisons required.\n\n\nHash Function - A hash function is a function that converts input (key) into a fixed-size value, typically an integer, which serves as an index in the hash table array. - A good hash function has the following properties:\n  - **Deterministic:** The same key always produces the same hash value.\n  - **Uniform Distribution:** The hash values should be distributed uniformly across the array to minimize collisions.\n  - **Fast Computation:** The function should be quick to compute.\n\nHash Keys\n\nHash Key: The key for which the hash function generates an index.\nHash Value: The integer index produced by the hash function.\n\n\n\n\n\nHow to perform hash function on calculator\nTo determine where the data associated with the last 4 digits of the Social Security number (‚Äò2023‚Äô) will be stored in the array, follow these steps:\n1. Understand the Hash Function: The problem specifies a hash function given by key % 1009. Here, % denotes the modulus operation. This operation returns the remainder of the division of key by 1009.\n2. Determine the Key: The last 4 digits of the Social Security number are ‚Äò2023‚Äô. Therefore, the key you‚Äôre interested in is 2023.\n3. Apply the Hash Function: Use the hash function to find the index in the array where the data should be stored. Specifically, you need to compute:\na. Key / Hash - (whole number in result) * Hash\n  i. For this example\n    1. $(2023 / 1009) = 2.004955401$\n    2. $2.004955401 - 2 = 0.004955401$\n    3. $0.004955401 * 1009 = 5$\n4. By calculating the remainder, you will find the index in the array soc where the data associated with the key ‚Äò2023‚Äô will be stored.\na. soc[5]\n\n\n\n\n\n\n\n\nTrees\n\n\n\n\n\n\n\n\nTree\n\n\n\n\n\n\n\nDescription\n\nA tree is a hierarchical data structure composed of nodes, where each node contains a value and references to child nodes. The top node is called the root, and nodes with no children are called leaves.\nPython Equivalent: Custom class with Node and Tree classes\n\n\n\n\nTypes\n\nBinary Tree: Each node has at most two children (left and right).\nBinary Search Tree (BST): A binary tree where the left child contains values less than the parent, and the right child contains values greater than the parent.\nAVL Tree: A self-balancing binary search tree.\nRed-Black Tree: Another type of self-balancing binary search tree.\nB-Tree: A self-balancing tree that maintains sorted data and allows searches, sequential access, insertions, and deletions in logarithmic time.\n\n\n\n\nForms\n\nFull Binary Tree ‚Äî Definition: A binary tree in which every node has either 0 or 2 children.\nComplete Binary Tree ‚Äî Definition: A binary tree in which all levels are completely filled except possibly the last level, which is filled from left to right.\nPerfect Binary Tree ‚Äî Definition: A binary tree in which all interior nodes have two children and all leaves are at the same level.\nBalanced Binary Tree ‚Äî Definition: A binary tree where the height of the left and right subtrees of any node differ by at most one.\n\n\n\n\nOperations\n\nInsertion: \\(\\text{O(log ‚Å°n)}\\) for balanced trees like AVL or Red-Black Trees; \\(O(n)\\) for unbalanced trees.\nDeletion: \\(\\text{O(log ‚Å°n)}\\) for balanced trees; \\(O(n)\\) for unbalanced trees.\n\nBST: Find the node to be removed, then:\n\nNo Children: Just remove the node.\nOne Child: Bypass the node and link its parent directly to its child.\nTwo Children: Find the in-order predecessor (or successor), swap values, and remove the predecessor (or successor) node.\nTime Complexity: \\(\\text{O(log n)}\\) on average, \\(O(n)\\) in the worst case.\n\n\nSearch: \\(\\text{O(log ‚Å°n)}\\) for balanced trees; \\(O(n)\\) for unbalanced trees.\nTraversal:\n\nIn-order: \\(O(n)\\) ‚Äî Left, Root, Right (used in BSTs to get sorted order).\nPre-order: \\(O(n)\\) ‚Äî Root, Left, Right.\nPost-order: \\(O(n)\\) ‚Äî Left, Right, Root.\nLevel-order: \\(O(n)\\)‚Äî Traverse nodes level by level.\n\n\n\n\n\nUsage\n\nUse Cases:\n\nSuitable for hierarchical data (like file systems), database indexing, and scenarios requiring sorted data with dynamic insertion and deletion.\n\n\n\n\n\n\n\n\n\nAdelson-Velsky and Landis Trees\n\n\n\n\n\n\n\n\nAVL Trees\n\n\n\n\n\n\n\nProperties\n\nAn AVL tree is a binary search tree in which the height of the two child subtrees of any node differs by at most one.\nIf at any time during insertion or deletion this condition is violated, the tree is rebalanced through rotations.\n\n\n\n\nBalancing\n\nSingle Rotation: Used when a node is inserted into the left subtree of the left child or the right subtree of the right child.\nDouble Rotation: Used when a node is inserted into the left subtree of the right child or the right subtree of the left child.\n\n\n\n\nTime\n\nTime Complexity:\n\nSearch, Insertion, Deletion: \\(\\text{O(log n)}\\), where n is the number of nodes.\n\n\n\n\n\nUsage\n\nUse Cases:\n\nAVL trees are well-suited for applications where frequent insertions and deletions occur, and maintaining strict balance is important.\n\n\n\n\n\n\n\n\n\nRed-Black\n\n\n\n\n\n\n\n\nRed-Black Trees\n\n\n\n\n\n\n\nProperties\n\nA Red-Black tree is a binary search tree with an extra bit of storage per node: its color, which can be either red or black.\nThe tree satisfies several properties:\n\nEvery node is either red or black.\nThe root is always black.\nAll leaves (NIL nodes) are black.\nRed nodes cannot have red children (no two red nodes can be adjacent).\nEvery path from a node to its descendant NIL nodes must have the same number of black nodes (black height).\n\n\n\n\n\nBalancing\n\nThe tree is kept balanced by performing rotations and color changes during insertions and deletions.\n\n\n\n\nTime\n\nTime Complexity:\n\nSearch, Insertion, Deletion: \\(\\text{O(log n)}\\).\n\n\n\n\n\nUsage\n\nUse Cases:\n\nRed-Black trees are used in many systems, such as the Linux kernel‚Äôs process scheduling and in standard libraries like C++‚Äôs std::map and std::set, due to their relatively simple implementation and good performance.\n\n\n\n\n\n\n\n\n\nBalanced Tree\n\n\n\n\n\n\n\n\nB-Trees\n\n\n\n\n\n\n\nProperties\n\nA B-tree is a self-balancing search tree in which nodes can have more than two children. It‚Äôs commonly used in databases and file systems.\nA B-tree of order m can have at most m-1 keys and m children.\nAll leaf nodes are at the same depth, and internal nodes act as a guide to direct searches.\n\n\n\n\nBalancing\n\nBalancing in B-trees is achieved through splitting and merging nodes.\nWhen a node in a B-tree becomes too full (i.e., has more than m-1 keys), it is split into two nodes, and the middle key is pushed up to the parent node.\nWhen a node has too few keys, it may borrow keys from its neighbors or merge with a neighboring node.\n\n\n\n\nTime\n\nTime Complexity:\n\nSearch, Insertion, Deletion: \\(\\text{O(log n)}\\).\n\n\n\n\n\nUsage\n\nUse Cases:\n\nB-trees are particularly effective for systems that read and write large blocks of data, such as databases and file systems, where minimizing disk I/O operations is critical.\n\n\n\n\n\n\n\n\n\n\nWrap-up\n\n\n\n\n\n\n\n\nComparison Summary\n\n\n\n\n\n\nAVL Trees: Strictly balanced, more rotations, better for search-heavy applications.\nRed-Black Trees: Looser balancing, fewer rotations, generally faster insertions and deletions.\nB-Trees: Optimized for storage systems, used in databases, and file systems for handling large volumes of data.\n\n\n\n\n\n\n\n\n\n\nTree Traversal\n\n\n\n\n\n\nPre-Order Traversal (NLR) - Node, Left, Right\nIn-Order Traversal (LNR) - Left, Node, Right\nPost-Order Traversal (LRN) - Left, Right, Node\n\n\n\n\n\n\n\n\nPre-Order Traversal (NLR)\n\n\n\nOrder:Process:Examples:\n\n\n\nNode ‚Üí Left ‚Üí Right\n\n\n\n\nVisit the Node first.\nThen recursively visit the Left subtree.\nFinally, visit the Right subtree.\n\n\n\nIf you have a tree like this:\n\n    A\n   / \\\n  B   C\n / \\\nD   E\n\n\nThe Pre-Order traversal would be: A B D E C\n\n\n\n\n\n\nIn-Order Traversal (LNR)\n\n\n\nOrder:Process:Example:\n\n\n\nLeft ‚Üí Node ‚Üí Right\n\n\n\n\nRecursively visit the Left subtree.\nThen visit the Node.\nFinally, visit the Right subtree.\n\n\n\nFor the same tree:\n\n    A\n   / \\\n  B   C\n / \\\nD   E\n\n\nThe In-Order traversal would be: D B E A C\n\n\n\n\n\n\nPost-Order Traversal (LRN)\n\n\n\nOrder:Process:Examples:\n\n\n\nLeft ‚Üí Right ‚Üí Node\n\n\n\n\nRecursively visit the Left subtree.\nThen visit the Right subtree.\nFinally, visit the Node.\n\n\n\nFor the same tree:\n\n    A\n   / \\\n  B   C\n / \\\nD   E\n\n\nThe Post-Order traversal would be: D E B C A\n\n\n\n\n\n\n\nWrap-up\n\n\n\n\n\n\n\n\nHow to Remember Them:\n\n\n\n\n\n\nPre-Order (NLR): Think of ‚ÄúPre‚Äù as ‚Äúbefore‚Äù - you process the Node before anything else.\nIn-Order (LNR): ‚ÄúIn‚Äù implies ‚Äúin between‚Äù - the Node is processed in between the Left and Right subtrees.\nPost-Order (LRN): ‚ÄúPost‚Äù means ‚Äúafter‚Äù - the Node is processed after the subtrees.\n\n\n\n\n\n\n\n\n\n\nVisual Mnemonic:\n\n\n\n\n\n\nPre-Order: Imagine starting at the root and touching it first.\nIn-Order: Imagine walking along the edge of the tree, touching the left side first, then the root, and then the right side.\nPost-Order: Imagine leaving the tree by processing the children before the root.\n\n\n\n\n\n\n\n\nHeap\n\n\n\nDescription:Operations:Use Cases:\n\n\n\nA heap is a specialized tree-based data structure that satisfies the heap property. In a max-heap, the parent node is always greater than or equal to its children; in a min-heap, the parent node is always less than or equal to its children.\nPython Equivalent: heapq (min-heap by default)\n\n\n\n\nInsert: \\(\\text{O(log ‚Å°n)}\\) ‚Äî Add a new element and adjust the heap to maintain the heap property.\n\nAdd the Element at the End:\n\nInsert the new element at the end of the heap (i.e., the next available leaf node).\n\nHeapify Up (Percolate Up):\n\nCompare the inserted element with its parent node.\nIf the heap property (Min-Heap or Max-Heap) is violated (e.g., in a Min-Heap, if the new element is smaller than its parent), swap the element with its parent.\nRepeat the process until the heap property is restored or the element becomes the root.\n\n\nDeleteMax/Min: \\(\\text{O(log ‚Å°n)}\\) ‚Äî Remove the root (max or min) and adjust the heap.\n\nRemove the Root Element:\n\nThe root element of the heap (the smallest element in a Min-Heap or the largest in a Max-Heap) is removed. This is because the root element has the highest priority.\n\nReplace the Root with the Last Element:\n\nMove the last element in the heap (the rightmost leaf node) to the root position.\n\nHeapify Down (Percolate Down):\n\nCompare the new root element with its children.\nIf the heap property is violated (e.g., in a Min-Heap, if the root is greater than any of its children), swap the root with the smallest child (in a Max-Heap, swap with the largest child).\nRepeat the process down the tree until the heap property is restored.\n\n\nPeekMax/Min: \\(O(1)\\) ‚Äî Access the root element.\nHeapify: \\(O(n)\\) ‚Äî Convert an unsorted array into a heap.\n\n\n\n\nOften used to implement priority queues, scheduling algorithms, and for efficient sorting (Heap Sort).\n\n\n\n\n\n\n\nSteps To Figure Out The Index Of Child Nodes in Heaps\n\n\n\n\n\n\n\n\nThe Index Of The Right Child Of An Item In A Heap\n\n\n\n\n\nheapList = [22, 33, 44, 55, 66]\n\nIdentify the index of the item:\n\nFind the index of the item 22 in the heap list. Let‚Äôs call this index \\(i\\).\n\nUse the formula for the right child:\n\nIn a binary heap, if an element is at index \\(i\\), the index of its right child is given by the formula: \\(2i + 2\\).\n\nApply the formula:\n\nSubstitute the value of \\(i\\) obtained from step 1 into the formula \\(2i+2\\).\n\nVerify the index:\n\nEnsure the calculated index falls within the bounds of the heap list.\n\n\n\n\n\n\n\n\n\n\n\nThe Index Of The Left Child Of An Item In A Heap\n\n\n\n\n\nheapList = [22, 33, 44, 55, 66]\n\nIdentify the index of the item:\n\nFind the index of the item in the heap list. Let‚Äôs call this index \\(i\\).\n\nUse the formula for the left child:\n\nIn a binary heap, if an element is at index \\(i\\), the index of its left child is given by the formula: \\(2i+1\\).\n\nApply the formula:\n\nSubstitute the value of \\(iii\\) obtained from step 1 into the formula \\(2i+1\\).\n\nVerify the index:\n\nEnsure the calculated index falls within the bounds of the heap list.\n\n\n\n\n\n\n\n\n\nSet\n\n\n\nDescription:Operations:Usage:\n\n\n\nA set is an abstract data structure that stores unique elements, with no specific order. It supports operations that allow the management of unique collections of data.\nPython Equivalent: set\n\n\n\n\nInsert: \\(O(1)\\) on average ‚Äî Add a new element if it‚Äôs not already present.\nDelete: \\(O(1)\\) on average ‚Äî Remove an element if it exists.\nSearch: \\(O(1)\\) on average ‚Äî Check if an element is present in the set.\nUnion: \\(O(n)\\) ‚Äî Combine elements from two sets.\nIntersection: \\(O(n)\\) ‚Äî Get common elements between two sets.\nDifference: \\(O(n)\\) ‚Äî Get elements present in one set but not the other.\n\n\n\n\nUseful in situations requiring the management of unique elements, such as maintaining a list of unique IDs, handling membership checks, and performing mathematical set operations.\n\n\n\n\n\n\nGraph\n\n\n\nDescription:Types:Operations:Usage:\n\n\n\nA graph is a collection of nodes (vertices) connected by edges. Graphs can be directed (edges have a direction) or undirected (edges do not have a direction).\nPython Equivalent: dict of lists, collections.defaultdict, or custom class\n\n\n\n\nDirected Graph (Digraph): All edges have a direction.\nUndirected Graph: Edges do not have direction.\nWeighted Graph: Edges have weights representing costs or distances.\nUnweighted Graph: Edges have no weights.\n\n\n\n\nAdd Vertex: \\(O(1)\\) ‚Äî Add a new node.\n\nVertex: Simply add the vertex to the vertex set.\n\nTime Complexity: \\(O(1)\\).\n\n\nAdd Edge: \\(O(1)\\) ‚Äî Add a connection between two nodes.\n\nEdge: Add an edge by connecting two vertices, updating adjacency lists or matrices.\n\nTime Complexity: \\(O(1)\\) for adjacency list, \\(O(1)\\) for adjacency matrix.\n\n\nRemove Vertex: \\(O(V+E)\\) ‚Äî Remove a node and its associated edges.\n\nVertex: Remove the vertex and all associated edges.\n\nTime Complexity: \\(\\text{O(V + E)}\\) in an adjacency list, \\(O(V^2)\\) in an adjacency matrix, where V is the number of vertices and E is the number of edges.\n\n\nRemove Edge: \\(O(1)\\) ‚Äî Remove a connection between two nodes.\n\nEdge: Remove the edge between two vertices.\n\nTime Complexity: \\(O(1)\\) for adjacency list, \\(O(1)\\) for adjacency matrix.\n\n\nSearch:\n\nDepth-First Search (DFS): \\(O(V+E)\\) ‚Äî Explore as far as possible along each branch before backtracking.\nBreadth-First Search (BFS): \\(O(V+E)\\)‚Äî Explore all neighbors of a node before moving to the next level.\n\n\n\n\n\nIdeal for modeling relationships and connections, such as social networks, transportation networks, and dependency graphs in project management.\n\n\n\n\n\n\nPath Algorithms\n\n\n\n\n\n\n\n\nDijkstra‚Äôs Shortest Path Algorithm\n\n\n\n\n\n\nOverview:\n\nType: Greedy algorithm.\nApplicability: Works on graphs with non-negative edge weights.\nTime Complexity: \\(O(V2)\\) for the simplest implementation, \\(\\text{O(V log V+E)}\\) with a priority queue (using a binary heap), where \\(V\\) is the number of vertices and \\(E\\) is the number of edges.\nFunctionality: It finds the shortest path from a single source vertex to all other vertices in a graph by iteratively selecting the vertex with the smallest known distance, updating the distances to its neighbors, and marking it as visited.\n\n\n\n\n\n\n\n\n\n\n\nBellman-Ford Shortest Path Algorithm\n\n\n\n\n\n\nOverview:\n\nType: Dynamic programming algorithm.\nApplicability: Works on graphs with negative edge weights and can detect negative weight cycles.\nTime Complexity: \\(O(V*E)\\), where \\(V\\) is the number of vertices and \\(E\\) is the number of edges.\nFunctionality: It calculates the shortest path from a single source vertex to all other vertices by relaxing all edges repeatedly over \\(V‚àí1\\) iterations.\n\n\n\n\n\n\n\n\n\n\n\nDifferences Between Dijkstra and Bellman-Ford\n\n\n\n\n\n\nComparison chart\n\n\n\n\n\n\n\nFeature Dijkstra‚Äôs\nAlgorithm Bellman-Ford\nAlgorithm\n\n\n\n\nEdge Weights\nNon-negative edge weights only\nHandles negative edge weights\n\n\nNegative Cycle Detection\nCannot detect negative cycles\nCan detect negative cycles\n\n\nTime Complexity\n\\(O(V2)\\) for the simplest implementation, \\(\\text{O(V log V+E)}\\) with a priority queue (using a binary heap), where \\(V\\) is the number of vertices and E is the number of edges.\n\\(O(V*E)\\), where \\(V\\) is the number of vertices and \\(E\\) is the number of edges.\n\n\nGraph Type\nDirected or undirected with non-negative weights\nDirected or undirected with any weights, including negative\n\n\nAlgorithm Type\nGreedy\nDynamic programming\n\n\nUse Case\nFaster for graphs with non-negative weights\nMore general, can be used when negative weights are present\n\n\n\n\n\n\n\n\n\nSummary\n\n\n\n\n\n\n\n\nSummary of ADTs\n\n\n\n\n\n\nArray: Fixed-size, contiguous memory; fast access by index.\nLinked List: Dynamic size; efficient insertions and deletions.\nStack: LIFO order; used in recursion, undo operations.\nQueue: FIFO order; used in scheduling, buffering.\nDeque: Double-ended queue; flexible insertions/deletions.\nHash Table: Key-value pairs; fast lookups and inserts.\nTree: Hierarchical structure; efficient searches and sorted data.\nHeap: Binary tree for priority queues; fast access to max/min.\nSet: Unique elements; fast membership checks.\nGraph: Nodes and edges; used in networks and relationship modeling.\n\n\n\n\n\n\n\n\nKey Operations in a Dictionary/Map\n\n\nA Dictionary (in Python) or Map (in many other programming languages) is a data structure that stores key-value pairs, where each unique key maps to a specific value. Dictionaries/Maps provide efficient insertion, deletion, and lookup operations, typically in \\(O(1)\\) time on average due to the underlying hash table implementation.\n\n\nInsertion\nDescription: Adding a new key-value pair to the dictionary.\nSyntax:\n\ndictionary[key] = value\n\nExample:\n\nphone_book = {}\nphone_book['Alice'] = '555-1234'\n\nThis adds the key 'Alice' with the value '555-1234' to the phone_book dictionary.\n\n\n\nLookup (Access)\nDescription: Retrieving the value associated with a given key.\nSyntax:\n\nvalue = dictionary[key]\n\nExample:\n\nalice_number = phone_book['Alice']\n\nThis retrieves the value associated with 'Alice', which is '555-1234'.\n\n\n\nDeletion\nDescription: Removing a key-value pair from the dictionary.\nSyntax:\n\ndel dictionary[key]\n\nExample:\n\ndel phone_book['Alice']\n\nThis removes the 'Alice' entry from the phone_book dictionary.\n\n\n\nUpdate\nDescription: Updating the value associated with a given key.\nSyntax:\n\ndictionary[key] = new_value\n\nExample:\n\nphone_book['Alice'] = '555-5678'\n\nThis updates 'Alice's number to '555-5678'.\n\n\n\nCheck Existence\nDescription: Checking if a key exists in the dictionary.\nSyntax:\n\nkey in dictionary\n\nExample:\n\nif 'Alice' in phone_book:\n    print(\"Alice is in the phone book\")\n\nThis checks if 'Alice' is a key in phone_book.\n\n\n\nIteration\nDescription: Iterating over keys, values, or key-value pairs in the dictionary.\nSyntax:\n\nIterate over keys\nfor key in dictionary:\n    print(key)\n\nIterate over values\n\nfor value in dictionary.values():\n    print(value)\n\nIterate over key-value pairs\n\nfor key, value in dictionary.items():\n    print(f\"{key}: {value}\")\n\nExample:\n\nfor name, number in phone_book.items():\n    print(f\"{name}: {number}\")\n\nThis prints all key-value pairs in phone_book.\n\n\n\nGet Method\nDescription: Retrieving the value associated with a given key, with an optional default if the key doesn‚Äôt exist.\nSyntax:\n\nvalue = dictionary.get(key, default_value)\n\nExample:\n\nbob_number = phone_book.get('Bob', 'Not Found')\n\nIf 'Bob' is not in phone_book, bob_number will be 'Not Found'.\n\n\n\nLength\nDescription: Getting the number of key-value pairs in the dictionary.\nSyntax:\n\nlength = len(dictionary)\n\nExample:\n\nnum_contacts = len(phone_book)\n\nThis returns the number of entries in phone_book.\n\n\n\nClearing\nDescription: Removing all key-value pairs from the dictionary.\nSyntax:\n\ndictionary.clear()\n\nExample:\n\nphone_book.clear()\n\nThis removes all entries from phone_book, making it an empty dictionary.\n\n\n\nCopying\nDescription: Creating a shallow copy of the dictionary.\nSyntax:\n\nnew_dictionary = dictionary.copy()\n\nExample:\n\nbackup_phone_book = phone_book.copy()\n\nThis creates a copy of phone_book called backup_phone_book.\n\n\n\nPop\nDescription: Removing a key from the dictionary and returning its value.\nSyntax:\n\nvalue = dictionary.pop(key, default_value)\n\nExample:\n\nremoved_number = phone_book.pop('Alice', 'Not Found')\n\nRemoves 'Alice' from phone_book and returns her number. If 'Alice' is not found, it returns 'Not Found'.\n\n\n\nPopitem\nDescription: Removes and returns an arbitrary key-value pair as a tuple (key, value).\nSyntax\n\nkey, value = dictionary.popitem()\n\nExample\n\nlast_entry = phone_book.popitem()\n\nRemoves and returns the last inserted key-value pair in the dictionary.\n\n\n\nSetdefault\nDescription: Returns the value of a key if it exists; otherwise, inserts the key with a specified value and returns that value.\nSyntax:\n\nvalue = dictionary.setdefault(key, default_value)\n\nExample:\n\nalice_number = phone_book.setdefault('Alice', '555-0000')\n\nIf 'Alice' is in phone_book, it returns her number. Otherwise, it adds 'Alice': '555-0000' to phone_book and returns '555-0000'.",
    "crumbs": [
      "Data Structures"
    ]
  },
  {
    "objectID": "courseC949.html#applies-algorithms---40",
    "href": "courseC949.html#applies-algorithms---40",
    "title": "Data Structures",
    "section": "Applies Algorithms - (40%)",
    "text": "Applies Algorithms - (40%)\n\nVariable declaration (dynamic vs static)\nThe way variables are declared and managed in programming languages can be broadly categorized into static and dynamic types. This classification impacts how and when variables are allocated and accessed in memory.\n\n\n\n\n\n\n\nStatic Variable Declaration\n\n\n\n\n\n\n\nDescription\n\nStatic variables are allocated memory at compile time, and their type and size are known before the program runs. The memory for static variables is typically allocated on the stack or in the data segment of memory.\n\n\n\n\nCharacteristics\n\nFixed Size: The size and type of the variable are determined at compile time.\nMemory Allocation: Memory is allocated during compilation and deallocated when the program exits or the variable goes out of scope.\nScope and Lifetime: - Scope: The scope (visibility) of static variables is determined by where they are declared (e.g., within a function or globally). - Lifetime: The variable‚Äôs lifetime extends for the duration of the program or the block in which it is declared.\n\n\n\n\nExamples\nC/C++:\n\nint main() {\n    int x = 10; // Static variable\n    return 0;\n}\n\nHere, x is a static variable with a fixed size and type, determined at compile time.\nJava:\n\npublic class Example {\n    static int x = 10; // Static class variable\n}\n\nIn Java, x is a static variable of the class Example, meaning it belongs to the class rather than any specific instance.\n\n\n\n\n\n\n\n\n\n\n\n\nDynamic Variable Declaration\n\n\n\n\n\n\n\nDescription\n\nDynamic variables are allocated memory at runtime. Their type and size are determined while the program is executing, and they are often managed using dynamic memory allocation functions or constructs.\n\n\n\n\nCharacteristics\n\nFlexible Size: The size and type of the variable can be determined and adjusted at runtime.\nMemory Allocation: Memory is allocated on the heap or through dynamic memory management constructs, and deallocated when no longer needed.\nScope and Lifetime: - Scope: The scope of dynamic variables is determined by how they are referenced in the code. - Lifetime: The lifetime of a dynamic variable extends from the point of allocation to the point of deallocation.\n\n\n\n\nExamples\nC/C++:\n\nint* ptr = (int*) malloc(sizeof(int)); // Dynamic memory allocation\n*ptr = 10;\nfree(ptr); // Deallocate memory\n\nPython:\n\nx = [10]  # Dynamic variable (list with one element)\nx.append(20)  # Modify the list\n\nIn Python, x can dynamically grow in size as new elements are added to the list.\n\n\n\n\n\n\n\nStrongly-typed vs Weakly-typed\n\nStrongly-Typed Languages\n\n\n\nDefinition:Key Characteristics:Examples:\n\n\nIn strongly-typed languages, the type of a variable is strictly enforced. This means that once a variable is assigned a specific type, it cannot be implicitly converted to another type without explicit conversion.\n\n\n\nStrict Type Enforcement: Operations between incompatible types will result in a compile-time or runtime error. For example, you cannot add a string to an integer without explicitly converting one of them.\nFewer Implicit Conversions: Strongly-typed languages avoid automatic type coercion, where one type is automatically converted to another.\nType Safety: The language provides more safety by catching type-related errors early, often at compile time.\n\n\n\n\nJava: You cannot assign a string to an integer variable without explicit conversion.\n\n\n\nint x = \"5\"; // Compile-time error\n\n\n\nC#: You must explicitly cast types when necessary.\n\n\n\nint x = 10;\nstring y = \"5\";\nint result = x + int.Parse(y); // Correct\n\n\n\nPython: While dynamically typed, Python is strongly-typed as it does not allow implicit conversion between incompatible types.\n\n\n\nx = 10\ny = \"5\"\nresult = x + y  # Runtime error\n\n\n\n\n\n\n\nWeakly-typed Languages\n\n\n\nDefinition:Key Characteristics:Examples:\n\n\nIn weakly-typed languages, the type system is more flexible, allowing implicit conversions between types. The language may automatically convert one type to another as needed, often during runtime.\n\n\n\nImplicit Type Coercion: The language can automatically convert types in certain situations, such as adding a number to a string by converting the number to a string.\nLess Type Safety: While more flexible, weakly-typed languages may introduce subtle bugs due to unintended type coercions that go unnoticed.\nEase of Use: In some scenarios, weak typing can make code easier to write and understand, especially for quick scripting tasks.\n\n\n\n\nJavaScript: Automatically converts types when needed.\n\n\n\nlet x = 10;\nlet y = \"5\";\nlet result = x + y; // \"105\" (y is converted to a string)\n\n\n\nPHP: Also allows implicit type conversion.\n\n\n\n$x = 10;\n$y = \"5\";\n$result = $x + $y; // 15 (y is converted to a number)\n\n\n\n\n\n\n\n\nComparison between Types\n\n\n\n\n\n\n\n\nComparison: Strongly-Typed vs.¬†Weakly-Typed\n\n\n\n\n\n\nType Safety: Strongly-typed languages provide more safety by enforcing type rules, reducing errors due to unintended type conversions. Weakly-typed languages sacrifice some of this safety for flexibility.\nFlexibility: Weakly-typed languages allow for more flexible and often shorter code, especially in cases where automatic type conversion is beneficial.\nError Handling: Strongly-typed languages catch type-related errors early, often at compile time, while weakly-typed languages may only reveal such errors at runtime, if at all.\n\n\n\n\n\n\n\n\n\nAssignment operators\n\nSimple Assignment (=): Assigns a value to a variable.\nCompound Assignment:\n\n+=: Addition\n-=: Subtraction\n*=: Multiplication\n/=: Division\n//=: Floor Division\n%=: Modulus\n**=: Exponentiation\nBitwise Operators: &=, |=, ^=, &lt;&lt;=, &gt;&gt;=\n\n\nAssignment operators streamline code by combining operations and assignments into a single step, making code more concise and often more readable.\n\n\nOrder of operations / precedence rules\n\n\n\n\n\n\n\n\nOperations & Rules\n\n\n\n\n\n\n\n1. Arithmetic Operations\n\nParentheses: () - Expressions inside parentheses are evaluated first. - Example: \\(\\text{(2 + 3) * 4}\\) evaluates to 20.\nExponentiation: ** (or ^ in some languages like Excel) - Raises a number to the power of another number. - Example: \\(\\text{2 ** 3}\\) evaluates to 8.\nUnary Plus and Minus: +, - (unary) - Unary plus and minus are applied next. - Example: \\(\\text{-5 + 3}\\) evaluates to -2.\nMultiplication and Division: *, /, // (floor division), % (modulus) - Multiplication and division have the same precedence, evaluated from left to right. - Example: \\(\\text{6 / 2 * 3}\\) evaluates to 9.\nAddition and Subtraction: +, - - Addition and subtraction have the same precedence, evaluated from left to right. - Example: \\(\\text{5 + 3 - 2}\\) evaluates to 6.\n\n\n\n\n2. Comparison Operations\n\nEquality and Inequality: \\(==\\), \\(!=\\) - Checks if two values are equal or not equal.\nRelational Operators: \\(&gt;\\), \\(&lt;\\), \\(&gt;=\\), \\(&lt;=\\) - Compares two values to determine the relationship between them.\n\n\n\n\n3. Logical Operations\n\nNegation: not - Evaluates to the opposite Boolean value.\nAnd: and - Evaluates to True if both operands are True.\nOr: or - Evaluates to True if at least one operand is True.\n\n\n\n\n4. Assignment Operators\n\nSimple Assignment: \\(=\\) - Assigns a value to a variable.\nCompound Assignment: \\(+=\\), \\(-=\\), \\(*=\\), \\(/=\\), etc. - Performs an operation and assigns the result to a variable.\n\n\n\n\n5. Bitwise Operations\n\nBitwise Not: \\(\\text{~}\\) - Inverts all bits of the operand.\nBitwise And: \\(\\text{&}\\) - Performs a bitwise AND operation.\nBitwise Or: \\(|\\) - Performs a bitwise OR operation.\nBitwise XOR: \\(\\text{^}\\) - Performs a bitwise XOR operation.\nBitwise Shift: \\(&lt;&lt;\\), \\(&gt;&gt;\\) - Shifts bits to the left or right.\n\n\n\n\n6. Miscellaneous\n\nFunction Calls - Functions are evaluated first, from innermost to outermost.\nMember Access: \\(.\\) (dot operator) - Accesses properties or methods of an object.\nIndexing and Slicing: \\(\\text{[ ]}\\) - Retrieves or modifies elements from collections like lists or arrays.\n\n\n\n\n\n\n\n\nLoops\n\n\n\n\n\n\n\n\nTypes of Loops\n\n\n\n\n\n\n\nTopic\n\n\n\n\n\nDescription: The for loop iterates over a sequence (such as a list, tuple, or string) or a range of numbers, executing a block of code for each item.\n\n\n# Iterating over a list\nnumbers = [1, 2, 3, 4, 5]\nfor number in numbers:\n    print(number)\n\n# Iterating over a range\nfor i in range(5):\n    print(i)\n\nWhile Loop\n\nDescription: The while loop repeatedly executes a block of code as long as a specified condition remains True.\n\n\n# Looping while a condition is True\ncount = 0\nwhile count &lt; 5:\n    print(count)\n    count += 1\n\nDo-While Loop\n\nDescription: The do-while loop (available in C/C++ but not in Python) executes a block of code at least once and then repeatedly executes it as long as a condition remains True.\n\n\n// Looping at least once and then while a condition is True\nint count = 0;\ndo {\n    std::cout &lt;&lt; count &lt;&lt; std::endl;\n    count++;\n} while (count &lt; 5);\n\nBreak\n\nDescription: Exits the loop immediately, regardless of the loop‚Äôs condition.\n\n\nfor i in range(10):\n    if i == 5:\n        break\n    print(i)\n\nContinue\n\nDescription: Skips the rest of the code inside the current iteration of the loop and proceeds to the next iteration.\n\n\nfor i in range(10):\n    if i % 2 == 0:\n        continue\n    print(i)\n\nPass\n\nDescription: In Python, pass is a placeholder statement used when a statement is syntactically required but you do not want to execute any code.\n\n\nfor i in range(10):\n    if i % 2 == 0:\n        pass  # Do nothing\n    else:\n        print(i)\n\nNested Loops\n\nDescription: You can nest loops inside other loops to perform more complex iterations.\n\n\nfor i in range(3):\n    for j in range(2):\n        print(f\"i={i}, j={j}\")\n\n\n\n\n\n\n\n\nConditional statements / branching\n\n\n\n\n\n\n\n\nTypes of Statements\n\n\n\n\n\n\n\nTopic\n\nIf Statement\n\nDescription: The if statement executes a block of code if its condition is True.\n\n\n\nx = 10\nif x &gt; 5:\n    print(\"x is greater than 5\")\n\n\nIf-Else Statement\n\nDescription: The if-else statement executes one block of code if the condition is True, and another block if it is False.\n\n\n\nx = 3\nif x &gt; 5:\n    print(\"x is greater than 5\")\nelse:\n    print(\"x is 5 or less\")\n\nx is 5 or less\n\n\n\nIf-Elif-Else Statement\n\nDescription: The if-elif-else statement allows for multiple conditions to be checked in sequence. If the if condition is False, it checks elif (else if) conditions in order, and finally executes the else block if none of the conditions are True.\n\n\n\nx = 7\nif x &gt; 10:\n    print(\"x is greater than 10\")\nelif x == 7:\n    print(\"x is 7\")\nelse:\n    print(\"x is less than 10 and not 7\")\n\n\nSwitch-Case Statement\n\nDescription: The switch-case statement (used in C/C++ and some other languages but not Python) provides a way to dispatch execution to different parts of code based on the value of an expression.\n\n\n\nint day = 3;\nswitch (day) {\n    case 1:\n        std::cout &lt;&lt; \"Monday\" &lt;&lt; std::endl;\n        break;\n    case 2:\n        std::cout &lt;&lt; \"Tuesday\" &lt;&lt; std::endl;\n        break;\n    case 3:\n        std::cout &lt;&lt; \"Wednesday\" &lt;&lt; std::endl;\n        break;\n    default:\n        std::cout &lt;&lt; \"Other day\" &lt;&lt; std::endl;\n}\n\n\nAND Operator\n\nDescription: Returns True if both conditions are True.\nSyntax:\n\nPython/C/C++: condition1 and condition2\n\nExample:\n\nPython: if x &gt; 0 and x &lt; 10 :\nC++: if (x &gt; 0 && x &lt; 10)\n\n\nOR Operator\n\nDescription: Returns True if at least one of the conditions is True.\nSyntax:\n\nPython/C/C++: condition1 or condition2\n\nExample:\n\nPython: if x &lt; 0 or x &gt; 10 :\nC++: if (x &lt; 0 || x &gt; 10)\n\n\nNOT Operator\n\nDescription: Returns the opposite Boolean value of the condition.\nSyntax:\n\nPython/C/C++: not condition\n\nExample:\n\nPython: if not x &gt; 5 :\nC++: if (!(x &gt; 5))\n\n\n\n\n\n\n\n\n\n\nClasses\n\n\nDefinition\nA class is essentially a template for creating objects. It encapsulates data for the object and methods to operate on that data.\n\nclass ClassName:\n    def __init__(self, attribute1, attribute2):\n        self.attribute1 = attribute1\n        self.attribute2 = attribute2\n\n    def method_name(self):\n        # Method code\n\n\n\nComponents of a Class\n\n\n\n1. Attributes:2. Methods:3. Constructor:4. Destructor:\n\n\nVariables that hold data related to the class. They define the state of an object.\n\nPython: Defined within the __init__ method using self.\nC++: Defined within the class, often with private access and initialized via a constructor.\n\n\n\nFunctions defined within a class that operate on its attributes or perform actions.\n\nPython: Defined with def keyword within the class.\nC++: Defined with the function signature inside the class and implemented outside the class body.\n\n\n\nA special method that initializes objects of the class. It is called when an object is created.\n\nPython: __init__ method.\nC++: Defined with the class name and no return type.\n\n\n\nA method that cleans up when an object is destroyed (in C++). Python manages memory automatically, so a destructor is less commonly used.\n\nPython: __del__ method (optional).\nC++: Destructor defined with ~ClassName().\n\n\nclass Car:\n    def __init__(self, make, model, year):\n        self.make = make\n        self.model = model\n        self.year = year\n\n    def display_info(self):\n        print(f\"{self.year} {self.make} {self.model}\")\n\n# Creating an object of the class\nmy_car = Car(\"Toyota\", \"Corolla\", 2022)\nmy_car.display_info()  # Output: 2022 Toyota Corolla\n\n\n\n\n\n\n\nInheritance\n\n\n\nDefinition:Example:\n\n\nInheritance allows you to create a new class that is based on an existing class, inheriting its attributes and methods.\n\n\n\nclass ParentClass:\n    # Parent class code\n\nclass ChildClass(ParentClass):\n    # Child class code\n\n\n\n\n\n\n\nEncapsulation\n\n\n\nDefinition:Access Specifiers:\n\n\nEncapsulation is the concept of restricting access to certain details of an object‚Äôs implementation. It involves using access specifiers to control the visibility of attributes and methods.\n\n\n\nPython: Uses naming conventions (e.g., _private or __private) rather than strict access specifiers.\nC++: Uses public, protected, and private keywords to control access.\n\n\nclass BankAccount: \n  def __init__(self, balance):\n  self.__balance = balance\n\n  def deposit(self, amount):\n      if amount &gt; 0:\n          self.__balance += amount\n\n  def get_balance(self):\n      return self.__balance\n\n# Creating an object of the class\naccount = BankAccount(1000)\naccount.deposit(500)\nprint(account.get_balance())  # Output: 1500\n\n\n\n\n\n\n\nPolymorphism\n\n\n\nDefinition:Example:\n\n\nPolymorphism allows objects of different classes to be treated as objects of a common base class, typically through method overriding.\n\n\n\nclass Animal:\n    def speak(self):\n        print(\"Animal speaks\")\n\nclass Dog(Animal):\n    def speak(self):\n        print(\"Dog barks\")\n\ndef make_animal_speak(animal):\n    animal.speak()\n\n# Creating objects\nanimal = Animal()\ndog = Dog()\n\nmake_animal_speak(animal)  # Output: Animal speaks\nmake_animal_speak(dog)     # Output: Dog barks\n\n\n\n\n\n\n\n\nSummary\n\n\nClasses: Define custom data types with attributes and methods.\nInheritance: Create new classes based on existing ones, inheriting their properties and methods.\nEncapsulation: Restrict access to certain parts of an object‚Äôs implementation.\nPolymorphism: Allow different classes to be treated as objects of a common base class, often through method overriding.",
    "crumbs": [
      "Data Structures"
    ]
  },
  {
    "objectID": "courseD493.html",
    "href": "courseD493.html",
    "title": "Scripting & Programming",
    "section": "",
    "text": "Scripting & Programming - Applications (D493)\n\n\n\nBasic\n\n#include &lt; ‚Ä¶ &gt; library facility\n¬†¬†a directive that tells the compiler what library will be used.\n\n\n\n\\(\\text{std}\\) standard library\n¬†¬†is a namespace\n\n\n\n\\(::\\) scope operator\n¬†¬†allows look-ups for objects by their names within a namespace\n\n\n\n\\(\\text{cout}\\) [see ‚Ä¢ out] character out\n¬†¬†a standard \\(IO\\) object\n\n\n\n\\(\\text{cin}\\) [see ‚Ä¢ in] character in\n¬†¬†a standard \\(IO\\) object\n\n\n\n\\(\\text{endl;}\\) manipulator\n¬†¬†ends the current line and flushes the buffer associated with the device to force the text to show up on the console.\n\n\n#include &lt;iostream&gt;\n\nint main()\n{\n  std::cout &lt;&lt; \"Hello, World!\" &lt;&lt; std::endl;\n}",
    "crumbs": [
      "Scripting & Programming"
    ]
  },
  {
    "objectID": "courseD495.html",
    "href": "courseD495.html",
    "title": "Big Data",
    "section": "",
    "text": "Big Data Foundations (D495)\n\n\n\ncoming soon",
    "crumbs": [
      "Big Data"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "1¬† Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Summary</span>"
    ]
  }
]